{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We made experiments on the data from {AD}. It consists of Reddit posts in English categorized into 10 topics: science, politics, history, space and astronomy, Minecraft video game, sexual activities, guns, food and cooking, music and motorcycles. In each class there is 100 posts in the database. The first 9 categories were treated as positive samples, while motorcycles as the anomalies. \n",
        "\n",
        "\n",
        "\n",
        "The training set constitutes $90\\%$ of comments from positive classes, they are selected randomly without assuming the equality of categories. The test collection consists of the remaining $ 10\\% $ of posts from positive classes and 100 comments from the category of motorcycles. So we have $52\\%$ of the anomaly in the test set.\n",
        "The accuracy metric was used for evaluation as the test set had almost the same number of inliers as outliers, and the authors of {AD} also used this metric.\n",
        "\n",
        "\n",
        "\n",
        "On the picture on the right there is a schema of the pipeline we used in our experiment."
      ],
      "metadata": {
        "id": "kp6MMJYxu71U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![diagram11.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdAAAAJRCAIAAAB6O3G3AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAAhdEVYdENyZWF0aW9uIFRpbWUAMjAyMjowOTowMSAxNToxNTo1ORpv1GoAAMYASURBVHhe7J13YFRF14dFegu9d1BEpAmIFKVjoUlHilRpgvRmQVDgBQUbHQSVJr0XAaUICChIFanSW4BQQieU78nOsN+6ye6dC9lkk5znj+XO7LlzZ86c+d1zN7tDnGvXrsWPHz9hwoRPGXDr1q2HDx8mSZJEl71y10GyZMl02Sv379+/fv16ihQpdNkr9OHq1aspU6bUZSsuX76McZw4cXTZK7RMn+PGjavLXsF7iRIlwoG67JWbN2/Sh8SJE+uyV+7cuXPv3r2kSZPqslewpPGAgABd9sqDBw+Cg4NteS9VqlS6YMWVK1foxtNPP63LXqEbxFK8ePF02Ss3btzA0jBQb9++zTANAzUkJAT75MmT67JXfO09loAvApXFlcCBLnuFZc6rYaD61TL3UaDaXeY0i70u/xej6wmCIAhPjgiuIAhCJBHn7NmzPJWYPNbxpMOzA3k+j3W86lrP8JzLEwSptYkxT2o8RPMMaGKMDU89hg+MQJJvaMwYMWaAJs8aGNMNHjRMHuswZoC88ljnC+8xNTwD+oP36DMHusozdr3HU7+PAhU/h4SEmHuPnhgGKph7DzCmG4besxWotrxHoHIQ45e5jwLV+zKXz3Ddkc9w3ZDPcF3xtffkM1wnj7HM5TNcQRAEQSOCKwiCEEmI4AqCIEQSIriCIAiRhAiuIAhCJCGCKwiCEEmI4AoRieFXmhS+MwbfNW74XSKFLWMhxiPfw3VHvofrRtivN+J/Bq4LLjC6K1euJE+e3ERlMKYbeMPw2/g3btxgUvA2V9e1HsDYGaiWxhASEoK36baJMd5TgWpiDIRT2KjmXAYe9lux8j1cV/BSzPsergiuOyK4boSN46CgoEyZMnFRQ9ERwvLdd9+9++67uvAIEVxXRHBFcN2JtYKbNm3aN954o1KlSvRT1zogQnCIiauxwRgJMEyHuRCWhj9LI2klSIhqk1sCsYcD6baJMTb0xNNyCgtjdJ1xhoA/hw0bNmHChDZt2ujaR4jguvIYy9z/BTe0rdu3bzM2E2iLJztdsIK4pHFdsIKIxwW6YAWSgXN1wYBLly5xii5YQTdU7mYCykW06YIVuA4H6oIVTAqhqQtWoC+Epi5YQdDb9Z4+esTFixeJnOHDh+uyC+o3tbpgBRFCZ3TBCvxsPi9YKs01gT6YTyKjo9u6YEDYxXXy5Em8h+DqsgvMi48ClZVo3m2i1DxQ/WqZ6yMDaNk89uwuc5WYhouRwAuCISrUdMEKpc66YIUSXF2wArXFXhesYOHRE12wgtEhRrpggC1jIcYjgisIghBJhG7PGM+BrvCM+hyNA8OPxshHILHZrndkOmQZSZMmNTFWWYbh55tAkm9ozBgxTpQokeEHiyR08X2zPSM5Gj4x/GBRPRQb/lEeG7pt+EE8uHkPz1y8eDFPnjwDBw784IMPeJzUbzhgXphxhqnLnsEGY7xh6D3Cg0ubfI6GMd6w5T287YtABTfvsdBOnDjxwgsvfPPNNx07drx+/bp+w4Fd77ESzQPVT5Y5jUdOoHqBMfpumatA9bTM41y9epX3TJxLW8wxByb+UtNG3Bt+24agxwUpzL5tgw3dTpUqlYkxXDH+WwQ2GBv+LQJj5AbXmWgoxgyQmTAJTYyZNuKYnpiMEUumxtB7BD3dTpkypbn3XP9wwRAuXLiQPn36YcOG9ezZk9b0G4+856OvhaFNWJpoKMasEDpmIosYE6V4OyAgIHK8h+DmyJFj3Lhx7dq1c/Pe5cuXzQOVJcAAzQM1Nixzw7+w0W27gUrgRcgy562nMYLQI68oG1vGrgeWOBo2NQZbLesjK+x2QNmbnOW0NDd2PTDB3Di0E3aM9ZEDFTS8Uq8D6BGOVn3bB5NTfGeswNKWsT5y4PSe89WJeZvg6ILtPpic4jtjBZbmxmCrZX1khaMLtps1OcXamFkXBEEQIgERXEEQhEhCBFcQBCGSEMEVBEGIJERwBUEQIgkRXEEQhEhCBFcQBCGSEMEVBEGIJERwBUEQIgkRXEEQhEhCBFcQBCGSCBXcOAabZTixZWyL2NCy73piC1vd8BNj/8FPxhgbvGcLP5kX78QJDAx0bNtmum/bw4cPDXe9c2zbFv22Z7x+/Tp9NtllAmO6ET9+fEPvMUBeDXe9CwkJuX//vqH3sGRqbHnPcB8ycPMenrl48WKuXLkGDRr04Ycfum7PqLyXJEkSDnSVZ7ChZbxhuN/VrVu3sDTcscluoOJtwz0DCVR68tjeI1SOHz+eP3/+b7/9tlOnTm7bM2Jsy3u2Nhh0rHLZhTUUxhhVyzx0mzLaMty3jWnDzHzfNuLYMDTt7tum/lcuE2O4evVqQEAAXdJlz2CDMX02nAlb2zMybbyahCZmTBs+MQxNIp6pMdxgEBu73mNedOGpp1C98+fPZ8yY8YsvvujVqxeX1m84uu277RkJDy7to+0ZiVXDDQZplrVqGKjg5j0Ge+zYMW5XY8eObd++fVjvmQcq3mMlGt6u6LP5MidQOfDRMqfxyAlUL9DtKFvmtMXa5j0TaIu41wUrmAka1wUriDyiTResIOjt/mdHnKILVtANOqMLVhAQLFddsALX4UBdsIJJYZHoghVEPAGkC1YQ9E/4X0V5+T/NbP1XUfSZnuuCFXjDPFARXPNAZQaZR12w4sm9J/+nmS5Y8RjLXB8ZYCtQ7S5zlZiGi7XAC4I/QNagjwQh2iKCK/gjZDekQkGPIHlxOwASbZVb6XMEwe8RwRX8kfPnz5cqVSrtI9KkSZM9e/asWbNyoKvSpk2XLl2LFi14pNXnPDGBgYEi34JPEcEV/JHEiRM3bNiwdevW7Ry0b9++ZMmSqGGZMmU6dOigKnm3cuXKJn818g4tkCwPHjx40qRJIriCTxHBFfyRgICATz75ZMKECWPGjBk7diyvtWrVor5evXocK3i3bdu2Jl9y8M7TTz998uTJ77777ty5cyZ/thaEx0bCS/BH4rj8H3wcK1Q9r/qNp58mOVU1T4j6hlCiRIl0WRB8gwiuED1QD/vhPvJfu3Zt5cqVAwcOJCmeMWPGhQsXnCr84MED3urbt++iRYs4VpWAzdChQ4cPHx4YGIgBB0FBQWvXru3Vq9fixYvlgwXBR4jgCtGbv/76q06dOvXr10dt0dxWrVq9/vrrS5Yscc2Fx40b17Fjx507d6pT7t+/P3bs2A8++GD//v3ktr/88gsyHRwcvG3bNpQX/XWVZkGIQERwhWgMitmmTZvNmze3b9/+8OHDZ86cQUkvXbqEvG7YsEHZVKlS5dNPPz19+vQ333xz3fFTWhSW49KlSw8YMCBp0qS8ktVmy5atXbt2JLxkvk/+hzhBCBcRXCG6EhISMmLEiN27dw8aNAiVzJMnT6ZMmVq0aDFr1iwUc/To0SStyrJly5b16tWjftGiRWfPnh0yZEi8ePF4zZo1K++S5KZOnZpEOHHixOnTp0+ePLk6SxAiHBFcIbpy8uTJ3377rUCBAo0bN0Yude1TTxUrVuyNN94g7SX/VTUBAQF9+/Ylhx02bBjJ76ZNm3r16lW2bFn1LqjPEOSjW8HXhIaprb/zRsgfhcMlNrTsu57YwlY3/MrY9RRy1cuXL5Of/vXXX7/++usvDjhYv3490nnhwoVDhw5pU4cKDxgw4N9//12wYEGDBg3at2+v33DgJ2O0he9a9il+4pCo8l4c4pLHK8ONcG7fvs2B4a53PPGB4X5XpBg3b9403LEJm+vXr5s/+l27ds3QmDFinCRJEteMyRMY37hxA9cZ7nd169YtXg33u7pz5879+/dNdmwCLJkapMfQe3Tb0NXg5j08c/HixezZs//vf//74IMPaEq/8ch7zDgHusoz2DCJeMPyA1PV2pdfftm/f/8hQ4Z069aNuIofP/7atWtbtmyJ7CqzsHz++eedO3fGORwzTTt37qxdu/bp06f79evXp08fBqISWw7IeWmqRo0anOK987YCFdy8R6gcP378ueeeGzlyZKdOnVy9BxgziRHrPcCYPvtimWN89+7de/fu+ShQo+kyp1lPG7OFfpMRaMsEc2O1faQvWlb4j7G5va2WwVbLthonIPSRAW4tOzcGVcGqKp1Qad4TR69NjWmZCHba0w2Okb/q1auv/C+rVq36+eefly1bVr9+fTVSoh/FGT9+POlFQEDA5MmTt2zZQqVqCjBjqfCqRucd8z5DuMbhek+NSBcMUEMzxJYx3fCfnpjMiMJWn+0am9t7Nw69LZjvekfUIva6YIVsz+gGrsOBumAFk8LtXResIOOL8dszknty0a+//lqXHz7ct2/fs88+W6VKlbC74dHDgwcPutZPmzaNxKp169ZLlizJlClThQoVgoKC9HsPH65fvz5HjhzkzrrsmSf3nmzPqAtWPMYy10cG2ApU2Z5RiHUQrProEUhkyZIl0cpFixbpKgenT5+uV69erVq19uzZo2r279//ySef5MyZs3v37mTELVq0WLt27ahRo1hyykAtBpVMqBpB8AUiuEJ0JXHixO3atUuTJk3nzp0HDRp0/PhxMpGNGze2atVq3bp1ZcqUKViwIGbI6NChQ8+cOdOlS5f8+fNT06FDh1KlSn377bdr1qxxtBT6eWWCBAm2b99++PBhlQmqekGIWERwhegBz3S88kyqigpUderUqdmyZRsyZEi+fPnSpk1buXLlrVu3tm3btl+/fsgoj6UjR47Epn79+m+//bY6C/vevXvzBNqnT58DBw5QkzVr1rJly27bti1v3ryNGzfmgVpZCkLEIoIrRA+KFi2KjPKqy4+oWLHi6tWrp02b1q1bN3Lb/v37//rrryNGjEB8eZecN06cOO+++y7amixZMnUKVKtWbfTo0SVKlLhw4cL9+/dTpEhBFjxq1CguUbp0aclwBV8hfzRzQ/5o5oaf/NGMcDI3viX/p9l/kT+auWErUOWPZkKsA7VlheiCIERPRHAFQRAiCRFcQRCESEIEVxAEIZIQwRUEQYgkRHAFQRAiCRFcQRCESCJOUFBQ/PjxDfdtu3XrFgeJEyc2Mb57926I8faM9+/fp3HDXe+wsbVvW3BwcEBAgC54hW5jTJ/VZk7ewZhuqE2ndJVnlPd4Ndz17o7N7Rnteg+HmBiDm/fixo174cKFLFmyDB06tE+fPrcdW/kplPdsbTBo7r2bN29yaU+73rmCMb168OCBoffu3buHtw33DKTZGzduPLb3GOzx48efeeaZ0aNHv/fee67eg2t2tmfEmJWIT3SVZzCmz7LMndDtqFrmoVveEUOGYGxoj2f1kRm2umEXW437ztinRNoY1cwSOtTzqiqd2HWIXXtDaNZWy5Fs7Ml7tvBpn33auD6KaPynz17sQ2+qfvITFPPfStFvWz9B8ekPeCLqJyhu+PSXZua/9oGwrvbySzNapn1dsIIsw/zHY3gDn+iCFfjZd780e0LvRdQvzZjx6PhLM58uc31kgN1AjchfmvEPr4bYMrZFbGjZdz2xha1u+Imx/+AnY4wN3rOFn8yLd+SPZoIgCJGECK4gCEIkIYIrCIIQSYjgCoIgRBIiuIIgCJGECK4QkSROnDiOwff2FYkSJTL55rkiQYIEJt88V6gv+euCFXHjxqUnumAFo0uSJIkuGGDLWIjxhP5ehehMmDChrvCK+n6ZYQzddeD6/5p44f79+9evX0+RIoUue4U+XL16NWXKlLpsxeXLlzE2FAJaps8mP+ABvMdaxYG67JWbN2/SByRJl71y586de/fuJU2aVJe9giWNG/7M5sGDB8HBwba8lypVKl1wEBQUlDZt2ipVqpQvX55+6loHt2/fJpZMXI0NxrjO8Nc+XAhLQ81VX1A1+WEVEHvYm/wCELChJ+YCzRhdjRnClStXvvnmmwkTJrRp00bXPoK3WAK+CFQWF94wvAmxzHk1DFS/WuZugeoFXM16Mbzf213mNOspQkRw3RHBdSNsHF+6dClLlizyXzA8HsQAATxx4sTWrVvrqkeI4LoigiuC607sFFz8z+V0wQVGRxwnT57cJI4xpht4w/An6oQHlnibq+taD2BMoDJMkx/4Y0yUkofiPUtjoFkmHe+ZGAMOCetqzmUgYQcugusKXhLBFcH9D7FTcL2A9wwFF/CeoeDCjRs3sDQMVASUYRoGKqk69oabpCjBNQxUCFdwPSGC60qMFFyj6wmCISwSfWSALWP/ITaMUfARcbgtqAzXMjK48TozXBNjcjRyB259JjHHrY8UhlufiTE2KkczMQbuk9zNTBIHbFTiYHLrw5hbH64jcTBxiDPDNTEm58InJg/FQIbL1Bg+FGNj13uGKQndJnHw0UcKhAfZHImDiffwhuFHCkCUEqt028SYZlWO5iPvmQcq3mMlmmS4GNNn82VOoHLgo2WuHsVMjLHxXaBG1TKPExgYSMSbZMu0ggpwYBL0gAowEybTBsQxi8Rw2rBh+WGsy1YQbYbGjBFjnGU4EzgX1xlKBt7j1TDoeUwjOk3UGbAk7g31RXnPUF/AlvcITbrBga7yDDZ0A28YSgbhgaVh0OMNIsrQewQq3jb0nq1ABXPvAcbm3sOYlWjoPQLVR8ucNY4DY/YypxsEnuEyZ4A062mZh64Q2gJd4RXa4pWOqqJ3HJ/t2Phwh1Fx69NlrzASblB+8tEYnjWJYyDomQlPH+64gWQQxyw/XfYKlipx0GWvEPRMumEuAHjP3NV4Tz7DdcWW92wFKtkf4WEeqLFhmfsuUFm2EbLMQ69ncrdxYsvYFrGhZd/1xBa2uuEnxoacOnVq3759uuAbonyMCt+17FP8xCFR5T0jgReE6EK/fv1KlChhmCQKQiQjgivEKMhcDD+jEITIRwRXiFEguIYfzAlC5COhKcQoRHAFf0ZCU4hRILjyAa7gt4jgCjGKBw8eGH5TShAiHxFcIUahPlKQJFfwT0RwhRiFfIYr+DMSmlHGlStXTp06df36dV0OD+Tj3LlzgYGB9yNu51myv4h66Ob5/cKFCxcvXuRAV0U1IriCPyOhGWX8+OOP2bJl69mzZ0hIiK76L8ji+vXrc+TI0a5duxs3bujaJwbtPn36NMKky08AUlu5cuVatWoFBQXpqqhGPsMV/BkR3Cjj9ddfz549++bNm8+cOaOrXCAPvXfv3s8//4x81KlTx/Dn55ZcunRp8ODBaH1EpcwIHNodIfIdUcgHuILfErpNWXzZnvER2GBMn00eSzG+9rj7ttH+7du327dvP8XBO++846qAmKG2R44cefvtt+nPypUr8+bN60UiMWZqGKP3bqDdf//995tvvlmxYsWJEydSNHEgHfC0VwvXPXHiBO1kzZpV/b7rStRtz4gN1K9ff9euXbt378ZdhoF69+5dYtVw+zRuMNdle8ZHYGx3matdlkyMsYmB2zOeO3eOiDcMepxLK4b7trEawdOF3SCOESDDLfKwYVSGO2kBa9XQmDESmvTZcCboBnFs6D0GyKsz6Dlr/vz5HTp0qF69+ujRo2nHOXbMOJ4xY0bPnj1btGgxcOBAJY7UM+tY0j18i1Lwij1xzNQ4vYcxV6F9iiwGzNRnrETYgQMHyKxh/PjxVKqlpaBZGudc6kM3gLp7V9Ur76mA45hmOcaGK3JdpVPUc0w9/cGYfqpznfAutwTVDVADwVjFkmpKvQW8q8KGejUQ3kWM1FlqjGFRF23atOk///zzxx9/cIp5oOIlE30BhsBADPUFzGMPMKYbYb0XFmwwZoCGgUqfcSPoKs9gjNs5wPOG3gNZ5gqM3Za5G6HiTVu8rSu84sxwddkratESmrrsFZaHShx02Sv0gRuU+VZsfvtf7Jw6dap27dpnzpxZt27ds88+q2sdED1o8Zw5cxYtWvTaa6+pSvyPlGzYsOHSpUvYo5t58uShnoincefHDmfPnl21atWePXuY1uLFi1eoUEH56ueffyabXrp0afbs2cuXL1+uXDnyQeUWVsLOnTt/++2348ePZ8qU6dVXXy1ZsqQKR7Xr3erVq+lk586dDx48uGzZsnTp0pEpZ8uWbdy4cYhgq1atiHX6Nn36dE5xjWPaZ3KxxCZNmjSqksBgFGvXriWFeeGFFxhgrly51FtAyE6ePJlm6R693b59e6FChcqUKUMebenqunXrIrgkufjEMFBRW65ovj2jSrt02Qq7/+8LS8AXgcriwp+gy14hzHh1DVQv+NUy9///Yie0LaKNsZlAWwiBLljBfZLGdcEKlgcu0AUrCHqcqwsGIE+cogtW0A06owtWsPaINl2wAtfhQF1wQK8+/PBDJpIHfF31CFQDSUUriTlVc+jQoZo1a6Jr2DOjiCkCNGbMGDpAh5UZAf3999/nzZtX5T6sRpYN0okU8i7X0rPuoE2bNsot58+fb9++ferUqWmT1c6yZEk0b96c+wHvKlcPGDCAaO7fvz+Ncy7H06ZNu3DhwvPPP0/7gYGB2EyaNEmtUhpR0AdeqSlYsCD9xwb27dtHUo/AMRDepas5cuRgIOpd4IqVK1dG9N9//32lg1z0999/Z3TawgMMp1atWvnz5yf2zAMVBzKPumAFfbAbe/rIAFr2UaCyEvGJLlhBlLoFqhf8apnrIwNo2TKcnNhd5ioxDRcRXHciU3Bh06ZN3MPr1KnjtuaRYB5hvvzyS1UkC0Z8EdB27drt3buX4a9YsQKlQ/h+/PFHOqxO/+mnn5A88kEyTdQQxRw6dCi6VqpUKVJXnLBly5YsWbLw3H3x4kU1lYwXbUX4GjRoQGcobtu2rUmTJtQgXiipapl2EL60adOOHj2alv/666/Tp0/TSOHChck9kWxsCKRjx44FBQXRPeBEivXq1UPBv/nmG+VVulGxYkUG0rVrV24DtEC+TAvILn3GAOhD1apVlUz/+uuv586do9v0xFIyuAT3pAIFCojguiGC6wYti+DGRsGlhTfeeIMnbmROVz18yITxaJwzZ87du3ermi+++IJssWfPnq6ThZyhuajSv//+S+P0vGzZsujpxo0btYVDIPr27Zs7d+5Vq1ZRJHFWT/fOaJs9ezbPgw0bNnT1P/1s3bo1sjh+/HglRkpwO3bs6LpuEUFXwQUacbbMozoZMd3u3Lmzc+CDBg2iHXJtzAgPbKg8fPhwkSJFihYtevToUYo0ogSX+4fjpFB4FLUMVCW43G9EcN0QwXUjqgTX6CMMwXfwyMzzNQksSZyueuqpAwcOrF27lmdq9cEuMfrzzz+nT5++WbNmrp+28yReu3ZtEt7NmzeTxnKwfft28keUS1s4Pk5FcDm9RIkSFNWsq7eAMFq5ciVa1qZNG9dP1kiT33333YCAgF9++YV3qeEs9Ymw988BXRufMmXKkCFDGB2yqz5qIMrXrVuH4qPmdAzUBw558uThBnPw4EH67zg19KPSNGnSoOaqaAhngeHHmoIQ+YjgRj1kuNmzZ1+xYgWZgqpZvXo12dybb76pPnrnEZ7UDynZuXPn0qVLFz9i+fLlPL/HixcPgUa51IcG+fPnV+rmBCXNmzdvuH+p4G5My6TSoKsegZqTF58+fRobiigpQmb+FwyUulevXkj/V199lTp1alWJ4J44cYKEmjvEsmXL9DAcA+EtLnTo0CHMlApzluGfYtxQpwuCHyKCG/WgtpUqVfrzzz/3799PEelBVZ955plixYopAyV2PLaT4daoUeOtR1SrVu2LL74gS+VhilcEi5wxbdq06iwTeKriRLTY+Q0HJzRF1qwLDlB2p3R6gRO5MfTs2RN1/vLLL9X3KBTcD3h33759TZs2JfNt1KhRnTp11EDQZYZ58uRJzFBMjumS4TcHnHCWuoQuC4KfIaEZ9aBrqA9ySVZIcdeuXXv27KlcuXKWLFmUAaCML730Elnwxo0b17uwadOmLVu2dO3aFRse9jEjHVanOEGG7t27x1u67AI6njBhwitXrgQHB+uqR2Af4uE3x15gLCTFvXv3Pnz4MDeD0qVL6zcegb6XKlWKkf7+++8///zz2rVr1UAoQvfu3bFBNHl9jESVkYJ8pCD4LSK4fkGJEiUKFCiADCF8q1atQunIZJ1ftCZpzZQpE0r63HPPlSlT5lUX8ufPz7vqG4U5cuRApMgfb9++rU5UrFu3DuEbP368LrtoWdKkSXPmzHn8+PEjR46oGidHjx5FNLNly2YrzUS7+/Tp8+uvv3722Wd169bVtY9IlSpV1qxZr1+/XqhQIbpUrlw5PYxXX33hhRcyZsxokkGHRems80A+UhD8FhFcvwA9fe2119DKNWvWkLQiRkiSMydFhnjoJnOcNm0auaqqBNS5Xbt2r7zyivpaQsGCBQsXLoy8Ov/0BNSr3w6kS5dOVzm+2a4aJyl+/fXXkyVLNm7cuEuXLql34ebNmz/88MPVq1fRRMOfDwDZ66hRo3766af33nuPjulaFxhI+fLl//77bxqnSB/oHgdcunnz5hUqVCDVpWhLMfHYyJEjAwMDOQ6V20cZLo0wzGHDhu3YscNhKAhRjwiuv/DGG2+gFGjH/v37SW9JWpUYKRo1aoQEDxo0qGPHjrt37758+fK2bdvatm07a9asF198Ec1FvJCzzp07X7x4sX379vPmzQsKCvr3338/+ugj2qTBypUr0w7qyVV27ty5d+9eVJUahL5evXoLFixAInmoJ0VFod59991JkyZVrVq1du3aJvKnbJBarsVA6MaDBw+QUVfIuzFr3LgxHf7kk0+6dOmya9cuLrd582Y6vGjRoqJFi5K/047rwC35448/evToQVMcc1FQn+HyiqN69+7NDcxhKAh+wDX5Hu5/oRvmX2+0+wU9L19v5EEbdWNGeLg+ePAgfaBGv+fA9QdamMWLFy9FihRNmjQ5duwYo1O/NONg8uTJefPmVd8eQ1ux59Ee5VWNkPShhioHRBnVWefPn2/Tpg3P++orX7TPcbNmzU6cOMG7ytX9+/dPmjQp6WRoK484e/Zsvnz5SpYseeHCBUaHrHM6hNVohJ6OqbPQQXVHUZ+ZcLmUKVOS4apNI4ErVqlShYSdm4eqAbwRbqAeP36cptDxkJAQ+sB9hayc2KNINp0jRw5uLdrUA8wg86gLVnBjsxt7+sgAWvZRoMr3cN2gZfWAZYLdZe7le7iyl4I7tEyflSRZgvcSPcFeCm6sW7du7ty5L7/8Mvks0YZkuG3Ggf///PNPcjq0KVOmTGXLli1RogSyRRzTOLqjzE6ePPnrr78iNAykdOnS6I7rl2fJfGfOnHn06NEsWbKgs2qC8D8pM8kmIpsxY0Y066WXXlKpIisE7yG10KpVq9y5czuaCYUpmzBhAo1TjxOmTZu2ZcsWtz4D80WAkUcXL15c1RAYZNPr169naugGGToDcfocYZ06dSqBS9LtdBdFRhpuoPbt25fMmvHSc+5JjIWuqn3RmjZtqn6y4QX8zBUNP6pmXlh+tmKPu5cuWIGrWQK+CFRmimlyDQMvEGa8eglUV/xqmdtytfrLhy57xe4yp1n1hc6whG7yxjQQxwxP13mAOKAtDhBcE2NufcwEcWxpDMwEK4qZMDFWM4FzTYzBPI6xwdgwjjFmJnAdDjRxCANkJojjcI3duocEIKP0xM047CgwUILr9F64NvrIASvKedf0dAqot5TgOg1cm3KrpMik441wWwPnucqA8EBDnUHvvWUWKsbEsasZ8NZvv/1Ws2bNgQMHcv9AcKn55ZdfOnXqRE596NAh7kxup7iCMd3A226f4XgCwWXScYiJMSjv6YJX6AmSYR6oLAHubeaBGhuWubmrMabPJoKLMSJJ4EXMMuepkDlTD3feoS08Sysm0waoAP4Nu0LChThm5kzmGLBxlQxLCCBDY8aIMQM0nAm6wX3PMOgZIK8m0wZ2vcfUeJpjN3ztPfrMga7yjF3voYnhBiozhRY3btx43759q1evRmeZPrJaEmry9FGjRuEZbeoB/EySa+49emIYqGDuPcCYbhh6z1agevJeWDAmUDmI8cvcR4Fqscy59TEZvGcCvUS/dcEKLkzjumAF08Y9RxesYNrIBXTBgGjxGa4bTAo6ogtWoBfkArpgBcvDrvf0kQG0TPu6YAV9pue6YAXe8BKoKCzZzcKFC1977bW33nprwYIFxPbcuXP1215hBplHXbDC197zUaCyElmPumAFUWoeqH61zPWRAbYC1e4yR6B1IQxGH2EIgp/zxhtvEM0//vgjx4T7ypUrX3jhhVdeeUW9Kwh+ggiuEBMoXLhw/vz5jxw5QtZMDjVu3DhS3QwZMui3BcE/EMEVYghvv/326dOnT5w4geYmSZKkXLly+g1B8BtEcIUYQpUqVe7du3fx4sUzZ84888wzhQoV0m8Igt8ggivEEDJkyJA5c+aQkJBr165x4PqfpAmCnyCCK8QQkidP/vLLL6vjggULqgNB8CtEcIUYQvz48UuWLMkBylu1alXLr98KQuQjgivEHDJnzsxrggQJnn322fvh7f8rCFGLCK4Qc0iVKlXKlCkTJ06cNm3ah2a/BBOEyEQEV4g5ZMyYkSQXTH6yKQiRjwiuEHPIkyfPjBkzRo8e/cDxn/QIgr8hgivEHEhsCxUq5NwEUhD8DRFcQRCESEK2Z/wPjBFj2Z7RFbvei+TtGcOCsa1Axc+yPaMTjAlUDmR7RgU2EbjMZQPy/4ANxlGyAbkrGLNCCOWwG5CHC5ZMjaH3CHq67aMttDG2ta8z3jBUAU8bkIcFY1YIw0yaNKmJMVGKt2UDcgXG0XeZ+y5QCbwIWeZPY6GOOPCOsrFl7HpgiaNhU2Ow1bI+ssJuB5S9yVlOS3Nj1wMTzI1DO2HHWB9ZYbdZW8ZuB17wnbECS1vG+sgKc0twdMF2yyan+M5YgaW5MdhqWR9Z4eiC7WZNTrE0ls9wBUEQIgkRXEEQhEhCBFcQBCGSEMEVBEGIJERwBUEQIgkRXMGCOI/+qmuC74z9h9gwRsFHiODGXu7duxcSodhq8PGMTc7ynbETW8aGmLT5QPaIiO5cu3bttuf/7t+Nmzdv3rhxQxesuONP/2E9p+iCFXSDzuiCFXb/w3ocqAtWMCnXr1/XBStYilevXtUFK+7fv6+8V7VqVZMvfgv+AJly+vTpFyxYoCYRbAUqK5H1qAtWEKXmgepXy1wfGUDLLARdsMLuMr9165YuhCH0Jyjx48dPmDChnlivqIYMfz9HFyFZsmS67BUGj76kSJFCl71CH9AXw1+VAM7F2PDhjpYNf2kGeC9RokQ4UJe9QhDTh8SJE+uyV4hjojNp0qS67BUsaTwgIECXvUIcE0A45NVXX92zZ0+7du04Xb8XHkg/Y9QFK+h2ggQJDF1NeMSLF89Q9LmpYGk4L0qJDOcFh2Bv+EtWbOi24XqBCPEeAz948ODatWsnTZpUv359VWkrUFlctAy67BWWOa+GgepY5f6yzFOlSqULVqD7rBfD2LO7zGnW06SL4LoTewS3VKlS3I13796t3/AAPTHXFz8RXJW8mPxoGHAI9oaTSLP0xFC5wK73PBmvWrWqUaNGY8eObdCggaoRwXUjWgiuPFEKFhBA+sgAdUvWBSvI/hA7XbCCVe09E3cFTcReF6xABeiJLljB6Gw5JKK8hxabO1bwW0IF1zAfUdgytkVsaNl3PbGFrW74ibH/ECVjDNtObPCeLaJkXuwS59y5czx5mTx80UV1myVbNrnZko+Ap11z3CDTIcsw2d4JsCFxMHzcBh6cDY0ZI4889NnkWQNjusGDhqH3GCCvPDOajJEcjczL0HtYMjW2vJc+ffrSpUtzsH37dvUI6Qm73kuSJAkHusoz2NAy3jB5KMaYTmLJQ7HlGDG2G6h422RzLCBQ6QlP0CbGYO49wDhc7xFjS5Ysad++/ddff92oUSMVSBgzQMNApc+2ljkHhoEqy9wVjL0v89BN3mjLxLm0oh55TEITY6aNODYMTSQDf5nv26Y+hTQxBsYYEBBAl3TZM9ioj8YMZ+Kane0ZmTZeTUITM6YNnxiGJhHP1DBGE2Ns8F7q1KlLlixJl3bv3s2F9HvhgUMMP3Sj21d8tj0j4YHgmmgoxniDtW3iPYzv3r1LrBpuMEiz6lNIE2Ow671wA5WBL1q0qGXLlmPHjm3YsCHzhQ3eYyUa3q7os/kyJyo48NEyp3FbgWprmZu7OqqWOVfUMHPe0XYOdJVnlI2hscJ3xoxfH1mhmgVd9orT0sReGSt0lWeUjaGxwtxYWTL3uEUFgX7DA3a9pwtWPJ6xySlOG3NjXk2MFTjElrE+ssJLH5gj3uJVTRk1FB+jZfXqHaeNuTGvJsYKW96z27I+soI2fec978bWAi8IgiBECCK4giAIkYQIriAIQiQhgisIghBJiOAKgiBEEiK4giAIkYQIriAIQiQhgisIghBJiOAKgiBEEiK4ggVPG/z8URAEE2QtCR65f//+1atXg4KCLnnmlteNb0y4d+/e5cuX1e/3fQSNcwnvGzaqX+6D+gk8r+osuqcMBOHJCRVc9QNtQ2wZ2yI2tOy7ntjCsBuHDh0qXbp0njx50nhmxIgR2tqBrQFiHC9evPXr1z/77LP9+vXTtT5gyJAhXGLNmjW6HAay+MDAwFdffbVatWoXL16kBp3t3bt3zpw5t27dqmyc2B2jPnoywrYTUS1HMr7rdpTMi13inD9/PnTXNtme0QFj9IftGTEjHSPBNPQelkyNLe+lT59e7Ra2c+fOcLPUBAkS7Nmzp3HjxhcuXKhSpYqnSa9Ro0bVqlXVW8p74W4wGBZs1CSig82aNWvSpMnnn39OGOi3/wvGdDLuY23PSHHAgAGTJk2aOHFi9erVw+a5RCkOvHLlSs2aNQMCAmbMmJE5c2Zipnv37nPmzFmwYEHZsmVDQkKUMT2kJ5G/PePixYvbtWv37bffyvaMnogWyzwOD000ZKgCamWaOBdjIht8tG/btWvXMNZlK3hONDSm2xgzbYYzwbQhAUyGrvIMxgyQZg03GCToiWPD0MSSaTbcYFB5L23atAguMYqqhtUgYFy7d++uW7cuzbLaM2TIEK4a0prTV3Tb7q53NL569WpEBM396quvCAP99n/BmK6aByreoLdqg0GKpM/jx4+fPHkykhp2sIgpDqTn3DmIE0Q2U6ZMVJ45c4bVkTt3btdZoFl6YhioYCv26AMO4UBXPYIAW7RoUatWrUaPHo2vGAI2tGxre0YmFEy851fL3HwnzOixzBkS0cl7JtAW0aYLViAZNK4LVhDxpBi6YAVBz0rQBQMuyf/a6wJBr7yH4BYsWFBVhss///zDk3jRokV5DNJVVtAN2tcFK1Sff/3115QpU3br1k1VegJvmAcqk6KSXMWHH36YKlWq5cuX6/J/wXu0fPbs2QIFCpQuXTowMFC/ER6MzjxQwXwSgXnxFKjc8xjCrFmzdFn+194wsMz1kQG0bB6odpc5dyxdCIO1wAsCgaKPPHPq1KkhQ4Zs2bIFY16HDh3av3//VatWoWW8y0rbtGnTF198MXDgwDVr1lBUZ4FqnKQA4SPbHTx48LBhw37//XeKysAJ6QPLm9Nph6T1p59+OnfunH7PBRYqp5MvDxo0SF1LpYFuo2DJzZs3b8CAAaNGjTpw4AA2tK/fc+RiS5Ys+eyzz06cOEGRcymSYKJE3Cfmzp1LB4YPH85IXceioOa3337DA3RgxYoVFLdt28bx/v37tYXDZvPmzd98803fvn3HjBmzY8cOrqjfE2IwkuG6IRmuE5XhFi9e3CR3QE9JwcglIUOGDOphjSfNjh07kjx+9NFHGTNmVJU8Nffs2ZMsAO9x4i+//JI6deoWLVq8//77pLqoHtBUmzZtXDNr7P/6668aNWrwjKmUkae2/Pnzz5kzR1s4ID/lipyurpUmTZrOnTu3bduWg2XLlmmjhw/Xr1//8ssv0wI2SO0LL7yAQPNapkwZleESvS1btuSxGkuKOK1du3akwEht2bJlnY+u9LxXr16uGc3JkyebNGmCgeokg23dujXjZWjz589XNhcvXnzvvffokvpYkFc81qVLl6NHjyqDsEiGa4lkuEK0B9VAykkYScd4dWXjxo07d+5kvSlLZCtJkiSTJk1aunTp119/ffr06bVr1z7//PNjx46tW7cusjVu3DiUd+XKlTly5Bg5ciS5p/OvEBz8+OOPvIXqceIff/xRuXLl7777Du1m5SubI0eOdOjQAZvmzZvv2bOH3HbixIlEMDpIpbLBmIyVPJR7CVdHr8leSTYnTJigDBS7du169913uZ188sknx44d46BSpUpk1nv37lUyrUCOGRRwjB8SJEiA8QcffJAlS5aff/6ZxkmQOSYfR0nVKSw2DKZPn16nTh2SVsZLs7iOXJibovoQkD7TQxzVuHFjenLhwoUNGza89NJL3377LZWqHSHGIhmuG5LhOkGJ8uXLpwMlPHLnzo0OKmNUMmvWrORxCJyqgSlTpiBbqNKff/6pqx4+nDx5MpVDhgxR4UGGS66XOXNm1xPJAUlmyR9//fVXivS5d+/eXHHgwIGus4Pi58yZE3VWaSktkEe/+eabFJ1Rjd7lypWLjqkM19kUD/LKgAbx3ueff07lK6+84sxw0XcydG4tFIkfMlAMyF7Resd5oZDwJk2alCRapUsLFizgrkNK68xxmHGkHw8kTJhwyZIl1BBgFSpUIL92zcjQ+hdffPGtt97yFCGS4VoiGa4Q7SHokcJBgwZ988035K2ukI3269cPTdSmjs890RGSNV1+6imEBs0qVapU4cKFddVTTyF/qI8KSlXDVZBXHtVVEZDgRo0asTjRO4qkkyTUzzzzTKtWrVTKqaDZmjVrkksiWBQRXNSwadOm9IrOKBu69MYbb6hjIKPctGnTc889x4mqhqvTZr169bhhOLsUFvUWZyVPnlzVAO0g5adOnULfKXJ7SJw48TvvvKM+rAAWKsN//fXX1ScMQDqPT+jw7Nmz0TVVmTdv3jlz5uBP8mhVI8RIRHAFb6AymTJl4rGd/K7rf+nWrVuLFi1c/59UjFE6xFSXH4lUtmzZXHWEY57cnQIEmD3//PO68Ai0DCkky0Y6SXgRNaQNbV2zZs3qR6ikGF3+999/MT569ChpILqsm3DAhfLnz+/8rCAoKAhRpnHXWwWNcF8hnVcdDhfeQmrTpUvHhXSVQz1pmScMKlFPeou7EG79tuMsHFKsWDEkWDVORkyaTGX79u2zZ8+OD3/66acDBw5w1gsvvOD6mYYQ85DZFSxAJlwlxjteBMtJWBtqEDJdeATP5oiXehamA+jmtm3bqlevXqlSpcqPKF++/MiRI1HkkydPonqIKclj2C8vp02b1qnvNMgTItLp+rVK7CliZtl/NwNVVI3zvEzajpI601snbjJat27dyZMnk8JjyQH6W7JkSZL3tWvXut6HhJiHCK4Q9aAyaKUuPALxIhUNCAhQuSFyVq5cuWXLlq1YseJnF1atWkVN8+bN48aNS3qrPih3ky31dQh1jCLD9evXaVDVAPYUMdPlx4IO0NW7jq8A66pHuMk0eXG1atV++OGHlStXLly48KOPPiLVJc/lMYJUVxsJMRERXMEvIEXVR49Q3xkoUKAArzz+p0+fHk0kpX399dffcKF06dKFCxcmF0bFnnnmmUuXLu3bt0838YjDhw87k3TayZIlCzZqzwSFUnzMniTBJCXPmTNnYGAg9wld5WiZBHz//v0IsarhgMFeuHAhQYIEL7zwwltvvTVo0KCNGze2adOGDmzZskWZCTESEVzBGl9/sEhuuGTJEtfk7vz581OmTEFnX331VYoZMmTgoXvz5s2zZs1SBgpkq169ehUqVOAtipUqVcqaNSsnInnor7JB7EiBnTlm2rRpsUfa5s6dq2rQRDpAsnnw4MHHHint0w43gKtXr86YMcP5JztUdceOHYyOu4VS8zNnzjRt2rRt27auCTW5eY4cOehzUuOtA4ToiAiuYMHt27fJB//555+/w7Bnz55Dhw6FhPlJmF2QOSTy3Xff/eWXX3jY3759e4cOHThu1KjRyy+/jAGy1aRJEzLTHj16fPrpp//++++NGzdIBt977z3E9MUXXyxWrBhmRYsWrV+//po1azj9zz//pKm1a9diQz+RVMelQuWVZgsVKvTJJ58MGTIE+UO1v/32W4rqXWX2eCC41apVGz16dO/evY8cOXLt2rWFCxfSgaNHjzo/MubmQSJMfffu3fEhnaQDEyZMGD9+fN68edV4hZhKqODaCrInjEgvxIaWfdcTWxh2Q/2pCqktV65cwYIFeXJ3A9lCvFSmhjHKS2bn+nklRXBTZGqUseoGRTS9b9++2bJlQy555H/llVdWrVrVrVu3wYMHO7/zgJj++OOPPIMPHz6c65KoVqxYEbPWrVt/9dVX6ssSGPfr1+/9999fv3595cqVsalZsyb9adCgAe9yIUdLT+XLl2/cuHEFChTgWT537tx58uQZNmwY9jSOjbP/PPvTT3UWlc4BunqPSnB+aEs3vvjii6pVq6K5tJYxY0Y6g+tatGiB4quWEydOzD2jVq1aM2fORF7TpUuXK1eunj17cjuhGzhBNeVG2CkznER/w3fdttVyVHkvzsWLF3mQIYNwXSfhQhfVlw2dX3DxDtEJYf9kHC5E7c2bN5Mb73dFXuD6dUjvkGgYGjNGjJMkSWLyaIkxeRaucz69egHjW7du8WriPcxYw6xtemLiECyZmmRmOzZhQ7fRNVY7Pt+9ezcd0++5wKBOnTqFMB0/ftzTPkk8JiMWKCNPxKS6Y8aMeeaZZ0hUlbjQAhncxIkTuRBKqk7hLR7nR44ciVwCA+SRn+SOp+znn39+0aJFaCV9e+2118qUKYOx0jvlPfSUDq9evXrz5s1BQUHZs2enhVKlSmFG/Kj2mTguvWHDhqVLl2JTvHjx2rVrcwlabtmyZZEiRdTfyhgR7y5btmzjxo0cV6pUiaboKm4nO06ZMiVqO3v2bJLoLl26PPvss5xFkeuq73KpqOa6p0+fJjtGJVu1aoWS0hSjvnr1KpfjXBopW7Ys2jp06NBRo0bNmDHj9ddfp5ITmQJGSoO0EBAQULJkSYbM6YQHg1VjcUI9DbZp0wa/NW7cmLnGhiWAMU1pI89gjN98scwxZjg4x0eBGk2XOc0Sq+GOMfRvBb6YCRDBdUXNBK9+IrgkVkpwedwOV3CBxczoMPbywSKtqUxQGaM1qAP9V+8qAcJGRY5CWXLKpUuX1JeoMCNUqKFencuIaFbZA5V0lROVsXN2MONEt1HzLvW8KldjwImALnCsjRxm6nLUKzWnZerxvGqQGmzoBq1RxJhGGIgKJ2WDgVpaKslFwffu3UvWj0ZTBAKVcbVt23bNmjW//PJL/vz5leJzoutAVD+vXLnCJDq95wRLBJc7GYLbpEkT+oCNCK4b0UJwQ3uJC3jPBKaNa+uCFYQgjeuCFcyZT3/zxym6YAXdoDO6YAVP0wScLliB63CgLljBpBBtumAFa9UXP+1V+O4Xk/RZyaUJeMM8UAl680BlBtX3xkxwei9cfvzxR9bUBx98QAdUDcaLFy8mZyfPtewSxp4CdcmSJfLTXu/4LlDtLnPn7IfFWuAFQTDktddeq169+pAhQxo0aPDll1+OGDGiU6dOTZs2TZkyZa9evUiptJ19WKv6SIjOiOAKQoSRKVMmnvo/+uijAwcO9OzZs0uXLhs3bmzVqtXs2bNLly6tjYRYjAiuIEQkOXPm/OyzzzZv3nz8+PGjR4+uXr16+PDhhV327hFiMyK4ghDBPO34aVz27NkR33Tp0pn8XUuIJYjgCoIPuf/oy7+CACK4giAIkYQIriAIQiQhgisIghBJiOAKgiBEEiK4giAIkYQIriAIQiQhgisIghBJxLl06VK8ePE87m3jgtoIh4PEiRObGN91YLgz0P3792/evBkQEGBijM21a9cw1mUrgoODDY3pNsZJkyY13Ebo+vXrCRIkULtMeQdjBkizhpsw3blz5969e4Z7rWF5+/Zt5xZW3lHec90tTO105Qlb3rt69Sozbug9uoE3DDdhunHjhnmg4o0HDx4YbmEVEhJiHqg0S08MAxXseo9J5EBXPULtFtaqVavRo0c3btyY+cKGlhmg4W5hKlDBxHt+tcxTpEhhYgzRYpnHOX/+PHFs2BZxzIGJZAAqQCgbBj1xzDSb79tG0GOsy1bgL0Nj5VxCzXAmcC6uM5QMvMeroWQQxESnSdADlixCQ3VW3suQIYMS3F27dqkF5glb3mOF0A0OdJVnsKEbeMNQMugkloaSgTeIKEPvEah429B7tgIVzL0HGIfrPWJs8eLFbdu2/fbbb59kP1xfLHPWOA6M2cucbhB4hsucAdKst+0ZiU7eM4FpA12wgmZpXBesYM7MNxhk2mzt2+Zl17uw2N31jrWqC1YwbUyGLlhB0BMTumCF3e0Z1RZ5htsz2nI1LdO+LlhBlhEdt2c032AQIipQw27PyIzbCtTYsMz1kQF2AzWilnmowPOPEl8TbBnbIja07Lue2MJWN/zE2H+IkjGGbSc2eM8WUTIvdrHOqAVBEIQIQQRXEAQhkhDBFSyw9f8UJE6cOI7BX8wUiRIlMvmrhcLwrxaK+PHjY68LVsR1/FdpumAFo7PlkIjyHsMxd6zgt4T+WZnoTPjoP6P2jvow2DCG7jow/Lvh/fv3r1+/rv6za0vow9WrV1OmTKnLVly+fBljw3ilZfps8sdfwHusVZM//sLNmzfpA4tKl71y59HXwnTZK1jSuOF3Yh48eBAcHIxDXnnllQMHDnzwwQch//1vzN1g0g37DBjjEBNXY4MxOmL4l2IcgqWh5qq/xZl8IQSIPRxo+Ed5bG7fvm34R3mIEO8Rjbt37160aNHEiROd//+xrUBlceFq0GWv0A1eDbvtV8s8VapUumDFlStXWC+G93u7y5xmsddlN2jL/I+/tGX+x1+7f740/+Ov3T9fyn8i6QpBr7xXsWJFHQRCdCB58uRz585Vkwi2ApWV6CffUvDpMtdHBtBylHxLQTJcd2JPhovDUWpLt7BCDF1NUxijC4ZJK93AG4Zfb6S3WJrkoRgTqAzT8Ku1OIHbm+G38WmWScchJsZgy3sEKkuAA10VBpaeM0uVDNcNvOf/Ga4IrjuxR3B12QocYjgvgLGh4ALeMxRcYIBMimGgqoc2Q1cjuHjbMFDxHoFq6Gqw6z1a9kWgiuC6EVWCa3Q9ITaDxOgjA1gk+sgA3xmD7xq35RDfeU+IjojgCoIgRBIiuIIgCJGECK4gCEIkEfpnZfVHM8vPj+I4/viLmcmXEDG+c+dOSEhIMuN9227cuJHCbCs2bNSffUyMwfxvEdiov0WYfJqO8bVr13BdArMtrJx/NDMxvn37Nj4x/Dv7vXv3mBrGaGKMjV3vGf6Vg2777lsKhEdcxy8UTLyHNx6YfUsB47t37xKrdNvEIeqPZoaBCna9Zx6oeI+VaPJHM4zps/kyJ1A58NEyV3/dNTHGxneBGlXLPE5gYCARbxj0OJdWTIIeUAEw0RcgjpEYQ33BhlEZ/gUfWKuGxoyR0KTPhjNBN4hjQ+8xQF5Ngh4IYqLT0HtYMjW2vGe4QsCu91ioHOgqz2BDy3jDUDLQUCwNg95uoOJtE30BApWe+MJ7gLEt7zFAw0Clz7aWOQeGgSrL3BWMvS/zUPEO/baIH3xfBH9x69NlrzASblDm3xchceDWhxd02Svq1mf+bRs8GyHfF3GDoCeODQMISxo39B5Bz6Qb5gKA98xdjfd89LUwwgNLvK3LXiHoGSbipcteQW2xp9u67BWfes9WoJL9ER7mgRoblrnvApVlGyHLPPR6JncbJ7aMbREbWvZdT2xhqxt+Yuw/+MkYY4P3bOEn8+IdI4EXBEEQnhwRXEEQhEhCBFcQBCGSEMEVYiDx7eyHKwiRhgiuENMIDg5u1arVb7/9psuC4DeI4AoxjWvXrk2ZMmXfvn26LAh+gwiuENN44Nigy/ArloIQmUhQCjENEVzBb5GgFGIaSnANf68lCJGJCK4Q0xDBFfwWEVwhpiEfKQh+y9NE50MHHHhH2dgydj2wxNGwqTHYalkfWWG3A8re5Cynpbmx64EJ5sahnbBjrI+ssNusLWO3A08Q0/fv3+cVS151rWfMW3aCpS1jfWSFuSU4umC7ZZNTfGeswNLcGGy1rI+scHTBdrMmp1gaxzl79mzorm2yb5sDxoixrV3v4sePb7jBIN7jNYHBBoMQEhKCT+iJiTESc/fuXcMNBrGh24Y7aYG594B5YcYZpi57BhuM8Yah9wgPJsVyxyZa++eff0qWLDly5Mh27drRef2GZ/Ae3vZFoIJPvcdKNA9UP1nmNB7lgcoYfbfMVaB6Wubyv/a6Y2t7Rrv7ttEHQlOXveLT7RnVvs66bIXv/jNUtYW2iQoAKwRLk0Ddu3dvgQIFvv/++5YtW+oqr9jdntGn3vPdPqJIAOiyV1jmvBoGql8tc/lfewUhslEfKRjKliBEJiK4QkxDPcqJ4Ap+iAiuENOQDFfwW0RwhZjGA/keruCviOAKMQ0RXMFvEcEVYhoiuILfIoIrxDREcAW/RQRXiGmobykYfsVSECITCUohpiHfUhD8FhFcIaZBhovaiuAKfogIrhDTkAxX8FtEcIVoz+XLl+fMmeP8XyMfPHjgmuH+/vvv8+fPv3nzpioKQhQigitEe4KCgvr37z9w4MDbt29TdBPcCRMmvPfeeyrtFYSoJXR7xrhx4xru23b37t2HDx+a79tGlBtuMMgi8d2+bWQ3hsaMEWNbu96Z79tma3tGu95jagy3yPO19+gzB7rKM3a9h5h6ClTmq2vXrlOmTJk3b16lSpWWLl3auHHj77//vmnTpitXrqxRo0bLli2HDRvmSXOpN9+eERt6YhioYO49wJhuGHrPVqB68Z4bGNvdnjGaLnMfBarFMr927RqTwXsm0MsbN27oghVcmMZ1wQqm7cqVK7pgBdPGU6QuGHDp0iVO0QUr6Aad0QUrgoOD1U3IBFyHA3XBCibl+vXrumAFenH16lVdsILlYdd7+sgAWqZ9XbCCPtNzXbACb3gJ1B07dqROnbpTp04cL1u2jOWxYMECjocMGZIqVapDhw45rMKHGWQedcEKX3vPR4HKSmQ96oIVRKl5oPrVMtdHBtgKVLvLHIHWhTDIRwpCTKBIkSKvvPLKxo0bz58/T9JHikE+wtr+8ssvmzdv/swzz2g7QYhSRHCFGEKLFi127tw5Z84cjhFcHp9nzJjBQZ06dZSBIEQ5IrhCDKFs2bJZsmTZvn07T7ikt0jtTz/9lC1btvz582sLQYhqRHCFGEKqVKneeuutWbNmHTx4MFGiRDt27Dhz5kzt2rXTpEmjLQQhqhHBFWIITz/9dJUqVW7cuHHo0KHEiRNPnTo1MDCwRo0a+m1B8ANEcIWYw4svvli0aNFNmzaFhIRcunSpsAP9niD4ASK4QswhR44caO7Ro0evX79++fLlevXq6TcEwT8QwRViFPny5bvn+E/j7969W7ZsWV0rCP6BCK4QoyhWrFjKlCk5yJQpk/y5TPA3RHCFGEWJEiVSpUrFQaVKldBcVSkIfoIIrhCjSJo0acaMGTnInTt3woQJVaUg+AkiuEJMI1euXLxmyJBBFQXBfxDBFWIa6qdl6pNcQfArQrdnjOdAV3gmjv1928Bw17sHDx7cvn2b50ETY2xu3ryJsS5bcePGDUNjxohxokSJonx7xpCQEHxiuOvd/fv3796966Nd78y9B8yLrQ0G8Yah9wgPJgVv6yoPYHnu3Ln169eXKFEiT548RKB+wzN4z3x7RluBCj71nvn2jMy4nyxzGo/yQGWMvlvmKlA9LfM4V69e5T0T59IWc8yBib/UtKECyZMnN3EuQY8LUqRIYWKMDd1OlSqViTFcuXKFlumSLnsGG4yTJUtm6Nxr167hOhMNxZgBMhMmoYkx00Yc0xOTMWLJ1Bh6j6Cn2ySA5t4zzBaV95hxwzgODg7GG4YqcP36dSxN7kBcndgjogxdTZTi7YCAgCj33uXLl80DlSWAvpgHamxY5r4LVAIvQpZ56Ewg3syErvAKSk8rhvccpgGQDF32CjPBimImdNkraiYMnQvEMcb4Qpe9QsuGggt4j5mwTLsUxDF9YCZ02SvEMTJqeMdWgotk6LJXkAwCyJb31N/9TSCO6YZJHAPdIJZMBBeIYywNAxUBZZiGgUp6iz3LT5e94mvvGQou2ApUFhd6AbrsFZY5r4aB6lfL3EeBaneZ0yz2uvxfjK4nCIIgPDkiuIIgCJGECK4gCEIkIYIrCIIQSYjgCoIgRBIiuIIgCJGECK4gCEIkIYIrCIIQSYjgCoIgRBIiuIIgCJGECK4gCEIkESq4hr/dVtgytkVsaNl3PbGFrW74ibH/4CdjjA3es4WfzIt34gQGBsZzoCs8Qxfv3Lnz8OFDkx2b4J4Dkx2b4IHfbM94/fp1+my4jRDdiB8/foIECThWON9SB06oYYC8Gu7YdPfuXcP9rgBLpsbcezjEcHsnwCGGW5PQ7WvXrtGNsMMPCzZ0A28Y7nd169YtLHG1iffwBhFl6D2iFG8beo9m6QkOiXDvAcbm3rMbqKxxk+1XMCZQOTBc5iEhITjQ09ZizkoOQO0TZB6ofrXMDUXS+zIP3aaMtgxVwLlbmIkxQY9/DUPT7r5tascmE2O4evVqQEAAXdJlz2CjNmEynAmmTW1Jdf78+Q0bNixduvT48eOnT5+mXtkIUYVhbAi+g0WUMWPGzJkzFytWrEaNGvny5UMQWeaGmvAYy9xwHzK7y5w0AoU0vNmjzrx6utnL9ozuqJkw3PWO6Pn3338nTZo0ZcoU+v/MM8+kS5eO08PdnI1EgD4YtoxDGKbJTRVIu7A3yV+AZrkRGu7UB0yiLWO6YehquoE3TIIeYon3zI3pBgM0dDXew8+GxniDV0NX4z0I19X4igXCujh69ChP0kWLFu3evfurr76aPXt2beEVTre7zP1/e0YRXHfMBZcUfsSIEd988w334caNG7/55psFCxbMlCkTN7dwr8UKod5QBXAIcWw4x1iyogzXKt5jXgxnHHhE8hQ9YcEndMPQ1XQDbxgGPd7D0lAF8AbDjI7eM28ZYwZo6D36jOvMvcereaCCJ+/xFqvj0KFDW7dunT59+ubNm6tVqzZs2LDnn39eW3jmMZa57IcbYyGCe/To0bt37xdffHHNmjWjRo2qVatWnjx5uBt5khskA3TBCoKeS+iCFUiG+tzNBOKYG6cuGGDXmPZ1wQr6TM91wQq8oYTABCzNXY0oIF66YIVfec/cGO8xTF2wwlag0qyXQEXiEcESJUp07Nhx5cqVLJMNGzaQmvz888/aIpYhgvs4EI6o7bhx49q1azdjxoyXXnrJ8O4nCLGW5MmTI7sLFy5MkyZNw4YNN27cqN+ITYjgPg6jR48eO3Zs586dhw4dav5XVEGI5ZAOv/zyyz/99FPGjBlZPkeOHNFvxBpEcG3zzz//jBw5ksei//3vf/HixTN/UhMEgafD5557jhW0Y8eOb7/91vwzpZiBCK49Hj58OGHChKNHj/br1y+R2RcVBUFw47XXXiPDnTRp0s6dO3VV7EAE1x4XLlxAcNu2bVusWDFdJQiCTeLEidOiRYukSZNOmzZNV8UORHDtsXHjxjt37nB/NvyGjSAI4fLCCy+ULl16wYIFsepTBRFceyxZsuTZZ58tVKiQLguC8FgkSJAAwT137lys+lRBBNceJ06cSJs2baZMmXRZEITHJWfOnIkTJz516pQuxwJEcO1x+vTpZMmSyVfBBOHJIXeJFy/e2bNndTkWECq4hj/EVNgytkW0aFltY6EL9lv23RhtYasbfmLsP/jJGGOA99Rv6G/cuKHLT4afzIt34pw/f56bjMkPpeii+v2o4deh1M8rTbYWgwd2dr3DRu05pMtWXLezwSDGnvZtS5AgQY4cOYoVK7Z06VLMMI7AfdtcwUz9FtPTnkNuYHlHtmd8BMZ4g4gy9J76FbWh92wFKph7DzA29x7GrERD7xGoPlrmrHEc+BjLnM5s2bKlQYMGXbt27dmzZ9hfV2MTJcvcDYzpBoFnuMwZIM16WuZxLl26REOGKkBbHJjEMcYEMRiGJpJBTAQEBJgYY8PCxliXrQgODjY0ptsYE/SeBDdLliwI7pIlS4gPjJk2Kg3j2LmrhYn3aJ84NlQBLFkkhhqqvGe4EybY8p7a+scwjtWeIIZxTNCbByreYG0bqgCSYR6oNEtPDAMV7HqPSeRAV3kGG1pmgIaCqwIVTLwXOcuczvz+++/16tXr3r177969wxVc3wWql2XuhtN7EbPMGRLRyXsm0BbRpgtW4EEa1wUrkIwrV67oghUE/eXLl3XBAG4qnKILVtANOqMLYcicOXPNmjV1wbFfJ9GmC1bgOhyoC1YwKUyzLliBZLBWdcEKgt6u9/SRAbRM+7pgBX2m57pgBd4wD1QkwzxQmUHmURes8LX3IipQ3WAlsh51wQqi1DxQn2SZ//HHHxkyZPjyyy91+b88xjLXRwbYClS7y5zw04UwWAu8IAiCECGI4AqCIEQSIriRR3wHumBFnDhxTD5g8jfixo1Lz3VBEIT/IoLrcy5cuDBlypQRI0aMdDB69OhRo0aNHTt2wYIF//zzz70wm2rfuXNn8eLFU6dOvXLliq6KDhw7dmz8+PGbN2/W5Uhn7969dEDt+Me9aufOnRQPHDig3vVbmO6FCxdOmzYtODjYp7dYboTHjx8fN25cFM6RIH80cyfC/2i2devWcP8TJ7LdHDlytG3bFlHQpg7obalSpbJmzbpr1y5dZYU//NFs3rx5LOn3339flw2I2D+ajRkzJlGiRLNmzeKYZj/88EM8PGnSJPUuEL0bNmwI+weNqP2jWVBQUMmSJZ955plDhw4xxoj9o9mZM2e2bdvGASuRnnOPZ4569eql3vWE429m8kez/0f+aBad4CkbRxcqVGj69OlLlixZ4YCkpl+/fmnSpJkwYULdunV37NihrR3/l1S+fPny5MmT0Pi/t/IHUqdOzRjTp0+vy5EOfgPnhzZZsmR5/vnn06VLp4qsxubNm/OcwVyoGj8BBVRfCFVxomsjAm7Yr7/+uvM/s6Fx5qhgwYIZM2ZUNULkI4IbGRDradOmrVixIgtA8dZbbyG469at69at299///3xxx+fP39eGSdPnvz7779fuXJltmzZVE20oHz58jzFk+GSmOiqqINMqkWLFihOjRo1VA3Z8ZEjR3iNPR8xk0u6blNAQle2bFl80r17d10lRDoiuJEEmqseAHXZAdqK1L7xxhtr16795ZdfdO0jbOU7tj7+i46iwwCfpNucq1ow+aWAd2y1YNln382F+gOmTz8XFuwikxHF8JTXsmXLW7durVq16o7jxzbBwcFNmjQpV67cyZMnKV68eLFmzZq9evWifsKECSVKlCBZrl+/vvo/+K5fvz5+/PiSJUvmyZOncePGW7duDW3UhatXr06ZMqVq1aqclT9//k8++eTff/91XYTz5s3Lly/ftm3bDhw40LFjR9LqnDlzcuC2aR7qT+Nt27bNnTs3fa5WrRrNkkPpt596avXq1c8999xXX33lbJxT/vnnnw8//JDHWK5euXLlH3744fLly+pdCAkJeffdd+vUqUPl0qVLq1SpgtlLL700cuRIZ77v5NChQ0OHDmWkKVOmzJo1K2fNnTv3hoef4ceLF++7777LmzfvggULKE6aNIkxbt++nefrgICApk2bMl569fbbbzMEVwElDeTJg7dcP+RxZdGiRa+++iqPJj/++CNtFilSZPLkyerWePfuXZ5LmLtMmTLhww4dOoSdDiz//PNPRp09e/YCBQqMGDGCDtBb9S6uw+Drr79+5plnSEVVpYLZyZEjByeqIAHOunbt2rRp09TkPv/88wQJT0u8hWOZQR6kcOxnn32WPn36b7/9Nn78+HQbn3z++eeqBcXRo0eHDBmC29OkSVOmTBmcHxgY6HoboIb6ffv27dmz55133sH5THSfPn3279+vLQRjRHCjHpY3QYygKP3ikZyIP3v2LBkxRV5Rn927d/O0juJkyJChaNGipMO1a9dmqffu3ZtFmyVLFtYAWsATNIvK0Woox48fZ4U0b94c7eZxkqtg/Nprr5FQawuHZJ85c2bWrFlvvfXW77//jqCjuSgUkrpmzRoM1NqbMWNGpUqVuO4LL7xQoUIFTqFZHtu5HziaCf3v+E+cOMFdQRUBRa5YseKYMWPoMyJ16dKl1q1bN2zYEBXWFk89FRQUxA2A1dumTRu0BjP607lz5/bt27tq7pw5c3gOoPPIJcKNVG3ZsoW7zgcffHDbw/8Pz52GUStFxj+lS5fm3HTp0tF5hsBtA+nBVyiU6+0Hj6HRdBgDXfVfuDUeO3Zs8ODBX3zxBTc5nlGowUVcDr2jk5s2bcKHzCnTwfCdcgzo4Lhx47iVLly4kCFwCXSQgSN5rqJPGNBzp7AqOJdKvO1sDb9xw2AWmAsmFzmeOHEik8uti9bQX+IEkeUq5cuXV3+2ZY5oxPU2uWzZMu5ziHKSJEkwI/a6dOnCDf6PP/7QFo4MALfQODc5ovTll19OlSoVw69Vq9Zff/1lK98X5FsK7tAN9ewfLo/xLQUSK5SOda5Wka514dy5c8WLFyepIWWgSAdYA6wQtEC9+8orrzBTLGbim4Gw9r788sukSZOS6zVo0IC8g0rkadiwYWQ9nTp1woATcT6CyIldu3ZFCqnh6ix1lmKhQoVQPWoARUicOHGKFCk+/fRTGqGGQaHsnIiiqRlnvZEB0Ul0X/1t9/Tp02RbXI6k29HMwyVLlrBouZYqItYkwuSALGn1R1tuIR9//HGCBAm4Vag/KCMfdevW5UKFCxfGTMUhqdybb75JJblbaEMPHyJw3E7wIVKohsZA0EqVOOMTZUZPkiVLNn/+fI4xGzhwIONyNoIqoYNohGoBuKnQf8yoYciqkqyZRkaNGqWKYZk5cyZ9y5gxI3pKkRO5Q3CAx5Ae2mfWmA7gloD8od08uzhOfbh+/Xqkn25zw1PdwIZ7DA3y8HHkyBFcjXsHDBiAl0iE1VkKZhlZ56aonMlrs2bNuFVwy2EuqCEOeVjBIcWKFWO+qOH2SdL6v//9j2OCgZaXL1/OHHEKNUASjUzTJbykRsH9j3sAwcD9ScUMoK30kIAcO3asWncXLlzo27cvld26dWPWHnuZy7cUBB/i+pjmSsKECUmUmFEiTNW4WTJPvPbo0YOchbeQCdJPnlsJX+SVXInQQX8RL9rZu3evSvpYsYggEjBo0CD19zeWsfpjHTYsztCmHdfiukh8z5491d/0aQSlRhfIvIhLLocQI5ckhlxL5YPceBBcde9xNPOfPjMWdBxZRIZ44E2UKBGViBSCi4ijm7/99puy5NIMH5nGTH0rg8STpI+uOr9Ciy4j3O3ateOWQ2eo4V3yxOrVq/OWMxFWHXBznSt0lcvhK1WkBa61evVqJECdRbfxGCKFN5RNWJSl+ssnB/gKz6OVPAGoT1TwEjZAJkgizFx89913akbwOeKI/8kl1UCwwUXcOJ29UueqY1dUpfNd7nzc0ugD6slcUEMySwbKEw/dQCCoUYKigkqdpXAez549m2cp+tOkSRNGQQ33SCKqbdu25OmLFy9WZmqK8TYPKHSVY2S9ZcuWzz77LHPE0Fwbt0XoYOLEcYZQbOBpgoyFgddQZe9ggyX2Jsag7M2NzVsGjPWRAWQTEdINFcFqbVA06TPGOEGdpbzhZk8lt0TawYa3MKNSXYK3eKUSYSUDIgWmhncpUs+KRUbJUFQfgCWXM2dOBosNr6wZEhbWJGuJxhWcWLJkSZIaJI/FRg2nE/TkvJwe2iHHuFA0BJ3HZBQNA5YZq5o8iIyGVPTw4cP0BLFgxZJnqctRQ2ssb7rH0+7GjRtz5cr14osvcrpqFsgBa9SoQQpJrscpvIUxq5elqwYO1PDESpKFNqkaJGzOnDmIstJ6roKg8DTAzUB5iaacHeCVPjAEJTTU0zKvqkZdhWPM0qdPX6ZMma1bt3Jn4qLYIB90m+cJ7g3YqKu7otqhWZ7TuZayoXLnzp30BxnF/6qHwAEPEzwWkEjiMTy5Y8cOaooUKcIpqkG6wbRSo/qMQ3ik4JVzVVGZcaCu6wwPmuJOQ3ZMxqpsFHjpxx9/pE1GROOcwrlcjmNa4JWOqRpSfm42zEWpUqUw1uc79gkjMWdScAWpK29hz71Q3eydQyZCiAoev7hdqe6p0y3hXGVMyxzQH2oYvnrXDVrWRwbQjj6yguvaMjYfIGY4WXlbV/2X0A/pBVsQkaALZng/hTWGdhD6BLGuCnMKb6FWuuDQNV5ZFVSqY1WpzgKimRXFAcuvngtkwZ07d0aIWf9KsDiRV5WEqnaAplRrHBOaCDSPkIg7z5u1a9dGNBs0aDBkyBAyO/URnjqLA2BZ8nDHoJBRBoU6qHcV9JlKLk2zqoYW0Hp1rODSvDqbVRw8eHDMmDEkv4yCPpARkzmqKyoD12OFa1G16TygVwyZlJlL88hPkW4jMXiGpwfectqHhbkgE1SpmYJ7A2ts7dq15O942Onqd955Z9++fcgW4sjdizscKu/qE66CYnJncu2qYxz/GYhCVfLK5PLwgQqg+27uxaugOq9e3ZoKbdoxR9y0GCz3bG5vNKjfdpzF3Y5O8i6XUKczRyo4nW5RB65OeGzUJWIJoRvlJnbAxHsHGwIRTIxB2fvCGOi2PjJAjVEXvIKZF2OSSpIsJTEUTfrMKRios5Sxmz2VLEXEEVED7KlUz5v0hIDGnnNpQRnzikZQSQ3vqkqKGJPJYglUUqMa2bNnz4oVK1a6sG7dOs4lPWEJ0QInYkabwInqXF7VRVXLvKJxPMMieWRV6AvPmx999BGqxzM479IU3aA1NVLVc/oTEBCgWlNwCSqxUcPkFHUVDlSNslFNOWtofMSIETzS8vA7ffr0X3/9lUyhRYsW1NBzjDEAdVHVJhd1+pAD3qUd6lWbqktciOSOuwIOQX14lwO0jwEq+7A4rhO6ETWCq9zirORaiKCbq5Fy1BZXhzo3fnykkO4lT56cV9UgLSBtGChXU49/aI2B8C6XUGbqgEuo/lNEZymijBg7TNzhcjRIO47ehc6Oal/V0A6NcEwLrv0BdQk1j3SGIvZci1faVDYc05qaO9Usr+otS5x+Uz2kBQ5oSr3rhtMDJpgbc127xoYDxAxveHGIfkbj1RBbxraIqS1jo8w8GbPOeS4rXLiwc/vkcC0tKzl2QlGtqwULFlz/L4gLCRfpmPpDvDJ2w7XSeUyG26FDB55DT548ic6SviExn3zyCa+uZqBU49ixY8iNrnoEV+dpi4jkmFMU6i1PzJ49G3HPkCHDhAkTTpw4Qea1adMmrpsvXz7eJdVSZqodZ2thi85jJ5kyZUK16f8///yzf/9+MlxyXm57+m3PuDWlhjNw4EDtYhfIamlcPftnzJiRBws3n5Aaqz9PcezoowYvKQOFMwlVRbzBKx5WRSc84+Mc9b+EKWPXV4U6RhGAUXO/V/VOeDpRc4QiU3Q91xVny54MwsXVWJ2rrvLkuLZsiS3jCET+aBZ5hBtYrPbJkyezfniS5W6vayOCIkWKEFW///67Lj8CCRg2bJiXL7G6Qbf//fffsWPHOr8qRFqETlHDq+ufrZwgZHnz5mUxHz58WFc5QBw3bNhw6dKlAgUK6CorEBoya1KMvn37NmrUKK3jvx2kHkVQP6PiXuUwNMVtFipXrozb8dJvv/1G2lilSpXHWP/58+dHpjdv3ox66ioHZOLcJH744Qd8TlL8/PPP79u3b+/evfptB4gjTyG64IBZw1EXLlzQZQfHjx/nlb4ppeBmwyxwoptwTJs2rU6dOtw5dNnx3V599F/oT7FixbgluF0d/vzzTx65ChYsiNt1lRBBiOBGEiwVQt91MbO8Dx061LVr17///rtp06ZlypTRbzwxahHSIFnzqFGjfvnlF+eyJHn58ssvSQ9ZVIbLCYFjtQ8YMGDo0KHqY18FUovkkZWrbMsVnpHr1auHAaegNbrW8eOIH3/8Ed2pWLGirrICp9GBu3fvnj59mkdyVYnrfvrpp+XLl3PspnFewPmomJs9LipVqtSyZct4FHjRgX7DDoyIHHb+/PloK3cIVYnPkT/ml3sbQ2Agb731Fok/dzv18TowLhxy8OBBJYucwgH+pKvcmZxdZewTJ07kwCm4L730UqFChaZOnbpy5UqHSSjcF6dPn86MoJW6ynF/5dU18BT0pHbt2sQDc0Qc6tqnntq+fTs3CZJxMgBdJUQcIriRAauIp78xY8YMHz78iy++YMn179+/bt26RYsWXbx4cePGjXv27MkC0NYRRK5cuXgSR1VZVx06dJg5c+b333/PRekDEtO6dWuVKlpCtsXyrlmz5sKFC1mEjGLevHkjRoygWZK1zp0758iRQ5u60KRJk/feew8NevPNN7/99tvZs2czRjJiROTjjz9+9tlntZ0VuE79aet///sfw5kzZ8748eNr1KjB8XPPPUe9+sOOJUmTJiU73rFjBz1fu3YtuaeznkHt3r171apVNMutQtXbIlmyZD169OCRomPHjg0aNEBDuR+0atUK5+TMmZO30qRJgxnZdPv27blQ1apVuREijg0bNuSAPjgFl9cKFSrwfEA/27Zty6xxg0SpSUWzZ8/uvHEiyt27d+e6KnjQ9K+++uq1115Du3kUUB+2pEqViutyOcRa7RmmznXC1HDr5cGFefn888/x7aeffkol+kufmXRtJ0Qg1+SHD/+Fbrj+0daNx/jhA7GufufjBs/dLCQezN2+sM3QypUrly1bNlSAIo+c6pdLPLkrAyCXQW5KliwZFBREkdQPV2OAGanW1av/v1UjT8qsSfVVTdIczmIt7dy5U7/t+P6/Srt02QGzTBKKLPIIzFKnhm6Q5BYoUACNoyl0HF1AWZzBgxzTTpcuXVQRGAhiQeeVsqN39GTNmjXOP6yTb7K8GSlZlapRrF+/HrFAsFSR0U2ZMoXBqnZ4Fq5fvz7J8rp160jEuHNggNm4ceMSJ06MsqtTuKXRSfVDLwXqz7M/LbzwwgsHXLbE5AnjmWeeyZo1q/PHIF4gaaVZMllddoHTyWdxmkon8XmzZs1+/fVX/bYDpoY7Fs/ycR1/euWAuyARhcIePnwYV6tAZWi1atVSn+lncXxFZP/+/dwmuSVwq1BNMeOYIdk4BLNEiRIxZYimM3qxHDRokNJ6JJU5JZFnjvr06aMMgBVNPku8JXH8UY4rch/Fh66LkUYYMgPXZQck3cWLF+cew4GKEBPclnks/OFD6P+cyhLCobjbEtWQmhtL6CJwE9ZlrzB4pi1FihS67BX6QOCaJyM4F+OwT1XhQsv0Wa2HsBD9xNmiRYtUEe8R6EqDPEFMqy+uok30AXv6T/sMlmgL6x9cgZ4yx7kduxagHZxO8KGVzpyU1shluC5KQSVxzFVIlNARciXWvGv/MeYZFmnmrfTp06svmTqvSz3ZN3Lj+skAl1N9pimMlavp9rlz5y5evEgN10JQXKeAhXTkyBFGx/O109Wcgj1n0RTj5SpoonoLcDU6TpAwCtegIhJIstBc9bVWxfHjx7mj0DIXRaOJWKIRM66YJ08exot8nzx5kryeE+khQ6ZLZN9KcYDOoA48YiM6XNHZEyzRfbrNE7r3qQSugrByY1My5wZzx4joJw7kuriIqcFX+u1HYEBPOMAAtx89epQhM7+MCMlT3qOG4fCaLl06/MYAmVxe6bkyIEKYRLynfq3LcDBzWxS4nXdRIoZM2osxHuOKWGoLB5yOE1AKrs5bRBS+wrHqXUbEuzjWdciEJU3REzzMYB9vmf/555/cbHr37h3uBmb0we4yZ+p1wQqGzGDVg4UlJsvcCSuRZp3ec4e2iE7GZoJkuKwQuxmuE/yMT3TBCozNXU30E5q6YAVB77vEAe/Rvi5YQZ9VcmoCsWfuPZTL3HskdDxtqNTYEiUZumCA3bQrogLVDfps7j1cDbpgxZMsc/lpr+BDmGDQBQOYHn0UffBdn5US6UJEQKp76tSpjRs3Dh8+nLRRbVhhAjcJfRR9iI6xFCMRwRViKRs2bChbtmz16tX/+eef9957jyRXvyEIPkMEV4ilPPvssy+88EL58uXnzJkjX4ESIgcRXCGWUrhw4SVLlixcuLBSpUq6ShB8jAiuIAhCJBHnsmPD04QJE1p+rB4nTpxbjq+LJ06c2MT4roNkyZKZfGB///79mzdvBgQEmBhjc+3aNYx12Yrg4GBDY7qNsfOL6G4kSJAgS5YsRYsWJTNiaBhfv36dSpPvi2DMANX3RUy8d+fOHfWNIhOHYHn79u3kyZObey9FihQmxmDLe+pLdSbftsGYbuAN53fdvIDxjRs3zAMVbzxwbMRlMsYQx0aRhoFKs/TEMFDBrveYRA50lWewoWUG6Pr9P09grAIVTLwXOcuczmzatKlOnTrdu3fv3bs3jWijR2Dju0D1sszdcHovQpZ5nPPnzxPHhkGvvlliIhmACoDJtAFxzCIx1BdsGFXYrzd6ghViaKycS589CW4uxx6vS5cuxUw5l2kw9B4D5NVQMog/otPQe1gyNba8Z7hCwK73UAEOdJVnsKFlvGEoGagAloaSYTdQ0VxDdSZQ6YkvvAcY2/IeAzSUDPpsa5lzYBKo8NjLnIWzZcuWhg0bdunSpWfPnuqirmATJcvcDYwjcplzD1HRaQIXBl2wgmZpXBesYM7Mv0nKtNn6gl4Efr3R7Xu4DBBl1AUrCAjiXhesYNqICV2wwu73cF2/C2mJLVfb+h4uWYb593DxBj7RBSvwM97WBSuYQXqiC1b41Hu2ApUZ9xKobvjnMv/zzz8zZsw4fPhwXf4vj7HM9ZEBdgM1opZ5qMDzjxJfE2wZ2yI2tOy7ntjCVjf8xNh/8JMxxgDvcQzkg7r8ZLi2bIkt4wjEOqMWBEHwBUpqo0r7ogQRXHskSJCAxyJdEAThCVCfcrCmdDkWIIJrj4wZM95w/J+PuiwIwuMSFBRE+uK6a1KMRwTXHlmzZr1y5crFixd1WRCEx+XMmTPkLrHqR9UiuPYoXbr08ePHDxw4oMuCIDwuO3bsiBs3ruv/TxHjEcG1R82aNclww/5HYYIg2OLo0aObN2+uUqWK+Y63MQARXHtkyZKlevXqEydODPsfpgqCYM6qVavU/+any7EDEVx7JEqU6L333jt//vykSZN0lSAINiG9HTBgQNWqVc3/O9GYgQiubSpXrtywYcNBgwbNnj0b/Y2or20LQmzg6aefvnv3bo8ePW7fvt2tW7fkyZPrN2IHIri2iR8//uDBg19++eXOnTvPnDkzVn1tWxCehLhx4wYHB3fv3n3JkiVDhw4ld9FvxBpEcB+HzJkz//DDD9myZevUqdOYMWNuPfo/twVB8MLOnTubN28+fvx4Mtw2bdro2thE3L59+5Lkc+ex3DUDa7XVSLx48QyN79+/Tz5osh8HljxoJEyY0MQYG55HDI0BY7XLlCV0G2P6zIGu8kD69Om5P+/atWv06NHcrpHgjBkz4hkv+w9xFn4GXfYKxnHixDHZoAgw5lV12wTszY1xsvlvgTCmZcOPWTD27jFX6LMKVF32ii3vKcxdDf7gPbpBn81djet85GpevXuPNXXixIlhw4Z17Njx3Llz33zzTa9eveg5vQr1pgd4N8qXOWBz584dHAKWPcFYbXODQ8I1jsP4ec+7vxQ4SP0UL9Zuz+gGE3bhwoVFixZxx96/f3+6dOnKly//7LPPosXhfjLFTYVXwzjGIWAyL4BDcLWhCtgyBm6ctozps6EK0A28YW6sgl6XveInrga73vOdqyPfe9SzQM6fP7/FQbJkyapUqdKhQ4dXXnlFKYm284CfLHOM6QbzYhIhGKNjvHranjF0E2huC4Y3YfXsTEdV0TsoPeBlXfYKc4y/DPcPZiRX7fyH9VeuXEmRIoVhaNIyfTaMNqaN2w83rdWrV69fv/73338/c+YMLtVvC0LsBpFKnTr1888/X6FChbJly5YuXRrpN5TFx1jm5sa0TFZkeAdiRbPMDe+FqDPNYq/L/yVUcGkIPdYVXlH7PCZJkkSXvWJXcBEvZFGXvWJ3Ji5fvoyxLwTXdSbIOC5evIiLuHsTVcrACVfnLV5Nng8woxF8YrgrNpY0bv4/PuBqH/2fBRiznAwTB7pB4BkmDsQxk+IpcXAFY7IM0itD7zFZeJtJNzGmWZUZRLj3gHCiG/Rflz2DDcakPiaBijF9JkrVE7eu9QDGzrzKxJg1TuQz6eEaM18EPB5Qq9XXyzxVqlS6YAXqTK9EcKOx4FrCqqYPhg8TBDE+8TRtbmBJ44bzgvdYfobzAsyLLWPWnqGrCU0Cz9DVaCiWhq4m8FBGQ+8huNgbeo9mWQWGORr4zntMouFDMdBnbmzmgcqroSYQqDjQ8KlXBNfoekKEQLSBLljBwjY3JjTD5tSesGUMrCh9ZAAt074uWGHLGG/gE12wAktzY/pg7mqw5RC73tNHBtj1nrmxT70XyxHBFQRBiCREcAVBECIJEVxBEIRIQgRXEAQhkhDBFQRBiCREcAVBECIJEVxBEIRIQgRXEAQhkhDBFQRBiCSedv7+hAPvKBtbxq4HljgaNjUGWy3rIyvsdkDZm5zltDQ3dj0wwdw4tBN2jPWRFXabtWXsduAJ9ZMqhUn75i07wdKWsT6ywtwSHF2w3bLJKb4zVmBpbgy2WtZHVji6YLtZk1MsjeOcPXs2bty4hhuI3HVs9WiygQjcu3eP6E9ktpfjgwcP1G4AJsbY3Lp1y/DH73Dz5k1DY8aofuBv8iNrjOlG/PjxDTcQce6l4AvvMTUmu42Ar71HnznQVZ6x6z21l4L3QE2aNGnHjh1Xrlz5119/4RPDQMXPISEh5t6jJ4aBCubeA4zphqH3bAWqifcUGDv3UjAZY/Rd5j4KVO/LXDavccd3m9cwx/TBcJsPpo1QNtwkBUsaN9yViqAPDg72hz1B6AaxZKICcOPGDSwtA7VFixYLFiw4f/48EWUYqKgtemT4n2v52nssAV8EKosLCQBd9grLnFfDQPWrZS6b1whCZGOoQYIQ+YjgCjEKMlDDtEUQIh8JTSFGwXOoCK7gt0hoCjEKEVzBn5HQFGIUIriCPyOhKcQolOAa/qFfECIZEVwhRiEZruDPSGgKMQoEV9JbwW8RwRViFA8ePJDv4Qp+iwiuEKOQDFfwZ0RwhRiFfIYr+DMSmkKMQgRX8GckNIUYhQiu4M/I9oz/gTFibL7rXQTu2+aGbM/oCsaWGwxigx+aNWt2+PDhjRs34j3DQMVStmd0gjGBykGMX+Y+ClTvyzxOcHAw75k4V/WSAxN/qQujAsmTJzdxLnN248aNFClSmBhjc/Xq1VSpUpkYg/mud9hgbLjrHcbXrl3DdSYaijEDZHmYLGyMWSGEMj0xGaPantHQewQ93U6ZMqW59wy3yFPeY8YNVYDYwxuGKnD9+nUsvSxsbIiiunXrIrh//fUXPkmaNKmJq4lSvB0QEBDl3rt8+bJ5oLIEGKB5oMaGZe67QCXwImSZ//9vcjjwjrKxZex6YImjYVNjsNWyPrLCbgeUvclZTktzY9cDE8yNQzthx1gfWWG3WVvGbgdhcbQXukrRIGeNOvCC08bEWBF6GTvG+sgKc0twdMF2yyan+M5YgaW5MdhqWR9Z4eiC7WZNTrE0lk+7hJgDagsmaYsgRAkSmkLMQQkueYQuC4KfIYIrxByU4EqGK/gtEppCzAG1fSA/7RX8GBFcIaYhHykIfosIrhBzIL2VjxQEf0ZCU4g5qI8URHAFv0VCU4hpiOAKfouEphDtueeAg7AZrqoXBD9BBFeI3kycOLFly5YnT57kWH2Gq/5ohuxevXq1WrVqy5YtcxgKQtQjgitEe6ZNm7Z161Z1jOCqr4XxOnbs2FWrVgUGBqq3BCHKEcEVojc1a9bMmTPn4sWL79+/r3JbXoFsd9asWcWLF69evbqyFIQoJ865c+fiOdAVniGI79y5QwZhuBWb+mTNcNc7lsft27dNtncCbG7evImxLltx48YNQ2PGeP36dfps8ocXjOlG/PjxDb3HAHk13PUuJCQEBTH0HpZMjZ94L0mSJBzoKs9gQ8t4w3C/q1u3bmHptmMT9VSOGDHis88+W79+fZYsWRo2bIgN+rtixYq2bdv26tWrR48eavsrTxCleNtkcywgUOmJ4S5uYO49wNiW91iJhoFKn20tcw4MA1WWuSsYe1/moZu80Zbhvm1MG2bm+7YRx4ahaXfftuDgYPMt8hhjQEAAXdJlz2CDMX02nAlb2zMybbyahCZmTBs+MQxNIp6pMdxgEBu73mNedMErdNt32zMSHmhr2Js9lX/99VeNGjWaNm3ar18/8lmcNn/+fJR3y5YtJ06cILy9jJSW7969S6wabjCIZLBWDQMV7HrPPFDxHivR8HZFn82Xubo/+WiZ07g/BGqULXPaYm3zngm0RdzrghXMBI3rghVIBtGmC1YQ9JcvX9YFAy5dusQpumAF3aAzumAFAcFy1QUrcB0O1AUrmBQWiS5YQcQTQLpgBUFv13v6yABapn1dsII+03NdsAJveApUJrdWrVo5cuQ4depUuXLlON6+fXvatGn79OmjLbzCDDKPumCFr73no0BlJbIedcEKotQ8UP1qmesjA2wFqt1lrhLTcLEWeEHwc0goqlatinwvXbqUPI6kb9++fRcvXnzzzTe1hSD4ByK4QkygSpUqvP7000+kLeTCHFSsWLFIkSLqXUHwE0RwhZhAzpw5y5Yte/bsWRJbHgCXLVtGzmv4iZ4gRBoiuEIMoW7duufPn0dzL1y4kDp16sKFC+s3BMFvEMEVYggVK1Z8+umnyXBPnTqVJ0+eggUL6jcEwW8QwRViCMmSJUNnObh9+3amTJkyZMig6gXBfxDBFWIIAQEBJUuW5IA8t1SpUg8ePFD1guA/iOAKMQR09uWXX+YgefLklSpVCgkJUfWC4D+I4Aoxh7Rp0yK78ePHz5Url2S4gh8igivEHFKmTJkqVapkyZIZ/k5XECIZEVwh5pA9e/YCBQrkz58/jsF2BIIQ+YQKrq3o9F0ox4aWfdcTW9jqhp8Ym5A5c+bFixdPmTLFp58nRO0YnfiuZZ/iJw6JKu/FCQwMjBcvXvz48XWFZ+ji7du3OTDfnjHEN7veYXPjxg2MddmK69evGxozRoyjZN82VzC7e/fufZ9tz4j3zB+6bXnv2rVrdIMDXeUZbOgG3jDc74rwwNJyxyYsmTuMiShD7xGoeNvQe7YCFcy9Bxibew9jVqKh9whUHy1z1jgOjNnLnG4QeIbLnAHSrKdlHufy5ctMg6EK0BZmsWd7RqLZ+5TgEEPBBRxC+8ycLnsF1+ETgl6XvaIEl3nRZa/gNB/FMZhLBqAChoILqACWJpIBCChr29B7SnANvackgzHqshW+8x6TaCgZQJ8NBReIJV6ZGlX0jhJceqLLXrHlPYyvOHb71GUrWLn+vz1jaFtKcHWFV5yCq8teIYjBMNqQDKLN0F/0AX8huLpsBTcVjA3jWM2EUgGOT58+TcdwIlGlDJwo5xoKLsaS4bqCDd0wFFyMiT0sDYMeb7BcDb1nN8Nl0s29h0PMJQNjXG3oPebFboZr6D3zDBdjXIfmGnqPQKVxxujdmEvToPr7Z9q0aXWtFSxzTtEFK5BykjDD2xXzQpcMb1e4mmY93exFcN3BIQxw165dS5cu3bhx4549ey5evBhWbQVB8B0Ibvbs2V988cXXX3+9Zs2aJotdBDdaCu6BAwfGjRs3derUoKAg5rtatWp58+bNlClT2IHQIDmarQ93eGUmvN/eATNyNHyCqy2NwTBxUGBjK8MlQgxzNLqNsXmGazdHw9Lw+UAyXFeU93yX4eLAiA3UwMDAc+fO/fHHHwsXLmSYBQoU+OCDD+rXr6/f9kC0ENzQtnAB4zeBtlirumAFQU/jumAFc+bTreA5RRe8sn79+jx58rCq69Wrt3PnTsuzcAjPU7pgBX7GJ7pgBXGsbm8m4D3zeWFQBLEuGGDX2NDVQJ/puS5YgTfwiS5YgZ/No5oZZB51wQqVGeiCAT71Hp3RBSvwnnmg4j3zQKVZ80Clw+aBCqdPn548eXLhwoWRsK5du3qXCPkfH6IZy5cvb9SoERG/YMGC2bNnM82WuYbSC12wggkGXbCCbpgb0wd6ogtWYMwi0QUDCDV9ZIBa1bpghV3v4RNdsMJ33gOfek8fGWDX1ebeCw1TO4Hqo9jDmMS5WbNmK1eu7N69++jRo1meFy9e1G9HT0RwNX/99Vfz5s0zZMjAHfXNN9+0lFpBECIHVuWwYcNGjhy5bt26Dz/8UNdGT0RwQwkKCurQoUO8ePHGjx9fokQJ81xAEITIoV27dh999NH333//9ddf66poiAhuKNOnT9+2bduXX35ZvHhx9dmffkMQBL+hR48eZcqUmTBhwqFDh3RVdEME96nTp09PmjSpdOnSderU0VWCIPgfiRIl+vzzzw8cODBr1ixdFd0QwX1q7969u3fv7tatm8dvcgiC4B8UKlSoevXqc+fOvXr1qq6KVojgPrVo0aKcOXPKf4ElCP5PkiRJqlSpsmvXrmPHjumqaEVsF9z79+//+eefqG2WLFl0lSAIfkz+/PmTJUu2fft2XY5WhAqura9A+e77UlHS8oMHD06fPp0+ffqkxtuRuGK3z74boy1sdcNPjP0HPxljbPBeuKROnTpVqlQsW11+hJ/Mi3fiXLx40Re/+YMQB774xSQ2169ft/WLyXCNGdGdO3fSpk3bsWPHb7/9lg5QgzGPLSa/+cP4hvy01wXlPflpryvm3gOM5ae9TrAJu8zjx49/4MCBevXqVahQgTXr+psLu4Hqu2VOs54C9WkseNsQjA3tiQN9ZIatbtjFS+O8RRCoX0k7a9SBCT7tti18122fOsRHDqRZWy37ibEtfNpnnzaujx4XVivygtTq8iP8p89e7ENvC+qbpyZwnzT/KTRZBo3rghW4L0r2UlA38z59+ujyw4d0g87oghV2f2SNA3XBCjrG7V0XrOBJ4urVq7pgBTcYu97TRwbY+ok6fabnumAF3jAPVLIM80BlBplHXbDC197zFKhhsRWorETz7RGIUvNAjfxlfvTo0QIFCrRv316XHyF7KQiCIEQ8KJc+im6I4AqCIEQSIriCIEQ/ommSK4IrCIIQSYjgCoIgRBIiuIIg/Ie4DnRBiFBEcCOGkydPzp8/f+XKlbdu3dJV0ZNr164tW7Zs+/btEf4Z2e3bt3/99dc1a9aor+L5J//++++8efP86nf6gYGBCxYsOHDggC77niNHjsydO5dXXQ6DCpJNmzbdv38/ThT9ZCuaIoL7pBBwDx48GDFiRN26dZs3b75161b9RvTkxIkTrVu3HjduHIPSVRHE5cuX33///T59+ly6dElXGXPo0KEzZ86Efm88oqHZgwcPOlVj8eLF9erVW7VqlSr6A3/99VeDBg0WLlyoy76H+2KTJk2QVF12/MeIf//9tzOZOH36dIsWLYYMGUK9LyYlBiPOelJ4+CL+1q1bly9fvpCQkCVLlkS4VEUmrJ8ECRIwqAjPXGg5UaJEvIKuMoObWePGjS9evBjhz7lr16598803UTRnyylTpsyQIcPjbazhI+LHj8+M2HXakxAQEJAuXbpkj/6bau6UzZo1+/LLL50PPXTm8aZSEH89KUTh77//vnfv3nbt2pUqVYo1fOrUKf2e8MRw98K3586d88WniqTz5M6ut5aWLVtyLfI7XY6V1K9f//jx47hCFW/cuLFr1y61RYCqER4b8eATwVolEJcvX542bdoKFSpUqlSJ0FyzZo1++79g7Lq2vUNwm0sMzdoyNtmGwwnplT6KCvBDwoQJ6bMvsjyVppFCgq4ywBfSr7DlaibRPJwwNvcelq7G+J/TGXXYy5Ft2Io9sBV7MQ8R3CeCuCRF+uWXX4oWLfrcc8+VK1cuffr0CxYsuHnzprZwgCi/++67Xbt2vXv37q+//lqvXr38+fPXqlVr3rx5bpZw7dq1GTNmNGjQoEiRIq+//vqECRPOnz+v33Pw/fffV69e/ciRIwcPHqTNQoUKvfbaa7Nnz1Z/jCIfpPKFF15444035s6dyxXVWQp6smLFivbt2xcrVowO161bd+LEiVeuXNFvO+RYHTC0oKCgd955p2rVqmSCqtLJokWLSpYsuXjxYl0OD+493bp1YxQ8ts+fPz8kJMRtsXEJLvf3339/9NFHJUqUwLJLly47d+7Ubz/1FG9xG/vxxx/Pnj1bs2ZNhun8Sw5L/a+//urZsyeeZyy9evXat2+fessVnPnTTz8xzHz58tGNcePGMSjqr1+/3rx5886dO+MQ3MXVf/75Z+rnzJlDa4zOcbaG4X/++efly5fHqzhk5cqVbn/3GzBgAPU8eu/YsYOJLliwIF1l4qix1BcCYMmSJS1atGAgeKBhw4aMNzg4WL/9CDexO3bs2BdffEG3X3755f/9738XL1787rvvypQp4+o9+PfffwcOHFi2bFkab926NYHqGg+BgYGNGjUaNWoUriOpx+bTTz/l0suWLWNyCR5sCLZXXnmFduhkgQIF+vbtyzwqheUVP+Bepub555+n/fXr1993+f/Vp0+fjs8PHDjArPXo0aNw4cJkJFSqmKee6cNXVapUmTlz5p07d9RZMZxLly7hYkaL77yDDSsTDI2JdYLbxBh4bLlw4YKhMYsEDdIFAzwZczn1H3UQDSxgVUM3CAhl4B11+pAhQ0gBRo8ezcMvcY+MkjetW7fu3r17TjPqWQwEcdu2bcmFCVyWVpo0abj0e++9x7JkGWDJKYgIy4PVlTt37hdffDFv3ryoEvZr165VDRLurIqsWbOyyFn/GGBGm5zCKNALjIl+KlOlSkX7n3zyCe5SJ+7fv79atWqskzx58rC6WAAZM2bEhhXFkqAPXIIVS+Nt2rThLEAxSbsmTZrEQgodjGM4BAxPndmyZfvzzz+dwwTeUq5mNnFIkiRJkidPzv0AMmXKhJTkypXrpZdeQiw4i8vh6q+//jpFihTKTA0EZ3711VdMAVfcvn07t43UqVPTBxSzRo0aDIGBIJeDBw+mfc7FkwwkZcqUyZIlQ3S4Oi0zL3Ryz549r776KgPEmeoGw9hLlSqFLOJzlJEh4N4cOXIwOwgKV+TSeHLs2LH0kOHQFDe/LFmy0AG8jdNwDgYM/+jRo/QEG7yE2iIcH3/8McOkn5hxwHWR3X/++UdNblg4nR4iN/Tq2WefpYc4gRs2JyJMJ0+eVDOC/DFSVFVdjldumXgSR9Elho/TkF3uwbiR27nqOTBrzC/nqnijS1yoVatWp06dohEaJ1fgLbIEhk8gkQSQCpw7d465ow/ffvstIU0juJfhE05078MPP8Sx3NRxGsPkohkyZMCAt/A/HRg5ciRD4+p0g7sUF+3fvz/vMkDmV42uU6dO3IA5S/lKLYTevXsTNpyonAM4lnByrQHmiBigq0wfl9C1Dsw1gTZtLXN0DDXTZa9gTGgRfm7ddvIUF8aCoRLE3sGGC4OJMdAsLjA0ZhaZaUNjBk/KowsGeDJWI2KykRUEV9XQDTqjDLxDQBCypUuXZt3+8ccfRDA1I0aMIDqJHjqphsMrqUTlypW5EJFH4oD+Ur969WrWGA+z5FPMBNN/+PBhtC9p0qSfffYZUUXfWBvffPMNMY1YoD60D4MGDaIpVGDo0KEsS2rIXNBQlhbLhg4wBCpJ2Siy5NQHcNwpkXv0pXv37qxzLkcPUczatWvTGkKDDd1A8dEUohknMCKyOVYRWqkCVI0am8yZMzdr1oy7tapUKO9hQOaLCrCili5dynWJP+4ErC4uhDSQLhGOmJHKMViWHB7AjP5s2LCBhDogIGDy5Mm0DFTSbbr0+++/O69CoorcIKZ0DwPax5ncqNKlS8dKZhS0hjPxOT7hlsMVudzp06eRaURHyQrLFTXB4IcffsCeZrkcfsBgzJgxoYvj9m3EDjl45plnyONUMO/evbtly5bkreSG1HAKXULFGBreJqtlyrgWk6UcSx5KUfXcFZpifvEhl0PFSKJp6syZMwyTmyInOvuAc+gkk047QAfoDw7BgElRTkO1OQU5IxI4BTPCjIlDT3mKYproKnPdtGlTLoc/uTQ25JgEJCe2a9eObmPGfZe+IZrECYFHU/SKIEcuucewojmLGu5Y9IET8TCeV0tm1qxZ2bNnp15FF+cOHz4cGzSXLPv48eOcSyJCJDMcwvXLL79kvFTSZ+4c3Fa3bdtGUfkHGFrYlUvkIPekFPicS+haB+aaoALVcJljjPeIEF32CsasbjzJga76L6HPXIwBuTEBP4IuWEGzNK4LVhD9LBtdsIIbL3OvCwZgzCm68F+YM2LisbdnJNcgrIlj2lE1PJ2hv6w98jhVAziaJYFGTJs2TVc5YM1wdeJbFXl8I3vi6VglIMwZlfSc7IZ1wpJTZsOGDeMssirMVA3GPNBR2aFDB1UDjOL999/nokQ5RZzA8mbZEJeuk4hmkR46PaD6TzukEhSZFHSNVUS9MgAyIDSRlazLLhDEuIIEmc4sXLhQ1zpAChkdaT4doMiaZ7mSFv3222/KQMGdhvSN3JCopcjweQhAX9AL1SV0kzSZmxC67zhDw3Ll7oKYsmgpzp49m04ijq6DxaU8vDNf6AtFpgPFnzp1qjoFmBFczURwjHs5nUZoSr2rYGbJtblTkk6qmvbt2zNebpOqqCA2cCxapsthQC7ffvvtxo0b4wpVg/d4RWEJKp5jVOWqVatQKCZdFdEpHqFGjRpFn51RjQojYdzkNm7cSJEh161bFwlbvny5MiAC8R43/vLly9Ma+QGVOAFFJv3nlqzMFNw2EFzSfFXE4agkXXV66eDBg8xRzpw5mQL6QONU4i7CBj8goMqMTlJs0KCBc3UQk8wmlcilmk2gBRIU3E4oqhoF9eEuc7U9Y1jH2tIElrmzA5ao5EMXrCDGnI4KS+hnuPzDqyG2jG0R7VomIFgM3FcIKXRNVZLHseZZk6xGVQN0gNklKyTp01UOCFnWMwHNMfG6du1a8ikSHBIotZaoR6R4cENKiGOihBre4pUnQefngwSr+iYTz4aqBqhEOtEFopwiT98kdKQhSJUyAIKD1c7q0uVHvnJ6jO7RH9IT0ihVw+oib2V5Fy9eXNW4Qm/RERYwybtrZ4BHAZ67VeeBrJMMq2LFiiT1qkZBMkXlzp07Sawo0hO3LqHILLk33niD1FjVKFiENIUu01uGjP6ySN58883EiRNrC8d/QYiYklmr/8JOOVmhDNSBekWPmET6oz6XUHAKiSQpP45F3VQll0Nb3QbClOE9NI5u6Kr/wlyj9Yg+yqhqCBJyFO40rjOiUF1i5a9Zs4ZrcUPC2OlMMj7igRBSRXzLbYzstVSpUqqG0+mk6jkHqudU0gj9dA0JcHUCqKs4i6BaI6tArJUPqSQauTETdaR4ykydyJOHc3XwLvcSDuiYc4zEDDdUbGhT1Vji2hkn4VZ6wpZxBCJ/NHt8eJxHhogScpkBAwb0d0Cag1KwxniiZ/FoUwcJHOiCA9dZR/tI/ViibtEPrBP0FB1R+ThnEZ3Or0kqVFOoqioqCGXXV5YEV2Epjhgx4oMPPiAvq1mzJhkHK9yp3WFBbnhUJ/vgXIqkuqghD/48PyoDN0g0WHIsIbceIhOkRc4hq89VeIYlo+/pAskOz6Rk1uidsnSD5zsyCJ4r9QkOaIQHczIvxsLTItKD6KAm3NL0aY/ADyx7XfAKPWQsOXLkcPMqcO9kKrm1OIdD0VXZgbec74aLmhGCBA3l+b1v375du3ZlRrp06cLww+0kgksYcLdIlSqVa+O0g8Od+ouL8ABpqboNu8K53HW4y3JMBziFaXLruQlcnUTb7dsdbuOliIFSWCeqkwSDKiroiUKXYy4iuI8Pz2WoDwHEcygPgEgtoLkkgLy7devWv//+W1kqvC8/2kGmWbfEsa56BGvPLeWhKe+thQsd5kmzdu3aH3300dChQ3l0RdxJeVgSaJM2CgNZDNnTli1byCsprl+/HuUlw1LvhkV9PsstwU0yWHtuy4xB4aKvvvqKx2RXSE7RC8RF24WBlYmNtnYwfPhw2qE1rq6ecBEypSb6HPtwK6WHPKeH1T7qw6rDY8wIN2ymo06dOj169Pj888+5q6GbPDAhlEqY3FBZLYpJl7xcTs0mYw97H+VE157TCPHmzEB9Qbj9fAxfxQxEcB8TxHHJkiW8ki0iRr+7sHnzZpLHEydO2Po5JkFPJqWeKHXVI9AvBIiF4Sa7tiAz6tChw6ZNm1q2bLl27VqugoD+9NNP9evXR+XDXd4KFn+NGjXIiZBaMq/FixcXK1bM7XHeFZIvHpZJD+m2rnJAen7mzBldcKx8LtqpUyfMUHBXGCxi17x5c236XxARlmu/fv3QVn2Cg5s3b3IildWqVaNl7iW4S31c4wrZ3/79+xFlXfYM9yEuhLF6sHCFayFq+O1JkjLyceKEOwcPGTw0MCO8Tp06tVatWtycwp0RYgBI4emS26UJRWcNU8bYicCwPcdReMmZmapTYq38RT4iuI/JoUOHeBIsVKgQOePLL79c2oWSJUs2atSIx3BSXWROn2AFi6RAgQLomlteDDxio19cJeyzrTlI7Y4dO1q1akUmpb40xtKlHhFkEaKknpJc1iSXfvbZZ5Fp0vZjx45Vr17dU+bI0iUlzJMnD31WGbGTU6dO/fPPP05RyJ49O5qIxCCRpGxO6NXq1atnzZrlqs6c5TwxV65cqVOnZiyIsj7HAQpOhjh79mx8RSP58+dHmnkEUWc5IbVH0Vyd7GzZjcyZMxcsWJBuu04ixnSYeypO4xK69rHYuHEjDkFtBw0axIVcZwRBv+L4v7+UpRNsihQpEhgYSPi55t3cP3bv3u2syZEjR5YsWZgC1/sNEozHSAgwVj0311ksHTMQvqMEc0RwHxNEgYXx6quvoi+6ygXWD2kgywmZ01UGVK1alaRp9OjR5D7kICqfPXv2LDU8XyNzT/7oRwatnpRVkQtNmDCBPAg8JbkIMeJYsWJF1urUqVMTJ06svoQULjTCXYGuouAjR450fopN/jVt2jTWv/PS6Ga5cuXwzw8//ECXVCWQRzds2JC7gmuCjMbRlDr3ueeeK1OmzC+//DJjxgxXyUBt69WrN2rUKFpDemgceZo0aRJj1BaOX1LMnz+fe6Hzs11a8PQRNqcjzUeOHOEhBnlVlYgOfebStMAlVOWTwMw6b3V0G5X87rvvcBdDDjsjhEft2rXxzNixY0nVnQo7c+ZMhs+7qojaYkZuPmbMGNqhBku8R9DOnTuX4HT+Mc0QRs2E0itdFh4XEdzHgexjwYIFrFuWnDPKXWGtIjpE+Zw5c8hWnCrjHXTkww8/3LVrF+d+/fXX69atmzx5Mg/Iy5cvb9u2rfp65mNTvHjxF154Yfr06e+//z6Lc9WqVTyVv/7666xbT58YKngLPeJmgOhMmTKF/D1v3rz6vTAoBaxTp079+vURuwYNGuAo+t+sWTP015Ek6SyJm8e7777LI0LPnj0xxownhs8++4xzWdgdO3ZU3/TEdRkzZmS1z5s3D71AnkiuOQW9Jjds3LgxjxGI70cfffT2229zM+jUqRP2tFC4cOFevXqhsDVr1hw/fvyGDRvQ4jfffJP8rkuXLtjQOJkySSUtLFu2LNy/0bVu3RoRnzhxIspL0k2OTzb6zjvv4DRmiqxf2z0W6rkBL3Xr1o0hrFixghlh6hkjA/E0I6+99hrBgMI2bdqU6OJEfPXBBx8wENfbD5UMliii/9xj6DkdZhR45uOPP86WLZu2M4CnB55FCEueHngioWPOSRRsQ+JAdsNUmYB2sOp0wQqVleiCFWQl6hnKBKbc1nfuSGE4RRf+C2PHCXa/h/vzzz+zJMqWLctTM+mJrv0vBCiJYXLHj3+4CmLq9m1WUN9pRz502fH/e6MOJCDU0zGUrkSJEt988w2LUFs8fPi///2PiEf7dNnx5R4WGPZuX33FknbQVlVkcVauXFmlydwnkCTkg5TqpZdeypMnD2PBBoVidbGknU7Ae7wGBQWRziPN6I6qDxfmRTmExBwVyJ07N9cChBW9K126NNciz1XGxNLevXvpOVdXa5j26SECEeLy36dv374dJ6iblnOArHzU0PlNCfX1NeZFXV19Lsyk//jjjzhTfWSJK7hB0oJzys6dO4d6qlumigFczTFZvzIAetu7d2/uMaoDXAghW7JkidM/XKVFixbcYtF0VaP466+/yDS5UXlZX2h9+fLlVfeYF7xEar979+4CDrgHYMPtijAYOnSoOgWYEaQ5R44cnEWvihQpwjDbtGmTMmVKnkK0keP7ql27dsW3mAF3F25mBINzLRw/fpxGatSowbpWNQr1/VledfnhQ2JS/XZO9erQoUNkG+regB+cy3zw4MHYOL9s/tVXX1F0dSaX7tGjB5XcMHSVAyy5YeBVXXaAcbjLnHGROoT9Hq4KVEOcgWoCw+RGpQtWEHiEny6EIQ7OYr4Nn1VVQ0oLLKGLYPhnYgZP6mH4GSV9IOVx+5O3F3AuxuHelrkrMNMsNgJa1dAyfXY+rIULkYpSkGRlzZqV051/gnAFydi6dSuXZhWx8DhGyhEOVqa2cPwBZ8eOHQS9+hWWE/WHnQsXLqRPnx6ZVrHu5N9//+UxGbnMnDmzqiHoaQeNI/3kFFUJPA6zNooVK+b83IOgRPRZM5yLGtIxwpp7A1fkXPzPLPz5558sJ5aW8hhDoM9MUMuWLRERksGw37VywhiRJKVNnEJX6QN6gWAhjjgBh6O5Kt6IY5VcHzt2DJfisTRp0mAZdmbpMApLOJEV0mdVSVOsvZMnT3IhBvjcc885v4GkPiFRgYobcRcdYxTYcAllo2B0DB/l5UGbZaxmlmPXHJD2qVc/BuNCTIdbhohEBgYG8gzhOrmMjvESSNyYlUPC5eLFiwcOHFAhSuNEApdjNpkpZgRn0n/crr70in3ooo0TBxsuSrfxLd1m0jt06IA08+zCxKmWgcDAt7iI1ugzljhcv+dYzn/88QfRXrRoUdceEjPcdwkb5/0Mz+NDnMDpTB8d2Lx5M9Hy4osv4mcmQi1z5pq45QagIpPZIdiIf5aJo5nQpyWGxmyyEFyjmk5yIt1wjV5Py1z9FeGVV14ZN26crnKgAlUXrHANVEsQSU/LPCzqiRZ7XXZDMlyc8Ni/NLN16yO+zV2N+tgypie6YAWuMJ9EUPPyzz//cIPp27evJ08qmBe0QBesYDm5ZrLewRvmxirD1QUrmG4vKYkbjM7c1cANTB8ZQMve3QukwPXr1+e5BG84XY1qk8hzN1K/4guLLe+xckEXrLC7zJl0XbDC0zKP1hmukcALEQIBBLpgBdFAdOqCAcylPrICS6JHF6xgebCYCfGvv/6aMKpVq1a4DwqRAN7AJ7oQoTApiJEuGGCrG+auBpOWSVQXL178xRdfkJhTZDZJPHmWJ1etUqWKa4boCgO0FXu2xmgL80CNkYjgCt74999/W7Zs+dprr3333XctWrQI9+e8QmRSrVq1Jk2aTJ06tV69eq+//jpT8+abb44YMaJZs2adOnUyfEYWooo4PDCqz3At7zykNipVTpIkiYkxzxrcV5MlS2ZyT+OOSiqeIkUKE2NsSPJTpkxpYgykaQEBAWFTM2p41KKHvXr1ImUgh6IGY2pMAhdjHqZwXYIECUwccvPmTV4TJ05sYkzH8EnSpElNxqgeihmjiTE2ht6LGzcu2VObNm145QmOAzzjJVGi24RT8uTJDb1HN/BGPKsdYwFjwoP+JPrv3+LDBWO8QT9NvIcxSSixqn7moGs9Q7Pqjw0mxkA4Gf5lQnkv3EB1Bd/iip9//nnmzJmbNm3CISVKlHjnnXcqVqzIwgw3M6VB+my+zAlUDny0zGn8SQKVaDl8+PBbb71VpkyZCRMmuD4F2nJ1VC3zOIGBgYzBMOjVJzsmQQ/4Akz0BYhjJMZQX7BhVK4f/3uHAA3XWI0oXbp0Xbt25ZGZ2aWG0KTPhjNBN4hjQ+8xQF5Ngh4IYqLT0HtYMhBb3jNcIarbSoyYTe+nKO+xUDnQVZ7BhnnBG97/PqnAGA3F0jDo7QYq3jbRFyBQ6Ymh98BT7IULxibew4CQYxJVoNITIAY8dUl5z7HKTZc5B4aB6ljlkbfMWW4IbsOGDUuWLKm+c63fsONqxhhlyxzxVtFpAhcGXbCCZiP503RPYMwpuvBf8A5OeOw/mjHAiPo03Q06RkzoghXohbn3WJnq72CG2HI1LauVbwJ3OHquC1bgDXyiC1bgZ7ytC1Ywg/REF6zwqfe8BGpYmHFbgRpjlvlR2Z4xQogNLfuuJ7aw1Q0/MfYf/GSMscF7ngi3ET+ZF+9YZ9SCIAhChCCCKwiCEEmI4AqCIEQSsV1w48SJkyxZsusGu6MKguAP3Lx589atW2F/8hstiO2C+/TTT2fOnPnSpUv3ffbTGkEQIpCrV6+SITm31IheiOA+nTt37mPHjl189D/fCYLgz5w9e/b8+fO5cuXS5WiFCO7Tb7311h9//HH0v/89gSAI/smGDRsCAgJKlCihy9EK+aNZ6Lbf8eLFU//zoyAI/sy5c+cWLFjw5ptvyme40ZXnnntO/Z8urv8XiyAIfsjEiRPR3ObNm6tt46MdIrih//fBe++9lyZNmgEDBqjfQes3BEHwJ7Zs2TJw4MCaNWtWrFhRV0U3RHBDKVmyZMeOHWfNmjV48OAHDx6YbKciCEJkcvz48S5dumTNmrV///4Jn/h/U40q4vbt2xd9gYdWYK12U44fP76u8gxm9xyo7Z0sQeZoXG2xYwKpqNoLygSM1QzpchjIatHckydPjhgxIjg4uFKlSvHixdPveYYG79y5Y8t7XMiwZbVbmKH3sDT3Hq6m23a9pwteodsYq2c9XeUZ5T28gU90lWeUsS3vMUzzQMXeH7x369Yt74HqBBtaZoDm3nv66afNA5UDf1jmdDtx4sRcZc+ePe+8886OHTsmT55cpkwZ2tEWLvguUDG2tcx59RSocc6ePct7gJF3mFrGz4Ealar0gpqJSNu3zQsm+7bhgWvXrvXr1+/777+vXLny+++//8orryRPnhz3IWdqgrXpI3AIK4S4ZCZ0lWeU93hVoalrPaMkw3CDQSW4hhsMYkO3MdZlK8x3vQPmhRlnmLrsGWwwxhuG3iM8kAy8ras8gzHesOU9vO2LQAWfeo+ViE90lWcwZsb9ZJnTuGWg0gfGRW9x9aVLl+bPn8+jZ0BAwNChQ2vWrMnltN1/MXc17WNMeJh7z3yZq0D1tMxj+38i6QYDHDly5KhRo8hzmdoqVaoUK1YsS5YsnraFJnoIC5OZALxBIyaSAUQV0aluwpZgSeMEkC57Be8RE6wQXbYCn9gyphsmrga6wQBNgh4YoFqEuuwVBJRhGnqP2MPbhkuAZpl0Q1eDn3jPVqDiPV4NA9WW9wwDlQ6wZg8cOLB69epffvll06ZNVatWHTJkSKFChbRFeHCK//8nkiK47tCNU6dOfffddxMnTmS8GTNmZAj4J9ylTgDRrGHLGPNqOMeMEcyNadxwOQHe9hNjBmjuPX9wNYj3XLHlPSxNApXbA5DbXrx4sWjRon369HnjjTfQR/22B0Rwo6Xg0nLy5MkxxnFr167lHnv69OkzZ87wDBK2hegVx05ij2SY2NtyNcQe76mid2x5D0uTQFX/F32+fPnKlSv38ssvGzYughtdBZc+G8Y9j3V4z9AYb9AHw2njMQ2fROyTmgLvMY+GkwgEkLkxLdMNQ1fb8h4pD5Y++kgBe3Pv2fpAxpb3MKZlQ+/hasLDUDJseY9Y4tXQe3YDlZ4Yeg9Xo06Wia2TaCG4RtcTPMFCVemACYQm6IIVBLG5sRJcXbCCODY3BlaIPjIAY9rXBSvohrkx3sAnumCFXe+pTy1NoMN2HaKPDLA1L7a8ZytQ8Z65q+16z9YYzfscXRDBFQRBiCREcAVBECIJEVxBEIRIQgRXEAQhkhDBFQRBiCREcAVBECIJEVxBEIRIQgRXEAQhkhDBFQRBiCRCt2c0/M1fHMeudw8fPkxovG/b/fv3E5ltkffAbN82BTY++nEqY8TY8BeTGNMNwx+nYswAeU1gtj2jXe8xNYnNtsjztffoMwe6yjN2vXfbsSepLwIVP4cYb8+IDT0xDFQw9x5gbPjTXmxsBaot76lfx8X4Ze6jQPW+zGUvBXds7aVg90fW9MHwh+RMG6FsuL8nljRu+Ktzgj44ONiW93z0E3W6QSwZ/sD/xo0bWBoGKvrCMA0DFbXFPnny5LrsFV97jyXgi0BlcSEBoMteYZnzahiofrXMZS8FQYgYULotW7awtnX5yWAxBwUF6YIgRBYiuEI0IDAwcPDgwe+///7WrVt11ZNBlvrZZ58tX74c5TXMKAXhyRHBFfyaGzduzJ07t0aNGiNHjixSpIjhRwqWHDly5Ndff23evHmvXr1OnDhh+GAuCE+ICK7gv+zcubNLly7IIknoiBEjvv322+LFi+v3nowXX3xxzpw59evXHz9+fMOGDZcuXar+UiQIPkUEV/BHgoKCvvnmm5o1ay5btqxjx45Llixp0qSJ4V9mDMmfPz8i/v3339+7d69t27Y9evQ4fvy4fk8QfIMIruBf3L17d/Xq1fXq1fv4448LFSo0e/bsIUOGpE+f/r7j/07WRhFEvHjxSHLnzp379ttvT58+vVatWj/99JOkuoLvEMEV/IjDhw/37dsX+Tt9+vRXX301efLkV1991dcfsObKlWvw4MFTp05NmDBhhw4dunbt+s8//+j3BCFCEcEV/ALyykmTJtWtW3fMmDENGjRYuHAhj/lp0qTRb/sScucECRJUr159/vz5XJSEl1R32rRpN2/e1BaCEEGI4ApRSZw4cdC7TZs2NW7cuGPHjmnTpp0zZ87o0aPz58+vLSKRzJkzDxkyZMaMGRkzZqQzrVu33rdvn35PECICEVwhyogfP/7JkyfROBLb7du3f/rpp+SVNWrU0G9HBfHixatcufJPP/3UvXv31atXk+pOmDDh6tWr+m1BeDJEcIWo4e7du4sWLapXr94XX3zx6quvLly4sFevXpkyZdJvRylZs2b9+OOPZ86cmSNHjk6dOrVp04b7gX5PEJ4AEVwhsnnw4MGBAwfefffdDh06hISEkEL+8MMPhQsXNvxhe+QQN27cihUrzpkzZ8CAAVu2bHnrrbdGjBgRHBzMW/LLNOGxEcEVIpWgoKBRo0bVrFlzxYoVLVu2VF/JMtyjJ/JJkSIFeTeyy/3gww8/bNGixe+//y4/SxMem9DtGeM50BWe4cauvqJovm8bGO56R9Zz+/ZtFp6JMTY3b940X6U3btwwNGaMGCdKlMhw17sI3LfNDVI/fEJPTIzv37/PE3oS3+x6Z+49YF7C3WAQF3HdtWvXjhkzZs2aNWXLlu3SpUuxYsWSJ09u8u1aGiQ8mBSTHZswxhu2vOdle0Za46KBgYHTpk0bO3YsLb///vvvvPNOxowZCW/LzkeI98KCDcasRPNA9ZNlTuNRHqiM0XfLXAWqp2Ueh6ck2jIJTdpijjFjVCbGeJboZEVZGgNBf/369ZQpU5oYY3P16tVUqVKZGIP59ozYXLlyxXDXO4zxHq4z0VCMmWNeTaINM6aNOKYnJmPEkqkhHTMxJujpti3vGe56R7cxdtv1jkpeDx48OH78+AkTJmTNmvW9995r06YNfqMbLFRDFSA8sDQMVFYIwzQMVKIUb9NtL8ZqFDt27Pjf//63bNmykiVLDhgwoFSpUqwd75ew6z3D7RmxsRWo165dI0pNNBRjYokDw0D1q2Vu7mq8R58NBdfuMqdZT3egp7EAjtSBF5w2EW7sxHfGhjxeB0zO8p2xE98ZGxJum0T29OnT69SpM3ny5CZNmsyfP79Tp06EL8bmfXBampziC2PehRdffJF7xqBBg06cONGoUaMhQ4acO3dOWzwx3jvgxuMZm5zlO2MnvjM2hDbNm3VampxiaWwt8ILw2GzdurVt27bt2rUjf/zhhx+++eab559/nrDTb0dDyM4Yzrx58ypUqIDycgtZuXKlfk8QrBDBFXxCUFBQ//79SWzXr1//8ccfL1iwoEaNGs7ENvrCc2JISEjhwoVJ2MeOHXv+/PmGDRt++OGHJ0+e1BaC4BkRXCEiiRcv3t27d+fPn4/UDhs2rFy5ckhtnz59MmTIoC1iCnHjxm3VqtWcOXPq1auH8r799ttLlixh7PptQQgPEVwhItm7d2+XLl3eeeedy5cvj3NQqlSpaP0ZghcYV758+b799tvRo0cHBwczalJd2eNR8IIIrhAxXLp0adSoUTxfk9526NBhxYoVzZo1i9gdbP2TpEmTNm7ceOHChc2bN+cGU6tWLdJe9c0qQXBDBFd4Um7durVhwwak9uOPP86dO/fs2bP/97//Zc6cWb8dO8iTJ8/w4cOnTJmSMGHCtm3bdu7c+d9//33w4EFMze6Fx0MEV3gieILu379/vXr1Dh8+PHjw4IkTJ5YvXz6B2X/HHcOIHz9+nTp1Zs6c2bp16xkzZtSvX3/atGmG3yEVYgkiuMJjcvfu3alTp7711ltjxoxx/l84adOmjeUSkzNnzi+++OKnn35KmjRpq1at3n//fdnOXHAigis8Dlu2bGnZsqX6gi2yO2rUKLWDreVPXWMDTz/9dPXq1WfPnv3BBx+sWrWKe9IPP/wQ7Nj4RojliOAK9jh79uywYcNq1aq1bt26Pn36zJo1q3bt2gkj6H8vj0lkypSpX79+kyZN4qBLly4dOnTYs2ePfk+IrYjgCqbcvXt38eLF9evXHzBgwKuvvrpo0aL+/fv7yQ62/kmCBAkqVao0Z84cUt1ly5bVrFlz5MiR165d028LsY9QwbX1h1Tf/dU1NrTsu57YwlY3eEC+f//+wYMHO3bs2LJly+vXr48bN45n5OLFi2sLF2y17CfesIutbnOXypAhA4K7ZMmSggULcvDOO+9s27YtJCREWzwuscF7togWsRcnMDAwdNc2433bHj58aLJjEzi2bYt+2zMiKPTZcBshuhE/fnxD7zFAXg13vWNBInOG3sOSqbHlPZN9yOgtQzt58uTy5cu/++67U6dONWnSpHXr1vnz5+eKYT+uVd5LkiQJB7rKM9gwL3jDcL+rW7duYWm4Y5PdQMXbhnsGMmp6YriLGzhjD0+y1qZMmcLtio61a9euadOmadKk4erOpjC25T3aMQxU+hy6yGUXVgeMMaqWeehmTrRl4lxaYdowM9+3jTg2DE0WMP4y3GAQm+DgYMNN3uDq1asBAQF0SZc9gw3G9NlwJng8xHWGKsC08WoSmpgxbfjEMDSJeKbG+waDTrCx9B4dQN3owG+//TZkyBBey5Ur17t37/LlyxMt1Id7LmfZ3fUObxjGMeFBl0w0FGO8wdo28R7GJKHEquEGgzTLWjUMVCCcMFbH9J+ztm7dOnjw4BUrVlSsWLFv375ly5bFXcyg8p55oOI9VqLh7Yo+my9zApUDHy1zGo/AQHXF1dXeodtRtsxpi7XNeybQFnGvC1YwEzSuC1YQcESbLlhB0F++fFkXDLh06RKn6IIVdIPO6IIVBATLVReswHU4UBesYFJYJLpgBRFPAOmCFQS9ifeOHDmCHKRNmzZnzpwjRowICgrSb3iFlpUcm0Cf6bkuWIE3zAMVwTUPVGaQedQFKwy954TY00cuEGOjR4/OnTt3hgwZEN8zZ86oelr2UaCyElmPumAFUWoeqH61zPWRAbYC1e4yV4lpuFgLvBDbYP2o7x6MGTOmRo0aU6dOff/991OnTq3fFp4YErEOHTrMmzeP9HbYsGGNGzfmGYJ7j0nCJURrZIKF/7Bjx462bdu+++67PEP9+OOP48ePf/HFF/V7QsTBU2eRIkUmTZqE4J44caJBgwaffvrp+fPnqdcWQkxEBFfQXLhwYejQoTVr1ly/fn3Pnj0XLFhAkhs/fnweprSFENEkT56ce9uiRYuqVav29ddfk+ouX76ch3T9thDjEMEVQv/mtnTp0rfffnvgwIEvvfTS3LlzP/jgg9i2+0wUUqBAgVGjRo0ZM+bWrVtNmjT55JNPZI/HmIoIbmzn4MGDXbt2bdSo0dmzZ0eMGDF58uRSpUrFzt1nopAkSZI0b9586tSpderUGTduXP369RcvXvzQ7K/zQjRCBDf2cuXKFdZ2jRo1pk+f3qZNG5Lc1q1b85Cr3xYinTx58pDqTpo06e7duzxwdOnS5dChQ/o9F27evLl79+47jv91X1cJ0QQR3BjL/fv3AwMDw34C+/TTT5M6bdiwgZSqR48eOXPmnDFjxueff547d25tIUQRTFmiRInq1as3f/78tm3b/vTTT7Vr1543b97169e1hYP9+/dXrVp10aJF8q2GaIdMWIxl586dlSpVYtHq8iNOnTr12Wef8dCKAQezZs1644034sePr98W/ABufsOHD//hhx8SJ07csmXLbt26HT58WL/31FNZs2YlFx4wYMCBAwd0lRBNEMGNmVy5coVVymv58uV1leO/ZkBea9asOXHiRER2yZIlZLgpU6bUbwv+RLx48WrUqLFgwYKOHTuqWUN/b9y4wVvp06fv378/ae+XX36pjIXogghuDOThw4e9evX6448/hgwZkjNnTlW5Y8eOdg7ixIkzduzYkSNHFipUSL0l+C0kswMHDpw5c2amTJlQ3k6dOvFcQn3FihV79uw5ZcoUVFhZCtECEdwYyOTJk8lh33777XfeeYfi5cuXeT596623li5d2rlzZ5KmWrVqyR/HogukulWrVp09ezaPLCtWrKhbt+53333Hw0r79u1z5co1aNCgjRs3alPB7wkVXFt/6/TdH0ZjQ8u+64mTbdu29evXr0iRIuSwd+/e/fnnn5FXnkBfeuml5cuXf/bZZ9myZbt//762NsBWn31n7D9EyRjTpEmjUt08efJ07dq1efPmBw8enDVr1r1793r37h0UFKTt/B7fTXq0iL0458+f5xZq8jcTunj79m0OonzXO2xu3LiBsS5bcf36dUNjxohxlOzb5gpmaCWyaLK1GGB5586dgIAAZrNhw4ZHjx5dtmwZ544bN27q1KkZM2Zs165d/fr106ZNqzaLwXuGm2OBLe9du3YtadKkHOgqz2BDN/CG4X5XhAeW5tszElGG3iNQ8bbhxmy2AhXMvQcYh+s9atROYwTbyZMneYIZP348rujevTsTOnTo0GrVqo0ePRqzcHtFPYHqo2VOB3BgzF7mdANvGy5zBkiznpZ5nEuXLjENhnFMWxyYxDHGBDGTYRjHSAaNG6oANvjL/KE4ODgYMdIFr9BtjOmz4UzQDTxrPhO8Gm4wiGTgE8M4Vve2FClStGnTZtq0aV999RVXGTJkCIkP+tuzZ8+cOXOyYgl32sSYADLcIg/seo+g50BXeQYbW95DMhiC4e0KyWCw5t7D24YqQLM+8h5wuwrrPUZ9+vTpY8eOZciQIWXKlNw1qeQ5hvldvXp1hQoV6P8vv/xCnvvJJ5/gTKZYneiEBumzLHMndNt3y5xApVmPy5w5Nt/1jraYOV2wgiD2n33bOEUXrKAbdEYXrGDaCDhdsALX4UBdsIJJYZp1wQpGR08QVmKiZs2aiCzB9Nprr61fv553iXIuffbs2VOnTqnp85Nd72Lt9oyeoOVwA3XBggVp0qRhtaZLl65YsWIdOnSYMWPGkiVLPv7447wOUqVKxSIfOHCgJ+ezElmPumAFUWoeqH61zPWRAbYC1e4yJ/x0IQzWAi/4PwR9nz59vv3220yZMu3Zs2fXrl3Dhg3r1avX+fPnhw8f3qlTJyS4SpUqlStX/vXXX/U5QvQBkWUeBw8eXKtWrezZs//+++/NmjVjTjds2MCMI2FoB4L7+eefz549m1WtTxP8j9AP3XjWIGHWFV5Rys2Tmi57hXsCGH6qQsSQwhhu2E4fSI7Mv0DK3Qxjsn1d9oraCp7nOF32Ct7j2cHkozEga6APPKnpslfQUNIBElVd9gq57Zdffkl6S2dy5cqVOnVqlt/x48dJaZkCigULFsyTJ0/mzJlbtGjBAUvUlvdIoHTBClrmsc7kSQ1IHIglkyc1IHHA0jBQnR8p6LJXyLKxN3x0VQ8TvvMeS8BLoLJMiAruo4GBgX/88cfatWs3btwYFBTEKYwCA6a4mwO3AGZxJXCgy15xfqSgit7xq2Xuo0C1u8xpFntd/i+S4UZvWGZdunRRX4BHC5jsc+fOobOsyXfeeYd89uLFi8eOHVu5cuXEiRN55ERtMVPnCtEO9Sl2tmzZihcvTpI7c+bMbdu2fffdd2S7SC16eubMmU8//ZR4UPor+BsiuNEYlLRx48Zjx47lmFyYB8/OnTv/+OOPPGn+/fff6j8zT5MmDbkbq9QwwReiCySAzGnWrFl5apk8efLq1au/+eabGjVqkEL26dNn0qRJ2k7wJ0RwozHktnPnzs2QIcN77703e/bsBQsWkNpUrVo1U6ZM2kKIubh+VsszbL58+Tp06EDOO3/+/Pr16+fKlUu/J/gTIrjRGB4qP//8882bN48YMaJixYpZsmQx/ExKiKkkSZKkdu3a06dPr1Kliq4S/AlZn9GYunXr9u7dm4dKkp278h/hCI+IHz++3Hr9E5kVQRCESEIEVxAEIZIQwRUEQYgkfCi4ceLEsfVBkuFvDRR2Wzb/UhQt+84YdEEQhNhHRP7S7OrVq1euXFGaggzduXMnJCTEcE+Q+47f+6dIkcLEGJvg4GDD36sAHQsICDBRRmzUL81MlBFjvIfrTH6CgrHzl2aexshFs2TJoo5t/dIMSxo33LnD17+Vkl+auRKxvzRzxdZPIuWXZm5E1S/N4gQFBRHHzISl0hEHxCUHtBXWmOlRPzDVZcE+adKkOXHiBH4GBJfoRDIs5wWwZGoM723YIF6GOzYB0WYoRnQbY24SHOgqz2DD2iOWTCQDY+JY/c7KstvKeyijl3ubK9yukAy6bWJMs/TEF94DjJnECPceNvSWV8N7G97g1VCd8R540hc38B5TYyjl9BnpN7xrAlFtmKAAk0ifDQWXxcUSMzFmXugzlp4CNc7FixcjRHDxS48ePb766quxY8dyK8CAaaCX4RqHRc2Eob5gY2smcK6hMWPEGGeZO5fBGkoGA+Q1XFcTghMmTPjrr78CAwOxUcYiuE4wFsF1xdx7xOeePXsGDRpkKKDAGHk1FCP8AObGNG4y4woCO8qNcTXPQDgwd+7chIqu9QDGFoLLHDMThpNBW7x6ukH16dPniy++INZVawwJDFtmGgh6AkiXrUBffGeMs0yCHhgstyvDmWPaaNZTltGhQ4fvv/+eq6tL0zKza3jHxhIVMP9IgUk3/0CGhy/zxzqeAdEXw+VHN4glw7TLfz5S8J33bH2kEOzY0dUk9tasWVOpUiVcba5HtkBZDPsM0c6YxUV47Ny5s3DhwrrKK6xE4t+j4BA9NMflTaAt4l4XwtC7d28aRClUkQMaV8eWMCqiTResIOgvx7j9cNu3b8/NydlPJoUURh1bgmSgdLpgBXdBu97TRwbQMu3rghX0mZ7rghV4wzxQyQy8BKobzCDzqAtW+Np7vgjU1atXszA3btyoy1YQpV4C1Q2WuXmg0mHzQMUV5poAtozphmGgLly4EO8huLpsBYFH+OlCGIwyEUEQBE+gI/rIAN8ZI9D6yABbxhGICK4gCEIkIYIrCIIQSYjgCoIgRBIiuIIgCJGECK4gCEIkIYIrCIIQSYjgCoIgRBIiuIIgCJGECK4gCEIkIYIrCIIQScS5fPmy2hPE8ld0cRwb4XAQ7iZMCRIkUNszXrsWukUsNXcdGG5hdf/+/ZuO7VdMjLHhKoZ7tUBwcLChMWNUe4KYbL+C8XXHNqPm++GqXS3C9V7btm0nT57M1bEE5+Y1Jg7BUm2/Yu69FGZbD4Mt7121uZsw3jDZvAZj5+Y1lt3GGG88cGxeYzLGkJAQ80ClWXpiGKhg13tMIge6yjPY0DIDtNyPhtBatWrV66+/vnbt2vLlyzNS/YYHaNnLMncDY8cq9+Ey91GgYmyyzPHevHnz6tWrt3Xr1uLFi5t4z8syhzjnz58njg2DXm1ME25bBEq3bt2++eabixcvqlWBCoDJtAFxzCIx1BdsGBXGumwFK8TQmDGiofTZUDLoBmpr6D0GyGu4koH3WrduPW3atAsXLmADTC3Raeg9LJkaW94zXCFg13uoAAe6yjPY0DLeMNnCCmNUAEsWgGW3MfYSqGEhStFcQ3UmUOmJL7wHGNvyHgO0DFRCaOXKldWrV0d2EVyCUL/hAeU9DkzubRCzlznTMWfOnEaNGv3+++/FihUzEVwvyzwU7iEqOk1g/KALYXjC3cJsbSNka8cmH23CBAyQOdAFKwgIL9sIReZuYbb2VbLlalqmfV2wgiwjOu4W5jvv2QpUZtwwUH29W5j/LHN9ZIB5oEb8bmH8w6shtoxtERta9l1PbGGrG35i7D/4yRhjg/ds4Sfz4h3rB2dBEAQhQhDBFQRBiCREcAVBECIJEVxBEIRIwl8EN47jqzC7d+8eNmxYs2bNatas2a1bt2XLll27dk0ZRAhLly5t2bLljh07VHH16tWNGzdeuXKlKgqCIPgUfxHcffv2vfPOO6VLlx48ePCKFSs2b948derUevXqlSxZcubMmSEhIdrODrdu3fr55583bdr09NNPK0Hfv3//woULT58+rQz27t07a9YsXlVREARLgoKCDh8+HBwcrMtm3Lhx48iRI1evXlUr8c6dO0ePHj137lw0/a7FY+MXgvvbb7/VqVNnzZo1jRo1WrBgwaFDh86cOfPHH38MGjQIraRywIABqKe2NmbRokWI+KlTp5w/TIgbNy4NOotFihRp06bNiy++qIqCIHjnwYMHw4cPz5s375w5c3SVGTxNFi5cmCxK/c6F1Kd48eJdu3ZFeZVBLCHqBRd57dWrFwo7YsSIMWPGVKhQIUWKFPHjx8+TJ0+PHj3mzZtXsWLFL7/8cvLkyfoEB5Y/EYHbDmjK02+ZypYtO27cOK6oy/Zx5s6CEEtQWYvJAnRFrRTXxRI7F07UC+60adO2bt3as2fPBg0ahN2UgHvp559/njx58gkTJvBIoip5PDl58uTNmzdVUXH//n2eUAIDA7kJc8yDz4ULF3hgoebYsWOcou1cuH79Ou24fUxM/hsSEnL+/PkTJ07w6vZjPhqkWeq5CqeTPl+8ePHevXvqXU7kXdqkJ27dEwTByfPPP79z585Ro0YldOy7EnuIYsElsV2+fDnJbP369T3d8YoWLcq7O3bsUL9QBB5nSpcuvXjxYlVUoHQ1a9asVatWcHAwIli9evXevXujeh06dChYsOD8+fO1nQszZsx49tlnp0yZossO1V63bl3Lli0JiBw5crzwwgudOnXifqDfduzI8+677zZp0mTNmjWVKlXKly9flSpV9uzZw1vbt29v06YNp2TPnj137tx16tSZPn16bHtiEmIbLFtPT5BeSJAgQdasWdOmTRuBeW600O4oFtyDBw+iU6hb5syZyRl17X/hYeSVV17hYPPmzQgiB0ySwvH+/0MNxrSTIkUKUuaGDRsyr6jn0KFDS5QooY1cUI2ALj/11MyZM5s1a7ZixYrGjRuPGDECoZ87dy7tbNiwQVs4YoU+d+7c+bnnnhs0aFCFChUyZsy4a9euFi1acGLTpk05sVevXuTjzZs3nzRpkj5NEGIiPCAOGTJExTmZx8CBA1u1ajV48GASWGUQLjwaduvWjcdW17+H86S4adOmTz/9lKXUv39/jvUbj2AxkkWRWi1btuy9997juvv371dv7d279+uvv27dunXXrl1JdLBR9X7HlStXSAMRMkbrHWxwLoRrzLM2GkeDqjXgQO0QoS3CwCnfffcdp+AmHs8vX74crjFmGzduzJAhA7mk2p+C2UVSyU85dtqcPn0aVSXzVX/6hMmTJydNmnTBggWkpagwNcOHD0+dOvXSpUuVwfjx4xMlSjRy5EhV3LZtG5kp+enatWvVpir055dffsmZM2fJkiUJEWpu3LiBCtPndu3a3bp1izFSQwc+/PDDePHiEQeOlkL5448/aApRPnHiBEWaIvVmmJ7G2LZtW6Sc61LEhmavXr0arnFYbt++7cl7YcEbQUFBhsagPjMxgTZpmfZ12SsY02d6rstewRhv4BOTbmODn/G2oTHz6Cfew1gFgCUYX7p0iecnXfYMoUUME7Hr16/nWNd6hpY9LXMWEcMn1ElrJk6cSGtAeBcpUqRevXpfffVVlixZAgICCGMMWKGsLBoBzBYuXJg8eXI0Ue0TxFrDkqXEhdTaDAwMJEFJkiQJS5JcNXHixCxeFgXe5l3VGcQUHUBnWFnx48fPlCkTT668O2rUKDI27DlXtZA/f35GzVuq527QmmGg0oJ6OCbH8tSaK7TsZZlDPBXxXJtGvUMmyARzVeUgXfsIvKluVlxMqZW6AGeFNVagUAgWB8wNp9AT5imsMZ5VD+aEIwsDb6puYM/p6qI81KjVyOU4YBZpip5gxjFrlUaAYaoTWWOMQrXDq7pJzJo1i7T0888/f/nll7HBgEbKlCnDHZt76ZIlSwgIGqcRJrVGjRqci3PpD60dP36c4XBFWqMz9Cpv3ryEJrccauiDui7d40IcO0b2/7h6T2XcFLHkIKxxWLDkKuF6LyyqJ3RJl62gZXqlC16h57RMN9QQvIONmgWTB1JljCURZTlGjOkzZgpd6xnaxNuG3qPDjFGFlq7yirn3QBkbeo9ucEC3VY0nUC5cxwGvtK/O8oLyHgdhlzlvEWlKK2iHVYMBB6wsnu14WkUQa9asyRVZLDz8kasWKlSoePHiyh5jzuWAPnMJdJlLsKBolnWNjM6ePbtu3bpdunRh7fz777/IKDkTZv369WPFcWkCAF1mnZJHV65c+eTJk2ju8uXLMSAlev/994sWLUqDixYtoobVxw0gW7Zsah25orzHq6X3uC6WHDBYHGipk86WuWj4EcLCY/C8ZwJXVV4Ol8fYnpFnCk7p3r07Ea9ufeHy559/4tly5coxMRR/+OEHNBq/q3cVJLYqw0WXVc3333/PTY/HEOZA1XATJsP9+eefVZG7NHI5evRojvFm9erVuXOuWrWKouNmEQrHK1eupB06SXzgcWKCWfz77795iwFSw8HUqVOZG07nnjxlypRjx45R6Qbd4Cq6EAbZntE7eAOf6IIV+Nk56ZYwg15izw2feg9jZwBYwoyr+LQkArdnpHsff/wxwsfiUjVnzpwhQaF9VqWqUSB5KC9P96qIBJNVjBgxQs3L7t2706dP36hRIzWn8+bNY4mRJqt8VsEkNmjQALN169apGjSUC9Gyq5eGDh1Ky8iuM5aYI6S/QIEC5NGqJizmgRqjtmfEm7xeuHDB+62DaUDaeJpgCnVVmJ44i2Hr3WqcuNbTATzFPbNp06boac5HoKFNmjThLW656t7FZKdMmZI55ixnC3Xq1Pnoo49Yt9xCmjVr9uKLL3LLRcp57lMGCk89iWRsdcNPjP0HPxljlHiPi4a9Lisid+7c5cuX12UHPNTzihyrosJ5uvOVBcXrmjVrkPjWrVuTDzkMQyEZYllxXyEHUjVciLSmSJEinKVqIG3atIjD+PHjt2zZQiPYkLcOHjyYvEr1IVxUByKfKP6j2fPPP//MM8/s27cPSXV1ohvcqUhwChYs6PxDJMZujwPUeGnBEiaAqeI2++yzz3JvfOERzBnPRFWqVOGYK6p54hnK7UGYOOD2S9o7bty4WrVqIdMcd+rUqXbt2ocPH9ZGghATYVHwxJksWTJddqCWJzm4KnqCNYtcskZoZNeuXTNnzvzpERzv3buXHIt3yV6VPUuPa6ljRVUHixYtevXVV8uWLUves2DBAvQka9asrvmZnxDFgpsjRw7ctH37dp56PH2ecvbsWbJ63IfqqRomSX0EoYoKppYs9bE1l8d51BahHDNmDPfGFS5Q5B7LPRO5R5Qx9nR7zJIlS7t27ZhvhjN37tzq1av//vvvFPXbghBDYUWEuygs1yMGzhP79u3bqFEjHigVHA8cOJBnf1a6+lgZy7CCmylTprFjxw4bNgwlIcsZOnQoefHrr7/OAVKujfyGKBZcJKxFixa47OOPP/7zzz91rQs8xX/99dd//fUXTnT9DS6Ce/HiRV1wcMyBq2qriWRGLWcduBmSye7fv9/5bV8nixcvZu4nT55Mg2Gb4orM6/Dhwzt37szjj6pMkybNG2+80aFDB96ln0qmBUEIC2uKlZUxY8Zly5bt3LmT9EvBqt+4cSNJLk+NPEFq6/AgT+rZs+eUKVPQkNmzZzdu3PjkyZMffPDBxIkTtYXfEMWCC6+88gpPAZcuXXr33XfnzJlz+fJlVc89bc+ePe+//z5axv2qV69eJKHqrWeeeYYnejJHte8XcoZQDhkyhHNdBZeb4Y0bN44ePeq8hXqnbt26tPzVV1/xeMKJ1HDiunXrevfuzbUICE/CTcd27949cuTIH374wXlTRWeXLl3KW0WKFPGUvAtCLIfFmzx58ty5c58/f55HzMKFC5NXKYoWLZorVy5SK5aPpxXE6cePH0cobt68SZZTqFCh+vXrT58+febMmalTp+b5UqXG/kPUCwGubNu27XfffXf//n1uTW+99RZFskWeKdBZfNe8eXMe87NmzapPcPz2DHH8448/sH/vvfdat27NWYkSJapQoYLrH9+YLW6MEyZM6NKlC7qpa//7gQDHzmLBggUHDBhA8e233yal5Sz1XHPmzJnBgwdXrFjRzV7BlJOnd+vWjV4hzWTi3CQ6duxIl8aPH9+gQQNSXW0qCMJ/YfmQx1SpUoWlyjJ3/SMzgkAW9eqrr86bN09Xhcfo0aOrV6/+22+/kWDpqqeeQm0pBgQEuFb6A36ReZGuonELFy4kSUQ3Z82ahRN5lECtli9fzgMFN0Bt6oDH//79+48aNQrjsWPHbtu2rVOnTqhbvnz5nH9Vg5deeumLL75gRidNmqS++60+qHXuFsZkUHROCRNPN+bPn09rBw4cGDFixJo1axD9xYsXo6fKDBsuSnC4ZbvckOk2zzUktnSY+wct//jjj19//XWqVKm0kSAI4VG5cuXatWvPnj2bJb9ixYpz587t3LmTxIU1nidPnjfffFPbhYF0jUdkFh3pEYvuxIkTpEdLlizp2rUruVetWrU8pcZRBo/A5l9vJG/nWVsXwvAY38N1cu/ePWXMbY0T6ZKX7xiioeq7kDxuuFpSxMvq2AmVzJ+qx5LGnd+/oxj2QnQDA/UWZ3Et/cYjqKQRVR8cHOx2RdUlcF7FCa7z9PVGiMzv4dr6cihJhz4ygJbDDtwT9Jme64IV/vM9XJ96L2y8eYIl4Ba6nojA7+EyfPWDUvIbVXP69Gmyjfz58zt/4amYNm0a8fzpp5+qInkMedJXX32lonr79u3ql2bOCzF20pqMGTOqzAahTJEiBU+Hu3btUgaAjJK+bNmyRZcd0CU6kzdvXi7HiUDWRX8mTpzoxT/mgRrx38P1Exg/rzgax+Eyt+9duUHXeSVXdbWkGPYJQtmorBZLGnfe9CiGvZCaBvUWrYX93JZKGglbr1CXA7+7tQrCE0PYk28io87NSXjaa926defOnd2+FlakSJFPPvlEfRAHKCDFUqVKcUehmCVLln79+jVs2NC5YFOmTDl8+HCeRHlA5K3PP/8cjZ48eXKhQoWUAVSrVu2DDz7Ili2bLjtgobVt25a8eMyYMYMGDRo4cOD333+/atUqeuW2tP0C/8lwzX/Aw5zZzTJ8kThA2AzXC5LhuiEZrhu07OcZbljwnrmx3WVubgzmMw7mgRpjM1xBEKIdiAjKpQsRDY3rIwPI8PSRHyOCKwiCEEn8/w5JofmuV5SNJ2Pnu+pVHThrTHA9ywRbLesjK+x2QNmbnOW0DNfY+a5r0fXABHNjLG0Z6yMr7DZry9jtwAu+M1ZgactYH1lhbgmOLhjZKzPXV+84bSLcWIGluTHYalkfWeHogpGxsgR1rCq94LTxZBzn7Nmz8RyEtuqVOI/2bUuYMCFnqkonyZMn7969+4gRIwIDA5XBPQeJEycOaxyWB45d75ImTWpijM3Nmzcx1mUrbty4YWjMGDFOlCiRyZ+8ML5161Z8z/9nmivKe7wmSJAgXO+1adNm+vTp586dw4aakJAQfEJPTBzCM91dx6aRht6j2xjrshXm3gPmhRlXQ/AONhjjDUPvER5MStg/ioYFY7xhy3t42xeBCj71nsnfZnHCqlWr3nrrrRUrVpQrV47O6zc8QMtelvn/tXfvKpEEUQCGHcFFF2+hPoVgJoY+gOaGRr6BqaGJz2BoYCKYKQYqmPoQYupdvLO/27Xi9tjdZxandnX/LximZoqa6lOnzxQM1LTr9DZn8L+eqFxj8Dbn0zc2Nubn5/f39ycnJ8mr9EYFRi4S9d3b/IU/mpX4o1mJP5q91e3odSNRu/qj2T91m6dnAfFE9UczSfqULLiSlIkFV5IyseBKUiYWXEnKxIIrSZlYcCUpEwuuJGViwZWkTCy4kpSJBVeSMuliwS3++yA1mvT29g4MDKRGk1arFe+M721/QVaDkRuPtHjV398fP1X+20+pIen/07q8vOzr6wtWxuJQhqrze5aWllZWVl7/2eLp6en5+TlyvBMY9uHhIV6P7u7u4tW8o8739/fMOVigmTMXGyzQj4+PPL57MBsXvrOzc3JycnZ2Vnw0c6Z/8PQjet7c3AwPD6d2LRbl4uJidHQ0tZucnp7G/weT+TONYECYBrkUOakO19fX8a/w29tbLjN40BSLSP+hoaHUrtXt6I2MjARz7/z8fHBwMPJ9v7u7OzMzc3BwMD09nV6qRTR4ZDNRNOsRPW6ZYKJSE0jUYKipCVSnYFaDdYl3ZmTmHEnUzc3Nubm5o6OjiYmJ9FItLpBhq6L3cjwjaxY8nrE4GYuk5zG9+gtrv7y8vLq6+vYtnse3ll++cw3GoeaOj48fHh4WA1JDyU6WjbeKPjWoAixN8Ig8+nR06h0JFOzMzOnMnCMxoQ/TiB9uSRX4kERtR5ypGvHoMRMCEumMePRAZ6YRjB6ducDGksFybG9vz87Orq+vT01N8UWe3qhQRI8nJGQweuRqlxKVUNM5tZuQTsHORfQiicqAW1tbi4uLe3t7weMZiTCPVdH7yB1uCZND6a/lqrBsV1dXfL2ndi3mwNd7R7sMOjcGtxDfOIDosWzBXTxrzByCOeEOt8QdbkmnO9zU0B/5sB2uBbfEgltiwX3rMxbc4+PjtbU1Ei/SmU/ntuXJF97hgpHJpUio6UNpWlhYGBsbSy/VsuBacH9jwS358gUX3In0DHYmnXgMrgt3LqjOqV2L6BHt4CKCuyDemUWsKnPtGJk5B0NN9IhGMKvrC25oCEmfGiWDspgaTaiJSI0mDMvgqdGk2LSmRhM6s8NLjYBOOzN+ajShOsejV8+CK0mZWHAlKRMLriRlYsGVpEwsuJKUiQVXkjKx4EpSJhZcScrEgitJmVhwJSmLnp4fAlYFKs3lptYAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "j5epiwo7u87M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let us briefly list the tools we have used. For embedding three methods of text vectorization were checked: word2vec -- the same that the authors {AD} took, BERT {BE} and the method proposed in {DU} - deep feature from BiLSTM network on top of GLOVE. For dimension reduction PCA and UMAP were checked. For finding outliers the following algorithms were used: Isolation Forest, DBSCAN, Local Otlier Factor, One Class SVM, Autoencoders with different inner networks (Dense, LSTM, BiLSTM, GRU and CNN were tested with different parameters) and the methods from {AD} - Threshold for Standard deviation error from classifier prediction. Additionally different classifiers were checked, including neural networks. \n",
        "\n",
        "Unfortunately, dimension reduction did not improve the results but even made it significantly worse. Therefore we decided to omit this step in the final version of our pipeline. Let us present the table with accuracy for all combinations (we highlighted the best results in the accuracy column):\n",
        "\n",
        "In each case, the dimensions were reduced to two, perhaps reducing to a higher number would produce better results. In addition, there are still many possibilities to improve the results. Starting from testing other algorithms to text vectorization and ending with changing anomaly detection algorithms.\n",
        "\n",
        "\n",
        "{AD} Amir Bakarov, Ilya Sochenkov, Vasiliy Yadrintsev: \\emph{Anomaly Detection for Short Texts, St. Petersburg, Russia, May 2018}\n",
        "\n",
        "{BE} Jacob Devlin Ming-Wei Chang Kenton Lee Kristina Toutanova: \\emph{BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding, 2018}\n",
        "\n",
        "{DB} Martin Ester, Hans-Peter Kriegel, Jiirg Sander, Xiaowei Xu: \\emph{A Density-Based Algorithm for Discovering Clusters\n",
        "in Large Spatial Databases with Noise, 1996}\n",
        "\n",
        "{DU} Ting-En Lin, Hua Xu: \\emph{Deep Unknown Intent Detection with Margin Loss, 2019}\n",
        "\n",
        "{IS} Fei Tony Liu, Kai Ming Ting, Zhi-Hua Zhou: \\emph{Isolation Forest, 2008}\n",
        "\n",
        "{WV} Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean: \\emph{Distributed Representations of Words and Phrases\n",
        "and their Compositionality, 2013}\n",
        "\n",
        "{LE} Xin Rong: \\emph{word2vec Parameter Learning Explained, 2016}\n",
        "\n",
        "{trees} Sartaj Sahni, \\textit{Data Structures, Algorithms, and Applications in C++}, Silicon Press, 2nd edition, 2004.\n",
        "\n",
        "{CD} \\textit{Curse of dimensionality} Wikipedia, Wikimedia Foundation, 1 August 2022, \\url{ https://en.wikipedia.org/wiki/Curse\\_of\\_dimensionality}"
      ],
      "metadata": {
        "id": "81ghoFvRu_yQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ux7HxkJMlxP"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![results1.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "NL6yPZaPvDsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EecSYPlMXsW",
        "outputId": "31120e52-54ae-4675-f1d4-bf5af410958b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     || 55 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     || 8.2 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=199c7646d642f4805ab4bc1e28737718e0022bf01ca0f8790d40ebb1c2a06c14\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEt2hW0bMXhZ",
        "outputId": "7c5fb6e9-4d6f-4d01-c810-da4c3e3556d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from pandas import DataFrame, concat\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score, make_scorer, f1_score, precision_score\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim import corpora, models\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm as cm\n",
        "from pylab import get_cmap\n",
        "import seaborn\n",
        "\n",
        "from os import path, makedirs\n",
        "from itertools import combinations\n",
        "from re import sub, compile\n",
        "\n",
        "import pickle\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from numpy import average, array\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XKGwlfdLaNL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKFXegGiLlwg"
      },
      "source": [
        "# class - vectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1FJtdQM9-GS"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from numpy import average, array\n",
        "\n",
        "DVACH = '2ch'\n",
        "REDDIT = 'reddit'\n",
        "MTS = 'mts'\n",
        "\n",
        "DATA = REDDIT\n",
        "COMMENT = 'comment'\n",
        "if DATA == REDDIT:\n",
        "    LANG = 'en'\n",
        "else:\n",
        "    LANG = 'ru'\n",
        "\n",
        "\n",
        "\n",
        "RU = 'ru'\n",
        "EN = 'en'\n",
        "\n",
        "class Vectorizer:\n",
        "\n",
        "    def __init__(self, lang=EN):\n",
        "        self._lang = lang\n",
        "        self._tokenizer = self.set_tokenizer()\n",
        "        self._stop = self.set_stop()\n",
        "        self._lemmer = self.set_lemmer()\n",
        "        self._model = self.set_w2v_model()\n",
        "        self._vocab = self.set_w2v_vocab()\n",
        "\n",
        "    def set_tokenizer(self):\n",
        "        if self._lang == EN:\n",
        "            return RegexpTokenizer('[A-Za-z]\\w+')\n",
        "        elif self._lang == RU:\n",
        "            return RegexpTokenizer('[A-Z-a-z-]\\w+')\n",
        "\n",
        "\n",
        "    def set_lemmer(self):\n",
        "        if self._lang == EN:\n",
        "            return WordNetLemmatizer()\n",
        "        elif self._lang == RU:\n",
        "            return MorphAnalyzer()\n",
        "\n",
        "\n",
        "    def set_stop(self):\n",
        "        if self._lang == EN:\n",
        "            return stopwords.words('english')\n",
        "        elif self._lang == RU:\n",
        "            return stopwords.words('russian')\n",
        "\n",
        "\n",
        "    def set_w2v_model(self):\n",
        "        if self._lang == EN:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/gdrive')\n",
        "            import sys\n",
        "            sys.path.insert(0,'/content/gdrive/My Drive/Praca_Licencjacka/models')\n",
        "            return KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Praca_Licencjacka/models/google_news.bin', binary=True)\n",
        "        elif self._lang == RU:\n",
        "            return Word2Vec.load('2ch_model')\n",
        "\n",
        "    def set_w2v_vocab(self):\n",
        "        if self._lang == EN:\n",
        "            return self._model.vocab\n",
        "        elif self._lang == RU:\n",
        "            return self._model.wv.vocab\n",
        "\n",
        "\n",
        "    def __morph__(self, word):\n",
        "        if self._lang == EN:\n",
        "            return self._lemmer.lemmatize(word.lower())\n",
        "        elif self._lang == RU:\n",
        "            return self._lemmer.parse(word.lower())[0].normal_form\n",
        "\n",
        "    def morph_sentence(self,    sent):\n",
        "        return [self.__morph__(word) for word in self._tokenizer.tokenize(sent)\n",
        "            if word.lower() not in self._stop]\n",
        "\n",
        "    def make_vectors(self, t):\n",
        "        t = [str(document) for document in t]\n",
        "        k = [[self.__morph__(word) for word\n",
        "              in self._tokenizer.tokenize(document) if word.lower()\n",
        "              not in self._stop]\n",
        "              for document in t]\n",
        "        vectors = [[self._model[word] for word in sent if word in self._vocab] for sent in k]\n",
        "        return array([average(vector,axis=0) for vector in vectors if vector])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZXH59I1MVQ-",
        "outputId": "b1424f7d-f88a-4e29-94b3-bc28c8985638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "vc = Vectorizer(LANG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpkds3K7L14P"
      },
      "source": [
        "# Preparing DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DMXs-ihAK1S",
        "outputId": "af6c5453-f199-4fb3-d62b-ed88843955ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8MI7BDUNDct"
      },
      "outputs": [],
      "source": [
        "UNKNOWN_CLASS = 'UNKNOWN'\n",
        "\n",
        "appended_data = []\n",
        "for name in range(9):\n",
        "        df = pd.read_csv('/content/gdrive/My Drive/Praca_Licencjacka/reddit-topics/{}.csv'.format(name))\n",
        "        appended_data.append(df)\n",
        "data = pd.concat(appended_data)\n",
        "\n",
        "data_an = pd.read_csv('/content/gdrive/My Drive/Praca_Licencjacka/reddit-topics/{}.csv'.format(9))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MVaHU34PAiGZ",
        "outputId": "0cc9b73e-adc7-4e56-bbd6-9413c1b9675e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9021eb53-70c2-466d-b278-3a85f8f9ad63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>grown with ecm extra cellular matrix 60 minute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>they had a gun shot victim treated with the st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>in your body well they can take a lot of white...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>wherever and it heals they also took out a guy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>make my living harvesting grain with a scythe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>pork neck bones you can use ribs cut into indi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>about 6 inches 1 large nugget of rock sugar or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>bring pot of water to boil add pork to the pot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>you can also serve with vermicelli or rice swi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>you overcooked the meat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9021eb53-70c2-466d-b278-3a85f8f9ad63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9021eb53-70c2-466d-b278-3a85f8f9ad63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9021eb53-70c2-466d-b278-3a85f8f9ad63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Unnamed: 0                                            comment\n",
              "0            0  grown with ecm extra cellular matrix 60 minute...\n",
              "1            1  they had a gun shot victim treated with the st...\n",
              "2            2  in your body well they can take a lot of white...\n",
              "3            3  wherever and it heals they also took out a guy...\n",
              "4            4   make my living harvesting grain with a scythe...\n",
              "..         ...                                                ...\n",
              "95          95  pork neck bones you can use ribs cut into indi...\n",
              "96          96  about 6 inches 1 large nugget of rock sugar or...\n",
              "97          97  bring pot of water to boil add pork to the pot...\n",
              "98          98  you can also serve with vermicelli or rice swi...\n",
              "99          99                            you overcooked the meat\n",
              "\n",
              "[900 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S7jjumI8FaM8",
        "outputId": "fcc50fbc-32de-445b-c20b-5fe2903a0ce2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-af229c9f-2eae-4c86-9298-6297657b1a50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>still i thought the tribute was awful</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>is music was literally popularized because of ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>reat list i d put master of puppets instead of...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>pantera and one of either sepulturatestamentme...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>i also dont think that that many bands deserve...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>personally believe that good kid maad city is ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>it is my happy song</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>his performance gave me chills it also made me...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>liora is a great album that s why</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>taylor is not the first female to win 2 album ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af229c9f-2eae-4c86-9298-6297657b1a50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af229c9f-2eae-4c86-9298-6297657b1a50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af229c9f-2eae-4c86-9298-6297657b1a50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Unnamed: 0                                            comment  label\n",
              "0            0              still i thought the tribute was awful     -1\n",
              "1            1  is music was literally popularized because of ...     -1\n",
              "2            2  reat list i d put master of puppets instead of...     -1\n",
              "3            3  pantera and one of either sepulturatestamentme...     -1\n",
              "4            4  i also dont think that that many bands deserve...     -1\n",
              "..         ...                                                ...    ...\n",
              "95          95  personally believe that good kid maad city is ...     -1\n",
              "96          96                                it is my happy song     -1\n",
              "97          97  his performance gave me chills it also made me...     -1\n",
              "98          98                  liora is a great album that s why     -1\n",
              "99          99  taylor is not the first female to win 2 album ...     -1\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#data_an = data_an.assign(label='-1')\n",
        "data_an.loc[:,'label'] = -1\n",
        "data_an"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB3ddg3KF0Xz"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yM476BhnFRJF",
        "outputId": "b9b53cc4-7a85-4462-b989-2de620e5dfb2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1a32fd2-36af-4f91-b43b-2271ba0f449d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>grown with ecm extra cellular matrix 60 minute...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>they had a gun shot victim treated with the st...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>in your body well they can take a lot of white...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>wherever and it heals they also took out a guy...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>make my living harvesting grain with a scythe...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>pork neck bones you can use ribs cut into indi...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>about 6 inches 1 large nugget of rock sugar or...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>bring pot of water to boil add pork to the pot...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>you can also serve with vermicelli or rice swi...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>you overcooked the meat</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1a32fd2-36af-4f91-b43b-2271ba0f449d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1a32fd2-36af-4f91-b43b-2271ba0f449d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1a32fd2-36af-4f91-b43b-2271ba0f449d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     index  Unnamed: 0                                            comment  \\\n",
              "0        0           0  grown with ecm extra cellular matrix 60 minute...   \n",
              "1        1           1  they had a gun shot victim treated with the st...   \n",
              "2        2           2  in your body well they can take a lot of white...   \n",
              "3        3           3  wherever and it heals they also took out a guy...   \n",
              "4        4           4   make my living harvesting grain with a scythe...   \n",
              "..     ...         ...                                                ...   \n",
              "895     95          95  pork neck bones you can use ribs cut into indi...   \n",
              "896     96          96  about 6 inches 1 large nugget of rock sugar or...   \n",
              "897     97          97  bring pot of water to boil add pork to the pot...   \n",
              "898     98          98  you can also serve with vermicelli or rice swi...   \n",
              "899     99          99                            you overcooked the meat   \n",
              "\n",
              "     label  \n",
              "0      0.0  \n",
              "1      0.0  \n",
              "2      0.0  \n",
              "3      0.0  \n",
              "4      0.0  \n",
              "..     ...  \n",
              "895    8.0  \n",
              "896    8.0  \n",
              "897    8.0  \n",
              "898    8.0  \n",
              "899    8.0  \n",
              "\n",
              "[900 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.loc[:99,'label'] = 0\n",
        "data.loc[100:199,'label'] = 1\n",
        "data.loc[200:299,'label'] = 2\n",
        "data.loc[300:399,'label'] = 3\n",
        "data.loc[400:499,'label'] = 4\n",
        "data.loc[500:599,'label'] = 5\n",
        "data.loc[600:699,'label'] = 6\n",
        "data.loc[700:799,'label'] = 7\n",
        "data.loc[800:899,'label'] = 8\n",
        "# data.loc[:,'label'] = 1\n",
        "# data.loc[:,'label2'] = 0\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWAHCbVOGG7M"
      },
      "outputs": [],
      "source": [
        "data=data.astype({'label': 'int64'})\n",
        "data_an=data_an.astype({'label': 'int64'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iWEJejXaKB0Y",
        "outputId": "7c4f8357-50b8-4e9e-df8e-e5cddb15c17c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e9114cc5-fa6b-458b-b63d-bc1eecf4f0a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>grown with ecm extra cellular matrix 60 minute...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>they had a gun shot victim treated with the st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>in your body well they can take a lot of white...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>wherever and it heals they also took out a guy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>make my living harvesting grain with a scythe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9114cc5-fa6b-458b-b63d-bc1eecf4f0a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9114cc5-fa6b-458b-b63d-bc1eecf4f0a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9114cc5-fa6b-458b-b63d-bc1eecf4f0a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index  Unnamed: 0                                            comment  label\n",
              "0      0           0  grown with ecm extra cellular matrix 60 minute...      0\n",
              "1      1           1  they had a gun shot victim treated with the st...      0\n",
              "2      2           2  in your body well they can take a lot of white...      0\n",
              "3      3           3  wherever and it heals they also took out a guy...      0\n",
              "4      4           4   make my living harvesting grain with a scythe...      0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWlWlKM0KFPh"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['index', 'Unnamed: 0'], axis = 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_0m1KJ7SKYCI",
        "outputId": "be9ca685-7234-4466-caf2-062296e83d06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-245babfb-b9a1-412c-8eb1-212ee56cd13b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>still i thought the tribute was awful</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is music was literally popularized because of ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>reat list i d put master of puppets instead of...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pantera and one of either sepulturatestamentme...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i also dont think that that many bands deserve...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245babfb-b9a1-412c-8eb1-212ee56cd13b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-245babfb-b9a1-412c-8eb1-212ee56cd13b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-245babfb-b9a1-412c-8eb1-212ee56cd13b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             comment  label\n",
              "0              still i thought the tribute was awful     -1\n",
              "1  is music was literally popularized because of ...     -1\n",
              "2  reat list i d put master of puppets instead of...     -1\n",
              "3  pantera and one of either sepulturatestamentme...     -1\n",
              "4  i also dont think that that many bands deserve...     -1"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_an = data_an.drop(['Unnamed: 0'], axis = 1)\n",
        "data_an.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gGes7P9OFVB",
        "outputId": "070da424-4b38-4eb4-a1aa-ee74c2204f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_an.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x1iAkirWKzJP",
        "outputId": "2d24d9d7-fd88-4513-b6a4-a8952f9cae8a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ffd56df-a961-481a-a353-96ead10efe7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>grown with ecm extra cellular matrix 60 minute...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they had a gun shot victim treated with the st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in your body well they can take a lot of white...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wherever and it heals they also took out a guy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>make my living harvesting grain with a scythe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ffd56df-a961-481a-a353-96ead10efe7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ffd56df-a961-481a-a353-96ead10efe7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ffd56df-a961-481a-a353-96ead10efe7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             comment  label\n",
              "0  grown with ecm extra cellular matrix 60 minute...      0\n",
              "1  they had a gun shot victim treated with the st...      0\n",
              "2  in your body well they can take a lot of white...      0\n",
              "3  wherever and it heals they also took out a guy...      0\n",
              "4   make my living harvesting grain with a scythe...      0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRHEAfvyNS3U",
        "outputId": "337cdf9f-974e-4c81-bb67-42bdf77e2430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-WmcMeUL1-s"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "import os\n",
        "from utils import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Modeling\n",
        "# from models import BiLSTM_LMCL\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# # GPU setting\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "# set_allow_growth(device=\"2\")\n",
        "\n",
        "dataset = \"SNIPS\"  # [SNIPS, ATIS] Different dataset\n",
        "proportion = 50 # [25, 50, 75] Different proportion of seen class \n",
        "embedding_path = '/content/gdrive/My Drive/nlp/'\n",
        "EMBEDDING_FILE = os.path.join(embedding_path, 'glove.6B.100d.txt')\n",
        "MAX_SEQ_LEN = None\n",
        "MAX_NUM_WORDS = 10000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# df, partition_to_n_row = load_data(dataset)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGDe27UlZ9uG"
      },
      "source": [
        "# Creating train and test set \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T7rfRZeLhQe"
      },
      "outputs": [],
      "source": [
        "text_train, text_test0, y_train, y_test0, db_train, db_test = train_test_split(data['comment'], data['label'], data['label2'], test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSkOJ8EIInfh"
      },
      "outputs": [],
      "source": [
        "text_train, text_test0, y_train, y_test0 = train_test_split(data['comment'], data['label'], test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjw676gnugNl"
      },
      "source": [
        "creating validation set for training classifier "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lo4I6IcuYAv"
      },
      "outputs": [],
      "source": [
        "text_train, text_val, y_train, y_val = train_test_split(text_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EucCLVOKN6YC"
      },
      "outputs": [],
      "source": [
        "df=data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwph48WWP9Z8",
        "outputId": "3db3af22-9df7-4c30-8768-bf38caf41133"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMxYvkg_N3ND"
      },
      "outputs": [],
      "source": [
        "data['content_words'] = data['comment'].apply(lambda s: word_tokenize(s))\n",
        "texts = data['content_words'].apply(lambda l: \" \".join(l))\n",
        "\n",
        "data_an['content_words'] = data_an['comment'].apply(lambda s: word_tokenize(s))\n",
        "texts_an = data_an['content_words'].apply(lambda l: \" \".join(l))\n",
        "\n",
        "\n",
        "\n",
        "# Do not filter out \",\" and \".\"\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<UNK>\", filters='!\"#$%&()*+-/:;<=>@[\\]^_`{|}~') \n",
        "\n",
        "tokenizer.fit_on_texts(texts)\n",
        "tokenizer.fit_on_texts(texts_an)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "sequences_an = tokenizer.texts_to_sequences(texts_an)\n",
        "sequences_pad = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDCbD5XQZwx",
        "outputId": "283a5048-9520-42b7-88c1-22783f600fc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(900, 98)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugsFW97OP5ki"
      },
      "outputs": [],
      "source": [
        "sequences_pad_an = pad_sequences(sequences_an, maxlen=98, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4q0ahh7Ofva",
        "outputId": "efae7d37-a416-4785-b4d6-af184c4845a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load pre-trained GloVe embedding...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ],
      "source": [
        "print(\"Load pre-trained GloVe embedding...\")\n",
        "MAX_FEATURES = min(MAX_NUM_WORDS, len(word_index)) + 1  # +1 for PAD\n",
        "\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (MAX_FEATURES, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_FEATURES: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcwWqQWyUniu"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.layers.core import Lambda\n",
        "from keras.constraints import unit_norm\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def large_margin_cosine_loss(y_true, y_pred, scale=30, margin=0.35):\n",
        "    y_pred = y_true * (y_pred - margin) + (1 - y_true) * y_pred\n",
        "    y_pred *= scale\n",
        "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n",
        "\n",
        "def BiLSTM_LMCL(max_seq_len, max_features, embedding_dim, output_dim, model_img_path=None, embedding_matrix=None):\n",
        "    model = Sequential()\n",
        "    if embedding_matrix is None:\n",
        "        model.add(Embedding(max_features, embedding_dim, input_length=max_seq_len, mask_zero=True))\n",
        "    else:\n",
        "        model.add(Embedding(max_features, embedding_dim, input_length=max_seq_len, mask_zero=True,\n",
        "                            weights=[embedding_matrix], trainable=True))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.5)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n",
        "    adam = RMSprop(lr=0.003, clipnorm=5.)\n",
        "    \n",
        "    model.add(Dense(output_dim, use_bias=False, kernel_constraint=unit_norm()))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=large_margin_cosine_loss, optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "    if model_img_path:\n",
        "        plot_model(model, to_file=model_img_path, show_shapes=True, show_layer_names=False)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19jhrsgmUyuW"
      },
      "outputs": [],
      "source": [
        "text_train, X_test0, y_train, y_test0 = train_test_split(sequences_pad, data['label'], test_size=0.1, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEWmu9KuVCnm"
      },
      "outputs": [],
      "source": [
        "#test set = (X_test + y_test) + anomaly class\n",
        "X_test = np.vstack([X_test0, sequences_pad_an]) \n",
        "y_test = pd.concat([y_test0,data_an['label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrwNqCjGWmrh"
      },
      "outputs": [],
      "source": [
        "y_test = pd.concat([y_test0,data_an['label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXHmx71hVrAu",
        "outputId": "4e2940cb-99d1-44de-90b0-f2347e8c9153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(648, 98)\n",
            "(162, 98)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(190, 98)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ot6_vkFjgAM"
      },
      "outputs": [],
      "source": [
        "y_train_onehot = to_categorical(y_train)\n",
        "y_test_onehot = to_categorical(y_test,num_classes=10)\n",
        "y_valid_onehot = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEn-3Yt4lOzA",
        "outputId": "fa35526d-fb64-4a26-eeaa-f8b5cf4568ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "804    8\n",
              "720    7\n",
              "746    7\n",
              "772    7\n",
              "43     0\n",
              "      ..\n",
              "649    6\n",
              "629    6\n",
              "248    2\n",
              "320    3\n",
              "599    5\n",
              "Name: label, Length: 648, dtype: int64"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVQ9RW9XlY2p",
        "outputId": "dcf600e7-051c-4af7-af8b-946e9c06ec29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(648, 9)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPzxDi-plxRR",
        "outputId": "6a7a4099-020a-45dc-8316-05eaaa2577eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9An7lUpkmzOf",
        "outputId": "55f88b38-f894-401b-dcca-ffbefbafc70d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "190"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RZTgYKAm3VB",
        "outputId": "d8daf52e-8a39-41db-8b68-e0a16f5d7003"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70     0\n",
              "827    8\n",
              "231    2\n",
              "588    5\n",
              "39     0\n",
              "      ..\n",
              "95    -1\n",
              "96    -1\n",
              "97    -1\n",
              "98    -1\n",
              "99    -1\n",
              "Name: label, Length: 190, dtype: int64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vUB9VIymu78",
        "outputId": "9d3f2075-36eb-443d-b2df-9c6c5d3dd6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "8\n",
            "2\n",
            "5\n",
            "0\n",
            "7\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "5\n",
            "8\n",
            "1\n",
            "7\n",
            "5\n",
            "1\n",
            "4\n",
            "4\n",
            "0\n",
            "2\n",
            "7\n",
            "6\n",
            "3\n",
            "5\n",
            "3\n",
            "0\n",
            "8\n",
            "6\n",
            "5\n",
            "2\n",
            "7\n",
            "2\n",
            "5\n",
            "6\n",
            "6\n",
            "0\n",
            "5\n",
            "4\n",
            "2\n",
            "0\n",
            "2\n",
            "3\n",
            "7\n",
            "6\n",
            "6\n",
            "2\n",
            "5\n",
            "4\n",
            "8\n",
            "4\n",
            "3\n",
            "5\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "3\n",
            "3\n",
            "5\n",
            "0\n",
            "3\n",
            "7\n",
            "4\n",
            "2\n",
            "1\n",
            "6\n",
            "5\n",
            "3\n",
            "4\n",
            "6\n",
            "5\n",
            "8\n",
            "3\n",
            "1\n",
            "8\n",
            "3\n",
            "4\n",
            "0\n",
            "6\n",
            "5\n",
            "1\n",
            "5\n",
            "0\n",
            "8\n",
            "7\n",
            "3\n",
            "4\n",
            "2\n",
            "5\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n"
          ]
        }
      ],
      "source": [
        "for i in range(190): \n",
        "  print(y_test.iloc[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg9Wl_nFlcf7",
        "outputId": "b90d6f46-1687-49f7-f8b2-a0dd112715c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "for i in range(190): print(y_test_onehot[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFBUsY0_lS34",
        "outputId": "f89b3682-672d-47c8-d370-2ac91b879d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "342    3\n",
              "573    5\n",
              "425    4\n",
              "11     0\n",
              "650    6\n",
              "      ..\n",
              "205    2\n",
              "71     0\n",
              "728    7\n",
              "646    6\n",
              "421    4\n",
              "Name: label, Length: 162, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXhCG8DsjcCc"
      },
      "outputs": [],
      "source": [
        "filepath = 'data/BiLSTM_' + dataset + \"_\" + str(proportion) + '-AM.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
        "                             save_best_only=True, mode='auto', save_weights_only=False)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, mode='auto') \n",
        "callbacks_list = [checkpoint, early_stop]\n",
        "\n",
        "train_data = (X_train, y_train_onehot)\n",
        "valid_data = (X_val, y_valid_onehot)\n",
        "test_data = (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwBoca5zAwkI",
        "outputId": "507ff70f-f0f5-41f9-ad20-22aa7287b6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "3/3 - 23s - loss: 12.5881 - accuracy: 0.1404 - val_loss: 12.4251 - val_accuracy: 0.2160 - 23s/epoch - 8s/step\n",
            "Epoch 2/200\n",
            "3/3 - 3s - loss: 12.4116 - accuracy: 0.2176 - val_loss: 12.4834 - val_accuracy: 0.1667 - 3s/epoch - 1s/step\n",
            "Epoch 3/200\n",
            "3/3 - 4s - loss: 12.3224 - accuracy: 0.2716 - val_loss: 11.9561 - val_accuracy: 0.2963 - 4s/epoch - 1s/step\n",
            "Epoch 4/200\n",
            "3/3 - 3s - loss: 12.2085 - accuracy: 0.3256 - val_loss: 11.8203 - val_accuracy: 0.3642 - 3s/epoch - 1s/step\n",
            "Epoch 5/200\n",
            "3/3 - 3s - loss: 11.8223 - accuracy: 0.5031 - val_loss: 12.5560 - val_accuracy: 0.2654 - 3s/epoch - 1s/step\n",
            "Epoch 6/200\n",
            "3/3 - 3s - loss: 11.9171 - accuracy: 0.4383 - val_loss: 12.3835 - val_accuracy: 0.2593 - 3s/epoch - 1s/step\n",
            "Epoch 7/200\n",
            "3/3 - 3s - loss: 11.7893 - accuracy: 0.5417 - val_loss: 11.3263 - val_accuracy: 0.4506 - 3s/epoch - 1s/step\n",
            "Epoch 8/200\n",
            "3/3 - 3s - loss: 11.2803 - accuracy: 0.6590 - val_loss: 10.9323 - val_accuracy: 0.5247 - 3s/epoch - 1s/step\n",
            "Epoch 9/200\n",
            "3/3 - 3s - loss: 11.1103 - accuracy: 0.6914 - val_loss: 11.6691 - val_accuracy: 0.3148 - 3s/epoch - 1s/step\n",
            "Epoch 10/200\n",
            "3/3 - 3s - loss: 11.3913 - accuracy: 0.5324 - val_loss: 10.6522 - val_accuracy: 0.6481 - 3s/epoch - 1s/step\n",
            "Epoch 11/200\n",
            "3/3 - 3s - loss: 10.8525 - accuracy: 0.7485 - val_loss: 10.5360 - val_accuracy: 0.5926 - 3s/epoch - 1s/step\n",
            "Epoch 12/200\n",
            "3/3 - 3s - loss: 10.7406 - accuracy: 0.7423 - val_loss: 10.4141 - val_accuracy: 0.5988 - 3s/epoch - 1s/step\n",
            "Epoch 13/200\n",
            "3/3 - 3s - loss: 10.5497 - accuracy: 0.8102 - val_loss: 10.0878 - val_accuracy: 0.6852 - 3s/epoch - 1s/step\n",
            "Epoch 14/200\n",
            "3/3 - 3s - loss: 10.5315 - accuracy: 0.7855 - val_loss: 10.4475 - val_accuracy: 0.6296 - 3s/epoch - 1s/step\n",
            "Epoch 15/200\n",
            "3/3 - 3s - loss: 10.5446 - accuracy: 0.7500 - val_loss: 10.2719 - val_accuracy: 0.6296 - 3s/epoch - 1s/step\n",
            "Epoch 16/200\n",
            "3/3 - 3s - loss: 10.4270 - accuracy: 0.8179 - val_loss: 9.9011 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 17/200\n",
            "3/3 - 3s - loss: 10.2816 - accuracy: 0.8549 - val_loss: 9.8810 - val_accuracy: 0.7160 - 3s/epoch - 1s/step\n",
            "Epoch 18/200\n",
            "3/3 - 3s - loss: 10.1794 - accuracy: 0.8812 - val_loss: 9.4891 - val_accuracy: 0.7531 - 3s/epoch - 1s/step\n",
            "Epoch 19/200\n",
            "3/3 - 3s - loss: 10.0099 - accuracy: 0.9151 - val_loss: 9.7527 - val_accuracy: 0.7160 - 3s/epoch - 1s/step\n",
            "Epoch 20/200\n",
            "3/3 - 3s - loss: 10.0237 - accuracy: 0.9059 - val_loss: 9.8023 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 21/200\n",
            "3/3 - 3s - loss: 10.0381 - accuracy: 0.9136 - val_loss: 9.4836 - val_accuracy: 0.7346 - 3s/epoch - 1s/step\n",
            "Epoch 22/200\n",
            "3/3 - 3s - loss: 9.9172 - accuracy: 0.9259 - val_loss: 9.6845 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 23/200\n",
            "3/3 - 3s - loss: 9.9608 - accuracy: 0.9444 - val_loss: 9.2680 - val_accuracy: 0.8086 - 3s/epoch - 1s/step\n",
            "Epoch 24/200\n",
            "3/3 - 3s - loss: 9.7529 - accuracy: 0.9522 - val_loss: 9.1962 - val_accuracy: 0.7963 - 3s/epoch - 1s/step\n",
            "Epoch 25/200\n",
            "3/3 - 3s - loss: 9.7456 - accuracy: 0.9522 - val_loss: 9.0702 - val_accuracy: 0.8086 - 3s/epoch - 1s/step\n",
            "Epoch 26/200\n",
            "3/3 - 3s - loss: 9.7239 - accuracy: 0.9707 - val_loss: 9.7624 - val_accuracy: 0.6975 - 3s/epoch - 1s/step\n",
            "Epoch 27/200\n",
            "3/3 - 3s - loss: 9.7790 - accuracy: 0.9352 - val_loss: 9.4308 - val_accuracy: 0.7593 - 3s/epoch - 1s/step\n",
            "Epoch 28/200\n",
            "3/3 - 3s - loss: 9.8637 - accuracy: 0.9475 - val_loss: 9.0772 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 29/200\n",
            "3/3 - 3s - loss: 9.6389 - accuracy: 0.9830 - val_loss: 9.3145 - val_accuracy: 0.7963 - 3s/epoch - 1s/step\n",
            "Epoch 30/200\n",
            "3/3 - 3s - loss: 9.6697 - accuracy: 0.9707 - val_loss: 9.0470 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 31/200\n",
            "3/3 - 3s - loss: 9.6041 - accuracy: 0.9784 - val_loss: 9.3939 - val_accuracy: 0.7716 - 3s/epoch - 1s/step\n",
            "Epoch 32/200\n",
            "3/3 - 5s - loss: 9.6479 - accuracy: 0.9722 - val_loss: 9.0119 - val_accuracy: 0.8272 - 5s/epoch - 2s/step\n",
            "Epoch 33/200\n",
            "3/3 - 5s - loss: 9.5271 - accuracy: 0.9923 - val_loss: 9.0284 - val_accuracy: 0.8333 - 5s/epoch - 2s/step\n",
            "Epoch 34/200\n",
            "3/3 - 3s - loss: 9.5181 - accuracy: 0.9907 - val_loss: 8.9943 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 35/200\n",
            "3/3 - 3s - loss: 9.5486 - accuracy: 0.9861 - val_loss: 9.3092 - val_accuracy: 0.7840 - 3s/epoch - 1s/step\n",
            "Epoch 36/200\n",
            "3/3 - 3s - loss: 9.5771 - accuracy: 0.9877 - val_loss: 8.9869 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 37/200\n",
            "3/3 - 3s - loss: 9.5166 - accuracy: 0.9923 - val_loss: 9.0619 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 38/200\n",
            "3/3 - 3s - loss: 9.5615 - accuracy: 0.9799 - val_loss: 9.0098 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 39/200\n",
            "3/3 - 3s - loss: 9.4418 - accuracy: 0.9985 - val_loss: 8.8764 - val_accuracy: 0.8210 - 3s/epoch - 1s/step\n",
            "Epoch 40/200\n",
            "3/3 - 3s - loss: 9.4640 - accuracy: 0.9861 - val_loss: 8.9214 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 41/200\n",
            "3/3 - 3s - loss: 9.4067 - accuracy: 0.9923 - val_loss: 9.0587 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 42/200\n",
            "3/3 - 3s - loss: 9.4380 - accuracy: 0.9969 - val_loss: 8.9051 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 43/200\n",
            "3/3 - 3s - loss: 9.4962 - accuracy: 0.9830 - val_loss: 9.0804 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 44/200\n",
            "3/3 - 3s - loss: 9.4735 - accuracy: 0.9938 - val_loss: 8.8804 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 45/200\n",
            "3/3 - 3s - loss: 9.3790 - accuracy: 0.9969 - val_loss: 9.0867 - val_accuracy: 0.8210 - 3s/epoch - 1s/step\n",
            "Epoch 46/200\n",
            "3/3 - 3s - loss: 9.4611 - accuracy: 0.9923 - val_loss: 8.7716 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 47/200\n",
            "3/3 - 3s - loss: 9.3529 - accuracy: 0.9985 - val_loss: 9.1478 - val_accuracy: 0.7778 - 3s/epoch - 1s/step\n",
            "Epoch 48/200\n",
            "3/3 - 3s - loss: 9.5270 - accuracy: 0.9769 - val_loss: 8.7960 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 49/200\n",
            "3/3 - 3s - loss: 9.3612 - accuracy: 0.9938 - val_loss: 8.7571 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 50/200\n",
            "3/3 - 3s - loss: 9.3131 - accuracy: 1.0000 - val_loss: 8.6684 - val_accuracy: 0.8765 - 3s/epoch - 1s/step\n",
            "Epoch 51/200\n",
            "3/3 - 3s - loss: 9.3248 - accuracy: 0.9969 - val_loss: 8.8434 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 52/200\n",
            "3/3 - 3s - loss: 9.3185 - accuracy: 0.9985 - val_loss: 8.9583 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 53/200\n",
            "3/3 - 3s - loss: 9.3584 - accuracy: 0.9954 - val_loss: 9.0674 - val_accuracy: 0.7963 - 3s/epoch - 1s/step\n",
            "Epoch 54/200\n",
            "3/3 - 3s - loss: 9.3641 - accuracy: 0.9938 - val_loss: 9.0562 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 55/200\n",
            "3/3 - 3s - loss: 9.3833 - accuracy: 0.9969 - val_loss: 8.6989 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n",
            "Epoch 56/200\n",
            "3/3 - 3s - loss: 9.3287 - accuracy: 1.0000 - val_loss: 8.6593 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 57/200\n",
            "3/3 - 3s - loss: 9.2776 - accuracy: 1.0000 - val_loss: 8.7601 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 58/200\n",
            "3/3 - 3s - loss: 9.2941 - accuracy: 0.9985 - val_loss: 8.8389 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 59/200\n",
            "3/3 - 3s - loss: 9.2951 - accuracy: 1.0000 - val_loss: 8.7121 - val_accuracy: 0.8889 - 3s/epoch - 1s/step\n",
            "Epoch 60/200\n",
            "3/3 - 3s - loss: 9.2899 - accuracy: 1.0000 - val_loss: 8.6674 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 61/200\n",
            "3/3 - 3s - loss: 9.2896 - accuracy: 1.0000 - val_loss: 9.1141 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 62/200\n",
            "3/3 - 3s - loss: 9.3637 - accuracy: 0.9892 - val_loss: 8.5594 - val_accuracy: 0.8951 - 3s/epoch - 1s/step\n",
            "Epoch 63/200\n",
            "3/3 - 3s - loss: 9.3019 - accuracy: 0.9985 - val_loss: 9.0814 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 64/200\n",
            "3/3 - 3s - loss: 9.3033 - accuracy: 1.0000 - val_loss: 8.8023 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 65/200\n",
            "3/3 - 3s - loss: 9.2765 - accuracy: 1.0000 - val_loss: 8.6486 - val_accuracy: 0.8889 - 3s/epoch - 1s/step\n",
            "Epoch 66/200\n",
            "3/3 - 3s - loss: 9.2528 - accuracy: 0.9985 - val_loss: 8.6152 - val_accuracy: 0.9012 - 3s/epoch - 1s/step\n",
            "Epoch 67/200\n",
            "3/3 - 3s - loss: 9.3298 - accuracy: 1.0000 - val_loss: 8.8194 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 68/200\n",
            "3/3 - 3s - loss: 9.2862 - accuracy: 1.0000 - val_loss: 9.0514 - val_accuracy: 0.8210 - 3s/epoch - 1s/step\n",
            "Epoch 69/200\n",
            "3/3 - 3s - loss: 9.3432 - accuracy: 0.9923 - val_loss: 8.6200 - val_accuracy: 0.9012 - 3s/epoch - 1s/step\n",
            "Epoch 70/200\n",
            "3/3 - 3s - loss: 9.2533 - accuracy: 1.0000 - val_loss: 8.6376 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 71/200\n",
            "3/3 - 3s - loss: 9.2529 - accuracy: 1.0000 - val_loss: 8.6277 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n",
            "Epoch 72/200\n",
            "3/3 - 3s - loss: 9.2506 - accuracy: 1.0000 - val_loss: 8.7917 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n",
            "Epoch 73/200\n",
            "3/3 - 3s - loss: 9.2512 - accuracy: 1.0000 - val_loss: 8.6427 - val_accuracy: 0.8951 - 3s/epoch - 1s/step\n",
            "Epoch 74/200\n",
            "3/3 - 3s - loss: 9.2650 - accuracy: 1.0000 - val_loss: 8.8581 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 75/200\n",
            "3/3 - 3s - loss: 9.2958 - accuracy: 0.9969 - val_loss: 8.7540 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 76/200\n",
            "3/3 - 3s - loss: 9.2495 - accuracy: 1.0000 - val_loss: 8.7299 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 77/200\n",
            "3/3 - 3s - loss: 9.2718 - accuracy: 0.9985 - val_loss: 8.6858 - val_accuracy: 0.8765 - 3s/epoch - 1s/step\n",
            "Epoch 78/200\n",
            "3/3 - 3s - loss: 9.2233 - accuracy: 1.0000 - val_loss: 8.6684 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n",
            "Epoch 79/200\n",
            "3/3 - 4s - loss: 9.2288 - accuracy: 1.0000 - val_loss: 8.7349 - val_accuracy: 0.8704 - 4s/epoch - 1s/step\n",
            "Epoch 80/200\n",
            "3/3 - 3s - loss: 9.2677 - accuracy: 1.0000 - val_loss: 8.6987 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 81/200\n",
            "3/3 - 3s - loss: 9.2505 - accuracy: 1.0000 - val_loss: 8.8943 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 82/200\n",
            "3/3 - 3s - loss: 9.2327 - accuracy: 1.0000 - val_loss: 8.5882 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n"
          ]
        }
      ],
      "source": [
        "    # model.add(Bidirectional(LSTM(128, dropout=0.5)))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n",
        "    # adam = RMSprop(lr=0.003, clipnorm=5.)\n",
        "\n",
        "## If you want to plot the model\n",
        "# model = BiLSTM_LMCL(MAX_SEQ_LEN, MAX_FEATURES, EMBEDDING_DIM, n_class_seen, 'img/model.png', embedding_matrix)\n",
        "model = BiLSTM_LMCL(MAX_SEQ_LEN, MAX_FEATURES, EMBEDDING_DIM, 9, None, embedding_matrix)\n",
        "history = model.fit(train_data[0], train_data[1], epochs=200, batch_size=256, \n",
        "                    validation_data=valid_data, shuffle=True, verbose=2, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfn_sJpbTjgg",
        "outputId": "074c0742-4e0c-43cd-b915-c0906da8664e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 - 50s - loss: 12.5720 - accuracy: 0.1404 - val_loss: 12.4790 - val_accuracy: 0.1605 - 50s/epoch - 17s/step\n",
            "Epoch 2/200\n",
            "3/3 - 3s - loss: 12.4207 - accuracy: 0.2932 - val_loss: 12.2120 - val_accuracy: 0.3765 - 3s/epoch - 1s/step\n",
            "Epoch 3/200\n",
            "3/3 - 3s - loss: 12.2333 - accuracy: 0.4275 - val_loss: 11.8312 - val_accuracy: 0.4753 - 3s/epoch - 1s/step\n",
            "Epoch 4/200\n",
            "3/3 - 3s - loss: 11.9315 - accuracy: 0.5123 - val_loss: 11.9031 - val_accuracy: 0.3642 - 3s/epoch - 1s/step\n",
            "Epoch 5/200\n",
            "3/3 - 3s - loss: 11.7509 - accuracy: 0.5139 - val_loss: 11.4293 - val_accuracy: 0.4630 - 3s/epoch - 1s/step\n",
            "Epoch 6/200\n",
            "3/3 - 3s - loss: 11.4870 - accuracy: 0.5833 - val_loss: 11.0933 - val_accuracy: 0.5370 - 3s/epoch - 1s/step\n",
            "Epoch 7/200\n",
            "3/3 - 3s - loss: 11.2884 - accuracy: 0.6481 - val_loss: 10.9779 - val_accuracy: 0.5741 - 3s/epoch - 1s/step\n",
            "Epoch 8/200\n",
            "3/3 - 3s - loss: 11.0337 - accuracy: 0.7222 - val_loss: 10.6774 - val_accuracy: 0.6173 - 3s/epoch - 1s/step\n",
            "Epoch 9/200\n",
            "3/3 - 3s - loss: 10.8677 - accuracy: 0.7593 - val_loss: 10.5307 - val_accuracy: 0.5926 - 3s/epoch - 1s/step\n",
            "Epoch 10/200\n",
            "3/3 - 3s - loss: 10.7380 - accuracy: 0.7793 - val_loss: 10.3606 - val_accuracy: 0.6358 - 3s/epoch - 1s/step\n",
            "Epoch 11/200\n",
            "3/3 - 3s - loss: 10.6111 - accuracy: 0.8210 - val_loss: 10.0619 - val_accuracy: 0.7037 - 3s/epoch - 1s/step\n",
            "Epoch 12/200\n",
            "3/3 - 3s - loss: 10.4515 - accuracy: 0.8395 - val_loss: 9.8946 - val_accuracy: 0.7346 - 3s/epoch - 1s/step\n",
            "Epoch 13/200\n",
            "3/3 - 3s - loss: 10.3419 - accuracy: 0.8611 - val_loss: 9.9813 - val_accuracy: 0.7037 - 3s/epoch - 1s/step\n",
            "Epoch 14/200\n",
            "3/3 - 3s - loss: 10.2188 - accuracy: 0.8642 - val_loss: 9.7782 - val_accuracy: 0.7469 - 3s/epoch - 1s/step\n",
            "Epoch 15/200\n",
            "3/3 - 3s - loss: 10.1568 - accuracy: 0.9043 - val_loss: 9.6851 - val_accuracy: 0.7469 - 3s/epoch - 1s/step\n",
            "Epoch 16/200\n",
            "3/3 - 3s - loss: 10.0457 - accuracy: 0.9012 - val_loss: 9.5048 - val_accuracy: 0.7531 - 3s/epoch - 1s/step\n",
            "Epoch 17/200\n",
            "3/3 - 3s - loss: 9.9832 - accuracy: 0.9306 - val_loss: 9.4382 - val_accuracy: 0.7840 - 3s/epoch - 1s/step\n",
            "Epoch 18/200\n",
            "3/3 - 3s - loss: 9.9234 - accuracy: 0.9259 - val_loss: 9.4532 - val_accuracy: 0.7593 - 3s/epoch - 1s/step\n",
            "Epoch 19/200\n",
            "3/3 - 3s - loss: 9.8450 - accuracy: 0.9537 - val_loss: 9.4910 - val_accuracy: 0.7716 - 3s/epoch - 1s/step\n",
            "Epoch 20/200\n",
            "3/3 - 3s - loss: 9.7966 - accuracy: 0.9460 - val_loss: 9.4075 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 21/200\n",
            "3/3 - 3s - loss: 9.8322 - accuracy: 0.9414 - val_loss: 9.4197 - val_accuracy: 0.8025 - 3s/epoch - 1s/step\n",
            "Epoch 22/200\n",
            "3/3 - 3s - loss: 9.8681 - accuracy: 0.9414 - val_loss: 9.6010 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 23/200\n",
            "3/3 - 3s - loss: 9.8357 - accuracy: 0.9583 - val_loss: 9.5780 - val_accuracy: 0.7593 - 3s/epoch - 1s/step\n",
            "Epoch 24/200\n",
            "3/3 - 3s - loss: 9.8092 - accuracy: 0.9460 - val_loss: 9.4599 - val_accuracy: 0.7407 - 3s/epoch - 1s/step\n",
            "Epoch 25/200\n",
            "3/3 - 3s - loss: 9.7890 - accuracy: 0.9475 - val_loss: 9.4678 - val_accuracy: 0.7840 - 3s/epoch - 1s/step\n",
            "Epoch 26/200\n",
            "3/3 - 3s - loss: 9.7580 - accuracy: 0.9568 - val_loss: 9.4746 - val_accuracy: 0.7901 - 3s/epoch - 1s/step\n",
            "Epoch 27/200\n",
            "3/3 - 3s - loss: 9.7869 - accuracy: 0.9475 - val_loss: 9.3799 - val_accuracy: 0.7778 - 3s/epoch - 1s/step\n",
            "Epoch 28/200\n",
            "3/3 - 3s - loss: 9.6590 - accuracy: 0.9707 - val_loss: 9.1421 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 29/200\n",
            "3/3 - 3s - loss: 9.6374 - accuracy: 0.9738 - val_loss: 9.0510 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 30/200\n",
            "3/3 - 3s - loss: 9.6064 - accuracy: 0.9830 - val_loss: 8.9889 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 31/200\n",
            "3/3 - 3s - loss: 9.5833 - accuracy: 0.9784 - val_loss: 9.0982 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 32/200\n",
            "3/3 - 3s - loss: 9.5361 - accuracy: 0.9923 - val_loss: 8.9673 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 33/200\n",
            "3/3 - 3s - loss: 9.4961 - accuracy: 0.9892 - val_loss: 8.8839 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 34/200\n",
            "3/3 - 3s - loss: 9.4668 - accuracy: 0.9907 - val_loss: 8.8949 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 35/200\n",
            "3/3 - 3s - loss: 9.4608 - accuracy: 0.9938 - val_loss: 8.8816 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 36/200\n",
            "3/3 - 3s - loss: 9.4377 - accuracy: 0.9969 - val_loss: 8.8143 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 37/200\n",
            "3/3 - 3s - loss: 9.4272 - accuracy: 0.9938 - val_loss: 8.7905 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 38/200\n",
            "3/3 - 3s - loss: 9.4158 - accuracy: 0.9892 - val_loss: 8.8424 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 39/200\n",
            "3/3 - 3s - loss: 9.4164 - accuracy: 0.9969 - val_loss: 9.0084 - val_accuracy: 0.8272 - 3s/epoch - 1s/step\n",
            "Epoch 40/200\n",
            "3/3 - 3s - loss: 9.3971 - accuracy: 0.9969 - val_loss: 8.9464 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 41/200\n",
            "3/3 - 3s - loss: 9.4403 - accuracy: 0.9923 - val_loss: 8.7984 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 42/200\n",
            "3/3 - 3s - loss: 9.4270 - accuracy: 0.9923 - val_loss: 8.8717 - val_accuracy: 0.8765 - 3s/epoch - 1s/step\n",
            "Epoch 43/200\n",
            "3/3 - 3s - loss: 9.4894 - accuracy: 0.9969 - val_loss: 9.1026 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 44/200\n",
            "3/3 - 3s - loss: 9.4968 - accuracy: 0.9985 - val_loss: 9.1683 - val_accuracy: 0.8025 - 3s/epoch - 1s/step\n",
            "Epoch 45/200\n",
            "3/3 - 3s - loss: 9.4448 - accuracy: 1.0000 - val_loss: 8.9695 - val_accuracy: 0.8333 - 3s/epoch - 1s/step\n",
            "Epoch 46/200\n",
            "3/3 - 3s - loss: 9.4282 - accuracy: 0.9985 - val_loss: 9.0317 - val_accuracy: 0.8272 - 3s/epoch - 1s/step\n",
            "Epoch 47/200\n",
            "3/3 - 3s - loss: 9.4205 - accuracy: 0.9969 - val_loss: 8.9442 - val_accuracy: 0.8210 - 3s/epoch - 1s/step\n",
            "Epoch 48/200\n",
            "3/3 - 3s - loss: 9.3892 - accuracy: 1.0000 - val_loss: 9.0305 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 49/200\n",
            "3/3 - 3s - loss: 9.3767 - accuracy: 0.9985 - val_loss: 8.9717 - val_accuracy: 0.8148 - 3s/epoch - 1s/step\n",
            "Epoch 50/200\n",
            "3/3 - 3s - loss: 9.3528 - accuracy: 1.0000 - val_loss: 8.9509 - val_accuracy: 0.8395 - 3s/epoch - 1s/step\n",
            "Epoch 51/200\n",
            "3/3 - 3s - loss: 9.3597 - accuracy: 0.9985 - val_loss: 8.8883 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 52/200\n",
            "3/3 - 3s - loss: 9.3339 - accuracy: 1.0000 - val_loss: 8.6868 - val_accuracy: 0.8827 - 3s/epoch - 1s/step\n",
            "Epoch 53/200\n",
            "3/3 - 3s - loss: 9.3332 - accuracy: 0.9985 - val_loss: 8.7263 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 54/200\n",
            "3/3 - 3s - loss: 9.3236 - accuracy: 1.0000 - val_loss: 8.7332 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 55/200\n",
            "3/3 - 3s - loss: 9.3005 - accuracy: 0.9985 - val_loss: 8.8175 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 56/200\n",
            "3/3 - 3s - loss: 9.3171 - accuracy: 0.9969 - val_loss: 8.8726 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 57/200\n",
            "3/3 - 3s - loss: 9.3127 - accuracy: 1.0000 - val_loss: 8.7630 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 58/200\n",
            "3/3 - 3s - loss: 9.3004 - accuracy: 0.9985 - val_loss: 8.7539 - val_accuracy: 0.8580 - 3s/epoch - 1s/step\n",
            "Epoch 59/200\n",
            "3/3 - 3s - loss: 9.2917 - accuracy: 1.0000 - val_loss: 8.8273 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 60/200\n",
            "3/3 - 3s - loss: 9.2941 - accuracy: 1.0000 - val_loss: 8.7983 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 61/200\n",
            "3/3 - 3s - loss: 9.2957 - accuracy: 1.0000 - val_loss: 8.7544 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 62/200\n",
            "3/3 - 3s - loss: 9.2813 - accuracy: 1.0000 - val_loss: 8.6920 - val_accuracy: 0.8704 - 3s/epoch - 1s/step\n",
            "Epoch 63/200\n",
            "3/3 - 3s - loss: 9.2717 - accuracy: 0.9985 - val_loss: 8.7458 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 64/200\n",
            "3/3 - 3s - loss: 9.2784 - accuracy: 0.9985 - val_loss: 8.7516 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 65/200\n",
            "3/3 - 3s - loss: 9.2719 - accuracy: 0.9985 - val_loss: 8.7741 - val_accuracy: 0.8457 - 3s/epoch - 1s/step\n",
            "Epoch 66/200\n",
            "3/3 - 3s - loss: 9.2767 - accuracy: 0.9985 - val_loss: 8.7801 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 67/200\n",
            "3/3 - 3s - loss: 9.2655 - accuracy: 1.0000 - val_loss: 8.7301 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 68/200\n",
            "3/3 - 3s - loss: 9.2546 - accuracy: 1.0000 - val_loss: 8.7427 - val_accuracy: 0.8519 - 3s/epoch - 1s/step\n",
            "Epoch 69/200\n",
            "3/3 - 3s - loss: 9.2538 - accuracy: 1.0000 - val_loss: 8.7269 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 70/200\n",
            "3/3 - 3s - loss: 9.2540 - accuracy: 1.0000 - val_loss: 8.7076 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 71/200\n",
            "3/3 - 3s - loss: 9.2563 - accuracy: 1.0000 - val_loss: 8.7112 - val_accuracy: 0.8642 - 3s/epoch - 1s/step\n",
            "Epoch 72/200\n",
            "3/3 - 3s - loss: 9.2526 - accuracy: 1.0000 - val_loss: 8.6957 - val_accuracy: 0.8765 - 3s/epoch - 1s/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "## If you want to plot the model\n",
        "# model = BiLSTM_LMCL(MAX_SEQ_LEN, MAX_FEATURES, EMBEDDING_DIM, n_class_seen, 'img/model.png', embedding_matrix)\n",
        "model = BiLSTM_LMCL(MAX_SEQ_LEN, MAX_FEATURES, EMBEDDING_DIM, 9, None, embedding_matrix)\n",
        "history = model.fit(train_data[0], train_data[1], epochs=200, batch_size=256, \n",
        "                    validation_data=valid_data, shuffle=True, verbose=2, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUZBsCOsc8iV",
        "outputId": "a556b885-1e27-4eee-b568-1127c9d01daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     -1\n",
            "1     -1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "185    1\n",
            "186   -1\n",
            "187   -1\n",
            "188   -1\n",
            "189   -1\n",
            "Length: 190, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_pred_lof)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bTPTSM7dqfn",
        "outputId": "48727991-3d61-46e7-b968-db75055eec37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(190, 9)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HizrKWXPfN9f",
        "outputId": "4a8c7a3c-653b-4e99-c5b9-c768f94abf20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70     0\n",
              "827    8\n",
              "231    2\n",
              "588    5\n",
              "39     0\n",
              "      ..\n",
              "95    -1\n",
              "96    -1\n",
              "97    -1\n",
              "98    -1\n",
              "99    -1\n",
              "Name: label, Length: 190, dtype: int64"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLeI0Qg0fun-"
      },
      "outputs": [],
      "source": [
        "d=test_data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYXIunp3gJJZ",
        "outputId": "55d7c93e-0842-4372-9a18-49b2f00b0479"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 8, 2, 5, 0, 7, 2, 1, 0, 0, 1, 5, 8, 1, 7, 5, 1, 4, 4, 0, 2, 7,\n",
              "       6, 3, 5, 3, 0, 8, 6, 5, 2, 7, 2, 5, 6, 6, 0, 5, 4, 2, 0, 2, 3, 7,\n",
              "       6, 6, 2, 5, 4, 8, 4, 3, 5, 2, 2, 2, 1, 3, 3, 5, 0, 3, 7, 4, 2, 1,\n",
              "       6, 5, 3, 4, 6, 5, 8, 3, 1, 8, 3, 4, 0, 6, 5, 1, 5, 0, 8, 7, 3, 4,\n",
              "       2, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmzVDnZVgzIh"
      },
      "outputs": [],
      "source": [
        "d=np.argmax(d, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uP8PZozfKUw"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score( y_pred_lof, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0K6m6KLiBFN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import get_scorer\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ6xXJZani_j",
        "outputId": "54e4d07d-f2e5-40fe-b1a3-aebad2178cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 100)         586600    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 256)              234496    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 2304      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 9)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 823,400\n",
            "Trainable params: 823,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZe0k-5hTjjq"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict(test_data[0])\n",
        "y_pred_proba_train = model.predict(train_data[0])\n",
        "classes = y_test.unique()\n",
        "method = 'LOF (LMCL)'\n",
        "get_deep_feature = Model(inputs=model.input, \n",
        "                         outputs=model.layers[-3].output)\n",
        "feature_test = get_deep_feature.predict(test_data[0])\n",
        "feature_train = get_deep_feature.predict(train_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVu7uZ9FOHvY",
        "outputId": "6bd4503d-3530-48ff-c0e2-72e27b49e5f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f17bf998b50>"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_deep_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wCpAJQM3isK",
        "outputId": "a2d71110-1aeb-42ed-9ab3-b2946bab45b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.11363865, 0.09598113, 0.08628959, ..., 0.12440191, 0.08645568,\n",
              "        0.10175695],\n",
              "       [0.09465767, 0.07559568, 0.08399788, ..., 0.12061546, 0.08070418,\n",
              "        0.20147906],\n",
              "       [0.10522423, 0.11473838, 0.2466297 , ..., 0.07929887, 0.09681679,\n",
              "        0.08457799],\n",
              "       ...,\n",
              "       [0.08435052, 0.08754462, 0.08041783, ..., 0.09646848, 0.16863684,\n",
              "        0.10568548],\n",
              "       [0.07587107, 0.12778777, 0.10733645, ..., 0.15041167, 0.1222211 ,\n",
              "        0.09982146],\n",
              "       [0.10549442, 0.16948463, 0.0792753 , ..., 0.09268572, 0.1333132 ,\n",
              "        0.07667072]], dtype=float32)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "FUC3vA7V0smY",
        "outputId": "e081639e-b8c0-4ad3-eb5a-1f355a2be4e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.531578947368421"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True, n_jobs=-1)\n",
        "lof.fit(feature_train)\n",
        "\n",
        "y_pred_lof = pd.Series(lof.predict(feature_test))\n",
        "df_seen = pd.DataFrame(y_pred_proba, columns=y_train.unique())\n",
        "df_seen['unseen'] = 0\n",
        "\n",
        "y_pred = df_seen.idxmax(axis=1)\n",
        "y_pred[y_pred_lof[y_pred_lof==-1].index]=-1\n",
        "cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()\n",
        "accuracy_score(y_pred,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msKLX_3A_1Sn"
      },
      "source": [
        "Ale omijajc wyniki klasyfikatora dla 9 klas..\n",
        "\n",
        "W zbiorze testowym znajduje si 100 anomalii - 97 zostao dobrze sklasyfikowanych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWpDEL54QIqV",
        "outputId": "fba793d4-0fb7-48ea-de61-a7ba661c082a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   5, 2812,  225, ...,    0,    0,    0],\n",
              "       [ 119,  262,   85, ...,    0,    0,    0],\n",
              "       [3343,   31,   38, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  65, 1072,  595, ...,    0,    0,    0],\n",
              "       [5862,    9,    4, ...,    0,    0,    0],\n",
              "       [5863,    9,   30, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDfjxPhg_0tp"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict(test_data[0])\n",
        "y_pred_proba_train = model.predict(train_data[0])\n",
        "classes = y_test.unique()\n",
        "method = 'LOF (LMCL)'\n",
        "get_deep_feature = Model(inputs=model.input, \n",
        "                         outputs=model.layers[-3].output)\n",
        "feature_test = get_deep_feature.predict(test_data[0])\n",
        "feature_train = get_deep_feature.predict(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqpZ1flpP5T8",
        "outputId": "ce7810f7-f15d-4f09-e6af-59fbafe768a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.10359517, 0.12320057, 0.08046834, ..., 0.09808845, 0.09907207,\n",
              "        0.09164179],\n",
              "       [0.09188161, 0.0885434 , 0.08768825, ..., 0.11534724, 0.08752667,\n",
              "        0.20406902],\n",
              "       [0.10766008, 0.1670118 , 0.19145626, ..., 0.07849938, 0.09173696,\n",
              "        0.10640532],\n",
              "       ...,\n",
              "       [0.08546976, 0.10476092, 0.07939428, ..., 0.09554262, 0.12921678,\n",
              "        0.09794468],\n",
              "       [0.06636148, 0.17385319, 0.13798696, ..., 0.12946413, 0.10169329,\n",
              "        0.10159175],\n",
              "       [0.10696699, 0.15286016, 0.09779482, ..., 0.09613074, 0.17020376,\n",
              "        0.07969492]], dtype=float32)"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "5QorX9437e0F",
        "outputId": "12db2763-d7a1-49f4-be1d-28deead781ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5368421052631579"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True, n_jobs=-1)\n",
        "lof.fit(feature_train)\n",
        "\n",
        "y_pred_lof = pd.Series(lof.predict(feature_test))\n",
        "df_seen = pd.DataFrame(y_pred_proba, columns=y_train.unique())\n",
        "df_seen['unseen'] = 0\n",
        "\n",
        "y_pred = df_seen.idxmax(axis=1)\n",
        "y_pred[y_pred_lof[y_pred_lof==-1].index]=-1\n",
        "cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()\n",
        "accuracy_score(y_pred,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRDeqm6DPQwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqnC5gnJPQ02",
        "outputId": "1bb289ed-c456-4844-be32-ddfb92756cea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 3, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
              "       [4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 8, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
              "       [0, 0, 0, 0, 3, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
              "       [0, 0, 6, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm[:9,:9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXr5jKzrGekN",
        "outputId": "c02de0d0-2286-4c71-c75c-7f8461374534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm[:9,:9].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljiky2LEGswv",
        "outputId": "73c6d708-7a89-4324-9d05-666cfc23b35b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(34+99)/190"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgub9lPZFWok",
        "outputId": "ea673f36-0d2a-4274-ac97-e7cfa5f449f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm[:9,9:].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t1qPuGrF-es",
        "outputId": "e81d075a-7a21-492e-8b2d-7e6abe7d006d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm[9:,:9].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "23h7HD598OYj",
        "outputId": "76679745-4677-4201-b2ca-b1e5620f4b3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5368421052631579"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEKCAYAAACPJum2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hV5bX48e+aGRiG3nsRlICI2JBqCJYoxlhufgYlarjGBE3sJvGi8cbEkvKLRo2ikYiKoigoBgtSRIxiQYpIVUGQOnRGepmZdf/Ye+A4Ttlz9t6H885Zn+fZD+ec2WftxYQsd3nfd4mqYowxmSDrSCdgjDGpYgXPGJMxrOAZYzKGFTxjTMawgmeMyRhW8IwxGcMKnjEmLYjIkyKySUQWJXzWWESmicgy/89G/uciIv8QkeUiskBETg5yDCt4xph08TQwqNRnw4HpqtoZmO6/BzgX6Oxvw4DHghzACp4xJi2o6rvAtlIfXwiM9l+PBi5K+PwZ9XwENBSRVpUdIyeqZKNWU3K1FnWiDywSfUwAm7FiYiQ1a8YSd8eBjVtUtVmy3z/n9Dq6dVtRoH3nLti/GNiX8NFIVR1ZyddaqGq+/3oD0MJ/3QZYk7DfWv+zfCqQtgWvFnXoLWdGHldycyOPCaD798cS1xiAnDbtY4k7eeXfV4X5/tZtRXw8JVhu2a2W7VPVnskeS1VVREKdWaRtwTPGpD8FiimO8xAbRaSVqub7l6yb/M/XAe0S9mvrf1Yhu4dnjEmaohzUokBbkl4FhvqvhwITEz7/qf+0tg/wdcKlb7nsDM8YE0pUZ3giMhYYCDQVkbXAncBfgHEichWwChjs7z4J+AGwHNgDXBnkGFbwjDFJU5SiiB7YqeqQcn70rZv56q1rd21Vj2EFzxgTSjHujFBwvuD1HLiDa+5eT3aW8ubYxox7pEXlX6pA01b7+e39K2jY9CCoMGlsMyY+3TItc3Uxrku5uhb3gsErOOeC1QjKlFc7MHFcpwgyrZgCRQ4VvJQ+tBCRQSLyuT8dZHjl36hYVpZy7Z/WccdlHfnFwC6cfmEB7Tvvq/yLFSguFP51b3uuPrsHN/2oG+f/dCPtj9kbNtVYcnUtrku5uha3Q6cdnHPBam656jSuG/o9evXfSKs2u0PnGkQxGmhLBykreCKSDYzAmxLSDRgiIt3CxOxy0h7Wf1WTDatzKTyYxTsTG9L3nK9D5bltc02WL/YGPO/dnc2a5Xk0aXkgVMy4cnUtrku5uha3XYddfLG4Ifv351BclMXCT5rQb2ClDy1DU+CgaqAtHaTyDK8XsFxVV6jqAeAFvOkhSWvS8iCb1x8egb4lvwZNWx0Ml2WCFm32c3S3PXw+v27oWHHl6lJcl3J1Le6qFfU47oRt1Kt/gNzcQnr220Sz5uGvTCqjKEUBt3SQynt4ZU0F6Z24g4gMw5sITC1qpy6zMtSqXcQdjy3j8bvbs2dX9hHNxZjKrFlVj5fGHMM9D37Evn3ZrPiiPkXFMU2jTKRQlB61LJC0emjhz6sbCVBfGlf6a9y6oQbNWh++3Gza6iBb8muEziM7p5j/fWwZMyY24f0pjUPHg/hydSmuS7m6GHfq6+2Z+ro3zeunVy9l6+a80DEr4820cEcqL2mTmgpSkc/n16ZNxwO0aLefnBrFDLywgI+mNgiVJCg3/3Ulq5fnMWFUpYsvBBZPrm7FdSlXF+M2aOTN527WYg/9BubzztQ2oWNWTigKuKWDVJ7hzQY6i0hHvEJ3KfCTMAGLi4QRv2vDn55fQVY2TH2hMau+qBUqyeN67uKsH21l5Wd5jHjDW4fw6b+1ZfY7DUPFjSNX1+K6lKuLcW+/dw71GxygsDCLx+47nt27wp81VsZ7aJEexSwISWUjbhH5AfAgkA08qar3lrdvfWmstlqKMZ6co2JbLWVumBVMjutRU194o3mgfXu0XxfqWFFI6T08VZ2ENwfOGFNNFDt0hpdWDy2MMW7xZlpYwTPGZABFKHJolTkreMaYUOyS1hiTERThgLozMN8KnjEmad7AY7ukTVtODR/Jium/nMVJL7dtjhDdHf+82GTZQwtjTEZQFYrUzvCMMRmi2M7wjDGZwHto4U4ZcSdTY0zasYcWxpiMUmTj8IwxmcC1mRbuZFqOngN38MR7n/HU+0sZfN3GtI0ZV9xb7lvFi/MX8PhbSyKJlyjTf7euxa1T7yC337eAx//9Af985QO69iiIJG5lijUr0JYOUt217GYRWSwii0RkrIiEWgTMOmvB1PGN+d3lx4SOU5r9bt2Le/WtXzD3/SZcfVE/rvtxH9asrBM6ZmW8xQOyAm3pIJVdy9oANwA9VbU73pp4l4aJaZ21YNGseuwsiH6Asv1u3Ypbu24h3U/ZzpRXWgNQWJjF7p2pWABUOKjZgbZ0kOqymwPkiUgOUBtYHyaYddaKj/1u3Yrbss1evt5ek5vvWsLDL37EjXcuITcv/hk1qlCkWYG2dJCyLFR1HXAfsBrIB75W1amJ+4jIMBGZIyJzDuLQFDBjjrDsbOWYrjuZNL4t11/Sh317sxn8s69ScGShOOCWDlJ5SdsIrw9tR6A1UEdELk/cR1VHqmpPVe1Zg8qXYrfOWvGx361bcbdszGXLxlw+X+g1A5o5rTlHd90RKmYQip3hlecsYKWqblbVg8AEoF+YgNZZKz72u3Ur7vatuWzeWIs2HXYDcGLvbaxeEb6BfBAuPbRI5Ti81UAfEakN7AXOBOaECWidtWD4Iyvp0XcnDRoXMmb2Qp69vxVTXmialvm69rt1Le4//9KFW/+8iJwayoa1eTzw+26hY1ZGEacWAE1117I/ApcAhcAnwM9VtcybdXF1LXOKLQ9lfNnNmsUSd8qmx0J1EmvXvb7eMr5PoH1v6TYt47qW3QncmcpjGmPilD5NtoOwqWXGmKQppM0siiCs4BljQnHpDM+d0myMSTuqEulc2rKmn4pIRxGZJSLLReRFEalZeaSyWcEzxiRNIbKpZRVMP/0r8ICqHgNsB65KNl8reMaYECTqgcelp5/mA2cAL/k/Hw1clGy2dg8vndnwEePTFk3iCbwp3Ne9hxaB7+E1FZHEsbcjVXXkoViq60SkZPrpXmAqMBcoUNVCf7e1QJtk87WCZ4wJpQqzKLZUNA6v1PTTAmA8MCh0ggms4BljkhbxTItD008BRGQC0B9oKCI5/lleW2Bdsgewe3jGmFCKyQq0BXBo+qmICN700yXADOBif5+hwMRkc7UzPGNM0lThYHE0502qOktEXgLmcXj66UjgDeAFEbnH/2xUssewgmeMSZp3SRvdhWI5009XAL2iiG8FzxgTikszLZwveD0H7uCau9eTnaW8ObYx4x5pkZYxLW58MTM57s23fEyvPuspKMjll8POBeCKoQvp23cdxSp8XZDL/X/rzbZteZHkXVoVh6Uccalc8bidiMwQkSX+1JEbw8a0zlpuxXUpV1fiTpt2FHfcPuAbn708viu/umYQ1/3yHGbNas1PLl8cOufyRTu1LG6pzKIQ+LWqdgP6ANeKSKgVCq2zlltxXcrVlbiLFjZn585vtkPYs+fwcvG1ahV6p2Exsp4WZVDVfFWd57/eCSwlxIhpsM5arsV1KVcX4yYa+t8LeOa5Vzn9jFU8+0z3SGMn8p7SZgfa0sEROc8UkaOAk4BZpT63rmXGRGD00z346WUXMOPtDpx/wfLYjlMy8DjIlg5SXvBEpC7wMnCTqn6jrZJ1LavecV3K1cW4ZZkxvQP9v7smltgl7JK2HCJSA6/YPaeqE8LGs85absV1KVcX45Zo3Xrnodd9+61j7Zr6kcUureQprStneCkbluJPFRkFLFXVv0cR0zpruRXXpVxdifs/t31Ijx6bqN9gP88+9yrPPtudU0/Np227HWixsGlTHR5+6JTQOVckXZ7ABpGyrmUichrwHrAQKPY/vl1VJ5W1v3UtM+awrO5dY4k7deE9oTqJNeraXM948uLKdwQm9A/XIS0KKTvDU9WZkCYX8saYyKTL5WoQzs+0MMYcOa7NtLCCZ4wJxQqeMSYjRLwAaOys4BljQkmXMXZBWMEzxgGamx5Ts0pThcKIFgBNBSt4xphQ7JLWGJMR7B6eMSajqBU8Y0ymsIcWxpiMoGr38IwxGUMosqe0qWONZtyK61KuLsS9+YaP6H3qOgq+rsU1150HwOVDFjDonC/5+mtvTcmnnzmB2XNDLS5eIbuHVw4R+QrYCRQBhWFXTihphnLbpZ3Ykl+Dhyct46MpDVi9LPklfOKIaXHdy9WVuNOmd+K1N77Db27+8BufvzKxKy+/cmyoPINwbS7tkTgXPV1VT4ximRhrNONWXJdydSXuosXN2bmzZuU7xkW9+3hBtnTgzsV3GazRjFtxXcrVxbiJLjjvCx77xyRuvuEj6tY5UPkXQrAl3sunwFQRmSsiw0r/0Jr4GBPe62925sph5/OrG89l2/Y8fnHVvNiOpf5DiyBbOkh1Fqep6snAuXh9ab/RQdia+FTvuC7l6mLcEgUFeRQXZ6EqTJ5yNF2+szWy2GWxS9pyqOo6/89NwCtArzDxrNGMW3FdytXFuCUaN9p76HW/vmv5alV0scuiKoG2dJDKJj51gCxV3em/Phu4K0xMazTjVlyXcnUl7vDfvE+P4zdSv/5+nn3qFcY834Mex2+kU8ftoMLGTXX4x4hQ5xUV8s7e0qOYBZHKJj6d8M7qwCu0z6vqveXtb018jDlMTjkulrjT5vwxVGOdvGNaa6f7v3U7vkxLLgp3rCiksonPCuCEVB3PGJMa6XJ/LgjnZ1oYY44cRShOkyewQVjBM8aE4tAJntsDj40xR5hG+5RWRBqKyEsi8pmILBWRviLSWESmicgy/89GyaZrBc8YE44G3IJ5CJisql3x7vkvBYYD01W1MzDdf58UK3jGmFCiOsMTkQbAAGCUF1cPqGoBcCEw2t9tNHBRsrmWew9PRB6mgrqsqjcke1BjTNVkr9typFMokwLFxYHH4TUVkTkJ70eq6siE9x2BzcBTInICMBe4EWihqvn+PhuApNfoquihxZwKfmaMMf7lauCCt6WScXg5wMnA9ao6S0QeotTlq6qqiCT9nKTcgqeqoxPfi0htVd2T7IGMMdVThOPw1gJrVXWW//4lvIK3UURaqWq+iLQCNiV7gErv4flPSZYAn/nvTxCRR5M9oDGmmonooYWqbgDWiEgX/6MzgSXAq8BQ/7OhwMRkUw0yDu9B4Bz/oKjqp6VXOTHGZKrIFwa4HnhORGoCK4Ar8U7MxonIVcAqYHCywQMNPFbVNSLf+EsVJXtAY0w1E+HIY1WdD5R1ny+SifVBCt4aEekHqIjUwHtqsjSKgxtjHKegwZ/SHnFBxuFdA1wLtAHWAyf679NCz4E7eOK9z3jq/aUMvm5j2sa0uPHFtLjQpsNuHh774aFt/LvTufAnqyLINAgJuB15lZ7hqeoW4LKwB/JvRL6Y8FEn4Peq+mCyMa2zlltxXcrVtbjrVtXh+iF9D8V/ZvJ/+GBG81B5BubQZNogT2k7ichrIrJZRDaJyER/bbsqUdXP/W5lJwKnAHs4vD5eUqyzlltxXcrVxbglTui1lfy1tdmcnxdZzApFO7UsVkEuaZ8HxgGtgNbAeGBsyOOeCXypqqHOua2zlltxXcrVxbglBpyzgf9MaRlZvAqVDDwOsqWBIAWvtqo+q6qF/jYGCLvO9aWUUTSta5kx4eTkFNN7wGZmTkt69lWVudTEp6K5tI39l2+KyHDgBbx6fgkwKdkD+uNrLgBuK/0zf17dSPCWeK8slnXWciuuS7m6GBegZ/8tfPlZfQq2Vd71LzLV5CntXLz5tIOBq4EZwDvAL/GKXrLOBeapauhHU9ZZy624LuXqYlyAAYNSeDnrEw22pYOK5tJ2jOmYQwh/DxCwzlquxXUpVxfj5tYq5KTeW3nk3mNDxwosjR5IBBGoa5mIdAe6kXDvTlWfqfLBvPaMq4FOqlrhYynrWmbMYTkt47knNzl/RKhOYrkd2mmr228MtO+qa36b/l3LROROYCBewZuEd0k6E6hywVPV3UCTqn7PGJPGHDrDC/KU9mK8YSQbVPVKvGWX421lboxxR3HALQ0EmUu7V1WLRaRQROrjrUXVLua8jDEuqNoCoEdckII3R0QaAv/Ce3K7C/gw1qyMMc5IlyewQQSZS/sr/+U/RWQyUF9VF8SbljHGGdWh4InIyRX9TFXnxZOSMcbEo6IzvPsr+JkCZ0ScizGmPDmB1uo9IqrFJa2qnp7KRIwxDlKcmlqWvv/ZMMa4oTqc4RljTBDV4pLWGGMCcajgBVnxWETkchH5vf++vYj0ij81Y4wTqtmKx48CffFWOQHYCYyILSNjjDOCLg2VLpe9QQpeb1W9FtgHoKrbgZoVfyV1rLOWW3FdytW1uBcNWcmjL7zLiLHvcuvdn1CjZoraRxdLsC0NBCl4B0UkG/+kVESakcRUYBF50m8CtKiq3y1PSfenOy7ryC8GduH0Cwto33lf2sW0uO7l6lrcJs32cf4lX3HT0P5cO2QAWdnK976fHzrXIKrbGd4/8LqLNReRe/GWhvpTEsd6GhiUxPfKZZ213IrrUq4uxs3OVmrmFpGVXUxurSK2bknRMu/V6R6eqj4H3Ar8GcgHLlLV8VU9kKq+C2yrcoYVsM5absV1KVfX4m7dXIsJYzry9KszGDPpbXbvqsEns5qFTbVy1e0enoi0x+sh+xrwKrDb/yxy1rXMmOTUrXeQPt/bxM8uGsgVPziDWnlFnD5oXWoO7tAZXpBxeG/gpSt4S7x3BD4Hjos6GetaVr3jupSra3FP7LWFjevz2FHgXcZ+MKMFx/bYzozJbULFDULSZHHPIIJc0h6vqj38PzsDvUiT9fCss5ZbcV3K1bW4mzfk0aV7Abm5RYBywqlbWfNV3dC5VjdVnmmhqvNEpHccyVSVddZyK65LuboW9/PFDXl/ekseenYmRUXCis/r8+YrKVqYPE0uV4OotGuZiNyS8DYLOBlooqrnVOlAImPxmgE1BTYCd6rqqPL2t65lxhyW0zaeS9PJax4K1UmsVut2etTVt1S+I/D5H25J/65lQL2E14V49/ReruqBVHVI5XsZY5zj0BlehQXPH3BcT1V/k6J8jDGuqQ4FT0RyVLVQRPqnMiFjjDsEt57SVnSG9zHe/br5IvIqMB7YXfJDVZ0Qc27GmHQXw6Bi/8pyDrBOVX8oIh2BF4AmeJ0Tr1DVAxXFKE+QqWW1gK14PSx+CJzv/2mMMXEMPL4RWJrw/q/AA6p6DLAduCrZVCsqeM39J7SLgIX+n4v9PyNbAMAY47gIC56ItAXOA57w3wveydZL/i6jgYuSTbWiS9psoC7eZXppDt2mNKYayMk+0hmUqwqXtE1FZE7C+5H+7KpED+LN3S8ZHdIEKFDVQv/9WiDpMToVFbx8Vb0r2cDGmAwRvOBtqWgcnoj8ENikqnNFZGAEmX1LRQUvPVbsM8akL430KW1/4AIR+QHes4P6wENAw5JRI0BbIOlVESq6h2fTHIwxlYvoHp6q3qaqbVX1KOBS4G1VvQyYAVzs7zYUmJhsquUWPFWNdO06Y0z1lIL18P4HuEVEluPd0yt3SmplrE2jMSacGB5hquo7wDv+6xV4qzSFZgXPGJO8NFrcM4ggA4/TmnXWciuuS7m6FveCwSsYMeYdHh0zgwsHr4gkZmWEarbEe5REJFtEPhGR16OIZ5213IrrUq6uxe3QaQfnXLCaW646jeuGfo9e/TfSqs3uyr8YASt45Ss9ZSQU66zlVlyXcnUtbrsOu/hicUP278+huCiLhZ80od/A1LRpdKmnRcoKXukpI1GwzlpuxXUpV9firlpRj+NO2Ea9+gfIzS2kZ79NNGu+N2yqwThU8FL50KL0lJFvEZFhwDCAWtROUVrGuG/Nqnq8NOYY7nnwI/bty2bFF/UpKk7B3IE0ulwNIiUFL+iUEetaVr3jupSri3Gnvt6eqa97HVR/evVStm7OCx0zEIcKXqouaUumjHyFt67VGSIyJmxQ66zlVlyXcnUxboNGXi/nZi320G9gPu9Mjb9FI3hTy4Js6SAlZ3iqehtwG4B/hvcbVb08bFzrrOVWXJdydTHu7ffOoX6DAxQWZvHYfceze1f4s8YgXLqkrbRrWeQHPFzwKlxE1LqWGXNYzlHtY4k7eeXfQ3USq92snXb9f8G6ln3yuBtdyyKVOGXEGFMNOHSGZ1PLjDFJK5lp4QoreMaYUKTYnYpnBc8Yk7w0GlQchBU8Y0wodklrjMkcVvCMSX+Smxt5TN2/P/KYAOyLKW4E7AzPGJM5rOAZYzJCtF3LYmcFzxiTNBuHZ4zJLCmenhqGFTxjTCh2hpdCPQfu4Jq715Odpbw5tjHjHmmRljEtbnwx44rbtNV+fnv/Cho2PQgqTBrbjIlPt4wg2+jzbdNhN8P/suDQ+5Zt9jDmn8cw8fkOYVOtmA08Lp+INMRb4r073q/pZ6r6YbLxSpqh3HZpJ7bk1+DhScv4aEoDVi9LfqmdOGJaXPdyBSguFP51b3uWL65DXp0iHn5tEZ/MbMDq5eEW1owj33Wr6nD9kL6H4j8z+T98MKN5qDyDcumhRaqb+DwETFbVrsAJhGzoY41m3IrrUq4A2zbXZPniOgDs3Z3NmuV5NGl5oJJvVS6ufEuc0Gsr+Wtrszk/NSseu7QAaCqb+DQABgCjAFT1gKoWhIlpjWbciutSrqW1aLOfo7vt4fP5dUPHijvfAeds4D9Torn0rpTiPbQIsqWBVJ7hdQQ2A0/5vWmfEJE6iTuIyDARmSMicw6SviPLTWapVbuIOx5bxuN3t2fPruwjnU6FcnKK6T1gMzOnRXNvNAjrS1u2HOBk4DFVPQnYDQxP3EFVR6pqT1XtWYPKp/1Yoxm34rqUa4nsnGL+97FlzJjYhPenNI4kZpz59uy/hS8/q0/BtuinzZXLoTaNqSx4a4G1qjrLf/8SXgFMmjWacSuuS7l6lJv/upLVy/OYMKpVBPE88eULAwal8HKWwwOPXTnDS9lTWlXdICJrRKSLqn4OnAksCRPTGs24FdelXAGO67mLs360lZWf5THijUUAPP23tsx+p2Fa5ptbq5CTem/lkXuPDR0rMFWnFgBNaRMfETkRb1hKTWAFcKWqbi9rX2viY+Lm0mopOS3juSc3OX9EqMY69Rq21ZMG3Bho3/deuzWzmvio6nzgiP6FjTHRSpfL1SCcn2lhjDmCFHDoktYKnjEmHHfqXcpnWhhjqpmontKKSDsRmSEiS0RksYjc6H/eWESmicgy/89GyeZqBc8YE4oUa6AtgELg16raDegDXCsi3fDG605X1c7AdEqN360KK3jGmOQFHXQcoN6par6qzvNf78Sba98GuBAY7e82Grgo2XTtHl5UsmKYclRcFH1Mc0hsDXfiUDs1CwFUlTfwOPBNvKYiMifh/UhVHVlmXJGjgJOAWUALVc33f7QBSHqMjhU8Y0w4wVdC2RJkHJ6I1AVeBm5S1R0icuhnqqoiyQ+EsUtaY0woohpoCxRLpAZesXtOVSf4H28UkVb+z1sBm5LN1QqeMSZ5Ed7DE+9UbhSwVFX/nvCjV4Gh/uuhwMRk07VLWmNMCJHOpe0PXAEsFJH5/me3A38BxonIVcAqYHCyB7CCZ4wJJ6L5+Ko6E+85SFkimVhvBc8YkzzHGnE7fw+v58AdPPHeZzz1/lIGX7cxbWPect8qXpy/gMffCrUiVpniyDeuuC7l6kLcG2/7hOdee5MRz7x96LO69Q5wzwMfMHLsW9zzwAfUrRe+D0eFbIn3bxORWiLysYh86k8b+WPYmCXdn+64rCO/GNiF0y8soH3nfWkXE2Dq+Mb87vJjQscpLa58XfrdZnLctya14/e/7vuNz358+TI+nduUYUPO4tO5Tfnx5ctC51whW/G4TPuBM1T1BOBEYJCI9AkT0KXOWotm1WNnQfSDk13qBOZSrq7EXfxpU3buqPmNz/p8N5+33mwPwFtvtqfPd/PL+mpkpLg40JYOUlbw1LPLf1vD30LVfZc6a8XFpU5gLuXqYtwSDRvtZ/tWbwXl7VtzadgoxhklijfwOMiWBlJ6D09Esv3HzZuAaQn9LUp+bl3LjImUUP6DzyiiBxt0XIXpZ7FKacFT1SJVPRFoC/QSke6lfl5tu5bFxaVOYC7l6mLcEgXbc2nUxLsn2KjJPgq216zkGyHZQ4uK+Q24ZwCDwsRxqbNWXFzqBOZSri7GLTFrZivOOnc1AGedu5qP3ouu41qZHCp4KRuHJyLNgIOqWiAiecD3gb+GielSZ63hj6ykR9+dNGhcyJjZC3n2/lZMeaFp6LgudQJzKVdX4t76hzkcf+IW6jc8wOgJU3huVFfGj+nM8Ltm8/3zVrN5Yx5//t9TQ+dcrpJ7eI5IWdcyEemBt5ZVNt6Z5ThVvau8/Z3rWmbLQ5kY5XQ6Kpa4k7+8L1QnsQa1W2vfzlcF2nfKgnsyp2uZqi7AW9/KGFNtpM/lahA2tcwYkzzFCp4xJoM4dA/PCp4xJpR0GWMXhBU8Y0w4VvCMMRlBFYrcuaa1ghcVG0JiYvTGzH/HEjc7ijHJdoZnjMkYVvCMMRlBgeh6WsTOCp4xJgQFtXt4xphMoNhDC2NMBrF7eMaYjOFQwbOuZSmKaXHji5lJce+/uR2Djz+OYad3OfTZju3ZDL/kaK7sfyzDLzn6UO8UVXj0jjb8d79juebMLixbkBdZ/ocFXAsvTYpiSgqeiHQVkQ9FZL+I/CaquNZZy624LuWarnHPvmQb9z634hufjXukOSedtpOn3l/KSaft5MVHmgMw++16rFuZy1PvL+XG/7+Gh29rGzr3b1GguDjYlgZSdYa3DbgBuC/KoNZZy624LuWarnGP77Obeo2+Ocj9wykNOGvwNgDOGryNDyc3OPz5xdsQgWNP2cPur7PZujGGu1h2hvdNqrpJVWcDkbb/ss5absV1KVeX4m7fUoMmLQoBaNy8kO1bvP4YWzbUoFnrw3Gbtj7I1g1R92fxp5YF2dJAWj20EJFhwDCAWtQ+wtkY4x4REEnh2ZSCOjQOL60eWlTnrmUW161cXf0HTc8AAAiySURBVIrbqOnBQ5eqWzfm0LCJd7bXtOVBNq8/HHfL+ho0aRlDj+ViDbalgdgKnohcKyLz/a11HMewzlpuxXUpV5fi9jl7B2+NawzAW+MaH7of2OfsHbz1UmNUYenc2tSuX3To0jdSDt3Di+2SVlVHACPiig/WWcu1uC7lmq5x//zLDiz4sC5fb8vhslO6ccWvN3DJdRu595qjmPxCE5q3OcDvHv8KgF5n7mD29Hpc2e9YcvOK+fUDq0Pn/i2qafMENoiUdC0TkZbAHKA+3oLQu4BuqrqjvO8417XMmBhNWT8/lrjZrZaH61qW3VT71jk/0L5Tdj6dGV3LVHUDEMMgIGPMkaVokTtrQabVU1pjjGNseShjTEaxYSnGmEyggBZroC0IERkkIp+LyHIRGR51vlbwjDHJU38B0CBbJUQkG29kx7lAN2CIiHSLMl27pDXGhBLhQ4tewHJVXQEgIi8AFwJLojpASoalJENENgOrAu7eFNgSQxouxXUpV9fiupRrVeN2UNVmyR5IRCb7xwuiFpC4LMxIVR2ZEOtiYJCq/tx/fwXQW1WvSza/0tL2DK8q/yOIyJw4xve4FNelXF2L61KuccYti6oOSsVxomL38Iwx6WId0C7hfVv/s8hYwTPGpIvZQGcR6SgiNYFLgVejPEDaXtJW0cjKd6n2cV3K1bW4LuUaZ9xYqWqhiFwHTAGygSdVdXGUx0jbhxbGGBM1u6Q1xmQMK3jGmIzhfMGLYyqKiNwsIotFZJGIjBWR0IugiUg7EZkhIkv82DdGkasf+ysRWegvtjonophdEhZwnS8iO0TkpgjiPikim0RkURR5loqdLSKfiMjrEcZsKCIvichnIrJURPpGELOWiHwsIp/6/xb+GFGusXQHrE6cvofnT0X5Avg+sBbvKc8QVU16ZLaItAFm4q3Xt1dExgGTVPXpkLm2Alqp6jwRqQfMBS4Kk2tC7K+AnqoaxyDWkt/zOrxBoEEHg5cXawDeeojPqGr3KPJLiH0L0BOor6o/jCjmaOA9VX3Cf3JYW1ULQsYUoI6q7hKRGnj/3m5U1Y9Cxm0OdAAuAraraqRdAqsD18/wDk1FUdUDQMlUlLBygDwRyQFqA+vDBlTVfFWd57/eCSwF2oSNmyJnAl+GLXYAqvouXtvOSIlIW+A84IkIYzYABgCjAFT1QNhi58dRVd3lv63hb6HPPOLqDliduF7w2gBrEt6vJWQRUdV1eP1zVwP5wNeqOjVMzNJE5CjgJGBWRCEVmCoic/3Ob1G7FBgbQ9woPQjcireidlQ6ApuBp/xL5SdEpE4Ugf3L7/nAJmCaqkb1b8FUwPWCFzkRaYR3ltgRaA3UEZHLI4xfF3gZuKmiJe6r6DRVPRlvlYlr/cvGSPiXcRcA46OKGTUR+SGwSVXnRhw6BzgZeExVTwJ2A5HcJ1bVIlU9EW82QS8RifTy3pTN9YIXx1SUs4CVqrpZVQ8CE4B+IWMC4N+veRl4TlUnRBETDp2VoqqbgFfwLvWjci4wT1U3Rhgzav2BC/x7mS8AZ4jImAjirgXWJpx9vYRXACPjXyLPAJKak5qK7oDViesFL46pKKuBPiJS27+5fCbe/bZQ/FijgKWq+vew8RLi1vEfguBfbp0NRPkEdAhpfjmrqrepaltVPQrv38Dbqhr6rNzvxbJGRLr4H51JBEsViUgzEWnov87De+j2WZI5jlDVE/0t9L3m6s7pqWVxTEVR1Vki8hIwDygEPiGaqTr9gSuAhf69G4DbVXVSyLgtgFe8ekoO8LyqTg4ZEzhUQL8PXB1FPD/mWGAg0FRE1gJ3quqoqOLH4HrgOf8/qCuAKyOI2QoY7T/9zgLGqWrooTRSqjugP4yowu6AmcbpYSnGGFMVrl/SGmNMYFbwjDEZwwqeMSZjWMEzxmQMK3jGmIxhBc9hIlLkDzhdJCLjRaR2iFhPi9c1Cn8KVbn9QEVkoIhUeTC2v6rLtzpclfd5qX12VfTzMvb/g60YYkqzgue2vf6A0+7AAeCaxB/6ix9Umar+vJJVXAYS0ewTY1LJCl718R5wjH/29Z6IvAos8Sep/01EZovIAhG5GryZHyLyiHhrCb4FNC8JJCLviEhP//UgEZnnr9023V/44BrgZv/s8rv+zIGX/WPMFpH+/nebiMhUf823JwCp7C8hIv/2F0FYXHohBBF5wP98uog08z87WkQm+995T0S6RvHLNNWT0zMtjMc/kzsXKJlhcTLQXVVX+kXja1U9VURygfdFZCreai1dgG54szWWAE+WitsM+BcwwI/VWFW3icg/gV0l662JyPPAA6o6U0Ta4818ORa4E5ipqneJyHnAVQH+Oj/zj5EHzBaRl1V1K1AHmKOqN4vI7/3Y1+HNgrlGVZeJSG/gUeCMJH6NJgNYwXNbXsI0tffw5ur2Az5W1ZX+52cDPUruzwENgM5467yNVdUiYL2IvF1G/D7AuyWxVLW8dezOArr509sA6vurwgwAfuR/9w0R2R7g73SDiPyX/7qdn+tWvGWfXvQ/HwNM8I/RDxifcOzcAMcwGcoKntv2+ksMHeL/H3934kfA9ao6pdR+P4gwjyygj6ruKyOXwERkIF7x7Kuqe0TkHaC85fXVP25B6d+BMeWxe3jV3xTgl/7SVIjId/xFAd4FLvHv8bUCTi/jux8BA0Sko//dxv7nO4F6CftNxZtkj79fSQF6F/iJ/9m5QKNKcm2AtzT5Hv9eXJ+En2UBJWepP8G7VN4BrBSRH/vHEBE5oZJjmAxmBa/6ewLv/tw88RrnPI53Zv8KsMz/2TPAh6W/qKqbgWF4l4+fcviS8jXgv0oeWgA3AD39hyJLOPy0+I94BXMx3qXt6kpynQzkiMhS4C94BbfEbryFMhfh3aO7y//8MuAqP7/FRLPEv6mmbLUUY0zGsDM8Y0zGsIJnjMkYVvCMMRnDCp4xJmNYwTPGZAwreMaYjGEFzxiTMf4PmT45B++V+3kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lof = IsolationForest(n_estimators=95, max_samples=90, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "lof.fit(feature_train)\n",
        "\n",
        "y_pred_lof = pd.Series(lof.predict(feature_test))\n",
        "df_seen = pd.DataFrame(y_pred_proba, columns=y_train.unique())\n",
        "df_seen['unseen'] = 0\n",
        "\n",
        "y_pred = df_seen.idxmax(axis=1)\n",
        "y_pred[y_pred_lof[y_pred_lof==-1].index]=-1\n",
        "cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()\n",
        "accuracy_score(y_pred,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_pnTk_9i8Ik"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "WvOG4vARvEZF",
        "outputId": "65a56df2-c4a3-47b3-a121-c9ba36cc86c5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e806fd2c76dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_an\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vc' is not defined"
          ]
        }
      ],
      "source": [
        "X_train = vc.make_vectors(text_train.values)\n",
        "X_val = vc.make_vectors(text_val.values)\n",
        "\n",
        "X_test0 = vc.make_vectors(text_test0.values)\n",
        "X_outliers = vc.make_vectors(data_an['comment'].values)\n",
        "\n",
        "#test set = (X_test + y_test) + anomaly class\n",
        "X_test = np.vstack([X_test0, X_outliers]) \n",
        "y_test = pd.concat([y_test0,data_an['label']])\n",
        "db_y_test = pd.concat([db_test,data_an['label']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uFCEofuMAeX"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vqUXHnt23jC",
        "outputId": "539941fc-14f4-444c-a33b-77214c394034"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXTtwq3jLhDf"
      },
      "outputs": [],
      "source": [
        "X_train = vc.make_vectors(text_train.values)\n",
        "X_test0 = vc.make_vectors(text_test0.values)\n",
        "X_outliers = vc.make_vectors(data_an['comment'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyiOKyctLH5u",
        "outputId": "c3fa95f7-0ec3-4bd4-d284-65a94fe675ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.0686191 ,  0.08219691,  0.01634696, ..., -0.05590384,\n",
              "         0.0275783 , -0.0225623 ],\n",
              "       [-0.03398514,  0.05371666, -0.09219408, ...,  0.01417923,\n",
              "        -0.03765583, -0.02503967],\n",
              "       [ 0.02618408,  0.08276367,  0.105399  , ..., -0.09319197,\n",
              "         0.02408273, -0.01593889],\n",
              "       ...,\n",
              "       [ 0.06313833,  0.0006307 ,  0.00173314, ..., -0.05719121,\n",
              "        -0.01654243, -0.01771037],\n",
              "       [ 0.07774135,  0.02988652,  0.01478468, ..., -0.06413814,\n",
              "         0.06386239, -0.03085763],\n",
              "       [ 0.03764461,  0.04586088,  0.06161675, ..., -0.08593779,\n",
              "         0.04104614, -0.03659762]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwRbZxg0aMyd"
      },
      "outputs": [],
      "source": [
        "#test set = (X_test + y_test) + anomaly class\n",
        "X_test = np.vstack([X_test0, X_outliers]) \n",
        "y_test = pd.concat([y_test0,data_an['label']])\n",
        "db_y_test = pd.concat([db_test,data_an['label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuhJi-AXaNJ-"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP7LMsNBNLrC",
        "outputId": "3c884937-af4b-4953-8b6f-741e2245e21e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(190,)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db_y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrrxTXfG_Zof",
        "outputId": "65f308b6-d633-4a79-bc38-80f6a216ab0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9864197530864197\n",
            "0.5894736842105263\n",
            "0.4965817277812306\n",
            "0.563912429378531\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=2, contamination=0.1, novelty=True)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB1PXTSaC0Xi",
        "outputId": "87293489-c7ab-4d0b-d92b-233a0400d0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9654320987654321\n",
            "0.6526315789473685\n",
            "0.49120603015075376\n",
            "0.6460027100271002\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=2, contamination=0.2, novelty=True)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8yoZZ1OC7bq",
        "outputId": "ba5d702b-bee2-4626-c985-f7224fc28b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7753086419753087\n",
            "0.7\n",
            "0.4367176634214186\n",
            "0.693816968703175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=2, contamination=0.5, novelty=True)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOZNUtNq_aeA"
      },
      "source": [
        "# threshhold for std - one class learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am4i9o5f_ZzP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilklHn-9_Zry"
      },
      "outputs": [],
      "source": [
        "class StdThresholdClassifier():\n",
        "    def __init__(self, train, threshold=0.15, clf=LogisticRegression(C = 9)):\n",
        "        self._clf = clf\n",
        "        self._threshold = threshold\n",
        "        self._train = train\n",
        "        \n",
        "    def fit(self, X_train):\n",
        "         self._clf.fit(X_train, self._train)\n",
        "            \n",
        "    def predict(self, X):\n",
        "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict_proba(X)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsMa72-OXeCi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "O3aGtG-GWGun",
        "outputId": "377f8511-92f7-4b01-bf11-aa625eedb63e"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f15786d9f7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStdThresholdClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-090b254b2218>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0;34m\" class: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m             )\n\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
          ]
        }
      ],
      "source": [
        "clf = StdThresholdClassifier(y_train, 0.15, clf=LogisticRegression(C = 9))\n",
        "clf.fit(X_train)\n",
        "\n",
        "y_pred_train = clf.predict(np.array(X_train))\n",
        "y_pred_test = clf.predict(np.array(X_test))\n",
        "print(accuracy_score(y_pred_train,y_train))\n",
        "print(accuracy_score(y_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbQv0van_Z5a"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Bidirectional(LSTM(60, activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      Bidirectional(LSTM(300, activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      Bidirectional(LSTM(15, activation='relu')),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s63GxaKaEilo"
      },
      "source": [
        "#Best model -acc:85%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRYpnq0ABMb5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(60,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(300,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(15,activation='relu')),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9IBmhDbEl5x"
      },
      "source": [
        "keep testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKD7fX_8I6w1"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Bidirectional(LSTM(256, activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgwiJRUhgDe9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydp0yZX3gPLM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Conv1D(128, 7,strides=3, padding='causal', activation='relu'),\n",
        "      Conv1D(128, 7,strides=3, padding='causal', activation='relu'),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uogNZy2CEnlo"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(60,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(300,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(300,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(15,activation='relu')),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXkbV-eRV3Pe"
      },
      "outputs": [],
      "source": [
        "class std_threshold_NN():\n",
        "    def __init__(self, train, threshold=0.23, clf=NN()):\n",
        "        self._clf = clf\n",
        "        self._threshold = threshold\n",
        "        self._train = train\n",
        "        \n",
        "    def fit(self, X_train):\n",
        "         self._clf.fit(X_train, self._train ,epochs=200, batch_size=512)\n",
        "            \n",
        "    def predict2(self, X):\n",
        "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict(X)]\n",
        "\n",
        "    def probs(self, X):\n",
        "        return self._clf.predict(X)\n",
        "\n",
        "    def std(self, X):\n",
        "        return np.std(self._clf.predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un06J_pwizfl"
      },
      "outputs": [],
      "source": [
        "y_pred_train = clf.predict2(np.array(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIlbSRKSg3Yt"
      },
      "outputs": [],
      "source": [
        "print(np.std(clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFPxohyyYNm1"
      },
      "outputs": [],
      "source": [
        "# model=NN()\n",
        "class std_threshold_NN():\n",
        "    def __init__(self, train, threshold=0.23, clf=NN()):\n",
        "        self._clf = clf\n",
        "        self._threshold = threshold\n",
        "        self._train = train\n",
        "        \n",
        "    def fit(self, X_train):\n",
        "         self._clf.fit(X_train, self._train ,epochs=200, batch_size=512)\n",
        "            \n",
        "    def predict2(self, X):\n",
        "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict(X)]\n",
        "\n",
        "    def probs(self, X):\n",
        "        return self._clf.predict(X)\n",
        "\n",
        "    def std(self, X):\n",
        "        return np.std(self._clf.predict(X))\n",
        "\n",
        "clf = std_threshold_NN(y_train, 0.01, clf=model)\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "clf.fit(X_train)\n",
        "\n",
        "y_pred_train = clf.predict2(np.array(X_train))\n",
        "y_pred_test = clf.predict2(np.array(X_test))\n",
        "print(accuracy_score(y_pred_train,y_train))\n",
        "print(accuracy_score(y_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UsPxW2gRBoH"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMUcoS-lQ-I2"
      },
      "outputs": [],
      "source": [
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UddN0hXM2osa"
      },
      "source": [
        "##**Autoencoder()** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yY9MQZi2nvE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV6GfYwJ2nxg"
      },
      "outputs": [],
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=8):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yAMucza3Pdb"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXRfGMOi2n0O",
        "outputId": "c9370cbf-883d-4357-9b37-7a09b5a64be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 408ms/step - loss: 0.1464 - mse: 0.2588 - val_loss: 0.1461 - val_mse: 0.2577\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1461 - mse: 0.2582 - val_loss: 0.1457 - val_mse: 0.2570\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1458 - mse: 0.2575 - val_loss: 0.1453 - val_mse: 0.2562\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1453 - mse: 0.2567 - val_loss: 0.1448 - val_mse: 0.2552\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.1448 - mse: 0.2556 - val_loss: 0.1442 - val_mse: 0.2539\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1441 - mse: 0.2543 - val_loss: 0.1433 - val_mse: 0.2523\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1432 - mse: 0.2525 - val_loss: 0.1422 - val_mse: 0.2500\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1419 - mse: 0.2500 - val_loss: 0.1406 - val_mse: 0.2470\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1402 - mse: 0.2467 - val_loss: 0.1385 - val_mse: 0.2428\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1378 - mse: 0.2420 - val_loss: 0.1355 - val_mse: 0.2371\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1348 - mse: 0.2361 - val_loss: 0.1315 - val_mse: 0.2293\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1304 - mse: 0.2276 - val_loss: 0.1261 - val_mse: 0.2190\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1243 - mse: 0.2162 - val_loss: 0.1188 - val_mse: 0.2053\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1165 - mse: 0.2016 - val_loss: 0.1092 - val_mse: 0.1875\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.1065 - mse: 0.1832 - val_loss: 0.0969 - val_mse: 0.1654\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0945 - mse: 0.1617 - val_loss: 0.0820 - val_mse: 0.1391\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0787 - mse: 0.1341 - val_loss: 0.0649 - val_mse: 0.1099\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0623 - mse: 0.1062 - val_loss: 0.0469 - val_mse: 0.0800\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0470 - mse: 0.0809 - val_loss: 0.0301 - val_mse: 0.0529\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0298 - mse: 0.0528 - val_loss: 0.0168 - val_mse: 0.0318\n"
          ]
        }
      ],
      "source": [
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTUsI1Jg2n2y"
      },
      "outputs": [],
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def find_threshold_method_two(model, x_train_scaled):\n",
        "  # another method to find threshold\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "\n",
        "  threshold_2 = np.percentile(reconstruction_errors, 95)\n",
        "  return threshold_2\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = model.predict(x_test_scaled)\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
        "  # 0 = anomaly, 1 = normal\n",
        "  print(errors.dtype)\n",
        "  print(errors)\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1 if x == True else -1)\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKsjon4u2n5Q",
        "outputId": "f258317e-f2d1-40a6-a611-fb238bbebefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold method one: 0.020182466134428978\n",
            "Threshold method two: 0.022571505326777697\n"
          ]
        }
      ],
      "source": [
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, x_train_scaled)\n",
        "print(f\"Threshold method two: {threshold_2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxLpAvUD3gW0",
        "outputId": "374fb44c-e0ed-492c-92e0-92d0169c22d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70     1\n",
              "827    1\n",
              "231    1\n",
              "588    1\n",
              "39     1\n",
              "      ..\n",
              "95    -1\n",
              "96    -1\n",
              "97    -1\n",
              "98    -1\n",
              "99    -1\n",
              "Name: label, Length: 190, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8TUF8Mq2n71",
        "outputId": "7aa95e1c-569a-4024-ed0d-856d1947ab0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<dtype: 'float32'>\n",
            "tf.Tensor(\n",
            "[0.02126688 0.01604506 0.01465875 0.01245676 0.03121058 0.0147031\n",
            " 0.01645912 0.01305681 0.01597319 0.01580039 0.01809939 0.01548968\n",
            " 0.01332784 0.02355714 0.01598155 0.01442608 0.01546012 0.01582009\n",
            " 0.01809993 0.01880593 0.01487795 0.01344955 0.0202638  0.01940164\n",
            " 0.0152726  0.01249714 0.01664067 0.01608166 0.02232843 0.01658733\n",
            " 0.02076385 0.01124507 0.01500547 0.01337271 0.02377196 0.01504018\n",
            " 0.0168625  0.01390202 0.0122798  0.01653306 0.01447157 0.02452421\n",
            " 0.01420862 0.01966073 0.01883323 0.01284761 0.01407814 0.01570755\n",
            " 0.01234338 0.01727765 0.01803268 0.01312866 0.01480115 0.02072767\n",
            " 0.01923663 0.01558571 0.02015411 0.01893443 0.02160785 0.01626897\n",
            " 0.02749488 0.01863675 0.01273244 0.01501124 0.02069785 0.01431264\n",
            " 0.02049097 0.01406085 0.01602106 0.01640257 0.01169121 0.01619008\n",
            " 0.01970334 0.01619864 0.01928134 0.01735893 0.01389722 0.01753124\n",
            " 0.02100851 0.01474149 0.01414941 0.02232829 0.0149743  0.02064014\n",
            " 0.01614318 0.01728777 0.01795758 0.02204439 0.02084775 0.0176328\n",
            " 0.01341198 0.02309899 0.01955862 0.01641228 0.01501239 0.01807172\n",
            " 0.01931397 0.01474459 0.0209558  0.01966267 0.01389896 0.01909832\n",
            " 0.01292174 0.01528197 0.01370385 0.01531228 0.01251588 0.01651956\n",
            " 0.01709538 0.01387021 0.01548836 0.02067293 0.01678231 0.01808772\n",
            " 0.01377076 0.01545542 0.01607884 0.01498829 0.01343272 0.01334598\n",
            " 0.01386819 0.01419807 0.01084575 0.01578056 0.01666979 0.01546079\n",
            " 0.01700952 0.0175053  0.01539298 0.01658661 0.01705279 0.01492546\n",
            " 0.01689885 0.01462864 0.02147929 0.02085544 0.01440612 0.01714667\n",
            " 0.01516328 0.01522099 0.01358645 0.01558242 0.01642245 0.01724306\n",
            " 0.01825665 0.01518983 0.02528825 0.01297711 0.01414599 0.01426784\n",
            " 0.01442302 0.0180853  0.01585702 0.01790127 0.02138222 0.02245541\n",
            " 0.01734265 0.0147027  0.01665176 0.01574978 0.02196333 0.01509582\n",
            " 0.01939127 0.01565878 0.01524237 0.01523805 0.01947779 0.01499995\n",
            " 0.01510661 0.01569043 0.01825706 0.02042687 0.01742255 0.01591197\n",
            " 0.01734265 0.01609414 0.0148836  0.01579775 0.01669358 0.01880689\n",
            " 0.01442694 0.0204049  0.01966223 0.01545227 0.01495602 0.01551173\n",
            " 0.01321117 0.01808559 0.01819821 0.02116503], shape=(190,), dtype=float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5578947368421052"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f08PMGlw2n-Q"
      },
      "outputs": [],
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=4):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSbUQpfX4OjC"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_test_scaled, x_test_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV79ffCN2C77"
      },
      "outputs": [],
      "source": [
        "model.predict(x_train_scaled).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYdSNXPt4Olo"
      },
      "outputs": [],
      "source": [
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, x_train_scaled)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibLy5yzox5yU"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEZFMk_ex8bZ"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhquh2LkzYiX"
      },
      "outputs": [],
      "source": [
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5psMCyozYsI"
      },
      "outputs": [],
      "source": [
        "# define the autoencoder network model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(60, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n",
        "    L3 = RepeatVector(X.shape[1])(L2)\n",
        "    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n",
        "    L5 = LSTM(60, activation='relu', return_sequences=True)(L4)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fUB099CzYvI"
      },
      "outputs": [],
      "source": [
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6GyczLBzYxw"
      },
      "outputs": [],
      "source": [
        "# fit the model to the data\n",
        "nb_epochs = 20\n",
        "batch_size = 100\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv-_l8q54cu0"
      },
      "outputs": [],
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.mse(reconstructions, x_train_scaled)\n",
        "\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def find_threshold_method_two(model, x_train_scaled):\n",
        "  # another method to find threshold\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.mse(reconstructions, x_train_scaled)\n",
        "\n",
        "  threshold_2 = np.percentile(reconstruction_errors, 95)\n",
        "  return threshold_2\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = np.array(model.predict(x_test_scaled))\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.mse(predictions, x_test_scaled)\n",
        "  # 0 = anomaly, 1 = normal\n",
        "  errors=np.array(errors).reshape(errors.shape[0],)\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1 if x == True else -1)\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGCbd99xz-5C"
      },
      "outputs": [],
      "source": [
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv4m3tnSICt1"
      },
      "outputs": [],
      "source": [
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(150, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(50, activation='relu', return_sequences=True)(L1)\n",
        "    L3 = LSTM(10, activation='relu', return_sequences=False)(L2)\n",
        "    L4 = RepeatVector(X.shape[1])(L3)\n",
        "    L5 = LSTM(10, activation='relu', return_sequences=True)(L4)\n",
        "    L6 = LSTM(50, activation='relu', return_sequences=True)(L5)\n",
        "    L7 = LSTM(150, activation='relu', return_sequences=True)(L6)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "nb_epochs = 20\n",
        "batch_size = 100\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history\n",
        "\n",
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8K1lEJl4OtY"
      },
      "outputs": [],
      "source": [
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(32, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(16, activation='relu', return_sequences=True)(L1)\n",
        "    L3 = LSTM(10, activation='relu', return_sequences=False)(L2)\n",
        "    L4 = RepeatVector(X.shape[1])(L3)\n",
        "    L5 = LSTM(10, activation='relu', return_sequences=True)(L4)\n",
        "    L6 = LSTM(16, activation='relu', return_sequences=True)(L5)\n",
        "    L7 = LSTM(32, activation='relu', return_sequences=True)(L6)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "nb_epochs = 20\n",
        "batch_size = 100\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history\n",
        "\n",
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG-v9Q0rLTuq"
      },
      "source": [
        "# Autoencoder on BERT embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEJvSi0WLNm0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg4ivEGhLMie",
        "outputId": "17f2f1ea-e2f4-4c6c-c4b2-c04d30d3697e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text==2.8.2\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     || 4.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==2.8.2) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==2.8.2) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.14.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (4.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.26.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.47.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text==2.8.2) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_text==2.8.2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIPKq3qNLMlI"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKgunRI7LMoD"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embeding(sentences):\n",
        "    preprocessed_text = bert_preprocess(sentences)\n",
        "    return bert_encoder(preprocessed_text)['pooled_output']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur621TJ_LMrQ"
      },
      "outputs": [],
      "source": [
        "X_train = get_sentence_embeding(text_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiqzH_a3LMtu"
      },
      "outputs": [],
      "source": [
        "X_test0 = get_sentence_embeding(text_test0.values)\n",
        "X_outliers = get_sentence_embeding(data_an['comment'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aen2XAfuy9lY"
      },
      "outputs": [],
      "source": [
        "X_train = get_sentence_embeding(text_train.values)\n",
        "X_val = get_sentence_embeding(text_val.values)\n",
        "\n",
        "X_test0 = get_sentence_embeding(text_test0.values)\n",
        "X_outliers = get_sentence_embeding(data_an['comment'].values)\n",
        "\n",
        "#test set = (X_test + y_test) + anomaly class\n",
        "X_test = np.vstack([X_test0, X_outliers]) \n",
        "y_test = pd.concat([y_test0,data_an['label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4i50a8eLkOj"
      },
      "outputs": [],
      "source": [
        "#test set = (X_test + y_test) + anomaly class\n",
        "X_test = np.vstack([X_test0, X_outliers]) \n",
        "y_test = pd.concat([y_test0,data_an['label']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVUKqLODLkRB",
        "outputId": "f5ca48ed-0f63-402f-a008-b4a52b4d646f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(648, 768)\n",
            "(190, 768)\n",
            "(162, 768)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgMgTPHe1Qgd"
      },
      "outputs": [],
      "source": [
        "X_train=X_train.numpy()\n",
        "X_val=X_val.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_EmxUAI1QjU",
        "outputId": "626ce44e-4bea-4e13-dce7-b650d20ba25c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "96.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "768/8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTIE8ueH1DF0"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(768,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(384,activation='relu',return_sequences=True)),\n",
        "      Dropout(0.5),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.GRU(192,activation='relu')),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6dc8jmO1Qdh",
        "outputId": "bf719689-8349-4e24-91e1-c124d2a271df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (648, 768)\n",
            "Test data shape: (162, 768)\n",
            "Epoch 1/200\n",
            "4/4 [==============================] - 13s 515ms/step - loss: 2.3601 - accuracy: 0.1373 - val_loss: 2.3164 - val_accuracy: 0.1049\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 2.2471 - accuracy: 0.0988 - val_loss: 2.1944 - val_accuracy: 0.1111\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 2.1999 - accuracy: 0.1373 - val_loss: 2.1916 - val_accuracy: 0.1111\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 2.1906 - accuracy: 0.1204 - val_loss: 2.2054 - val_accuracy: 0.0802\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 2.1838 - accuracy: 0.1281 - val_loss: 2.1837 - val_accuracy: 0.1173\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 2.1889 - accuracy: 0.1111 - val_loss: 2.2062 - val_accuracy: 0.1111\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 2.1862 - accuracy: 0.1358 - val_loss: 2.1722 - val_accuracy: 0.1296\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 2.1714 - accuracy: 0.1481 - val_loss: 2.1666 - val_accuracy: 0.1173\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 2.1738 - accuracy: 0.1667 - val_loss: 2.1616 - val_accuracy: 0.1358\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 2.1606 - accuracy: 0.1744 - val_loss: 2.1523 - val_accuracy: 0.1420\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 2.1298 - accuracy: 0.1806 - val_loss: 2.1213 - val_accuracy: 0.1914\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 2.1706 - accuracy: 0.1759 - val_loss: 2.1408 - val_accuracy: 0.1975\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 2.1100 - accuracy: 0.1914 - val_loss: 2.0955 - val_accuracy: 0.2037\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 2.1217 - accuracy: 0.1775 - val_loss: 2.1387 - val_accuracy: 0.2160\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 2.0989 - accuracy: 0.2006 - val_loss: 2.0633 - val_accuracy: 0.1852\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 2.1299 - accuracy: 0.1914 - val_loss: 2.1089 - val_accuracy: 0.2531\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 2.0712 - accuracy: 0.2284 - val_loss: 2.0495 - val_accuracy: 0.1790\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 2.0321 - accuracy: 0.2052 - val_loss: 2.1423 - val_accuracy: 0.1790\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 2.0764 - accuracy: 0.2238 - val_loss: 2.0074 - val_accuracy: 0.3025\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 1.9710 - accuracy: 0.2639 - val_loss: 2.0638 - val_accuracy: 0.2469\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 2.2468 - accuracy: 0.1852 - val_loss: 2.0716 - val_accuracy: 0.2963\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.9864 - accuracy: 0.2901 - val_loss: 2.1787 - val_accuracy: 0.1790\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 2.0574 - accuracy: 0.2454 - val_loss: 2.0074 - val_accuracy: 0.2284\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 1.9218 - accuracy: 0.2886 - val_loss: 1.9896 - val_accuracy: 0.2469\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 2.1412 - accuracy: 0.2454 - val_loss: 1.9870 - val_accuracy: 0.2963\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 1.9533 - accuracy: 0.2948 - val_loss: 2.0139 - val_accuracy: 0.2531\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.9311 - accuracy: 0.3025 - val_loss: 1.9672 - val_accuracy: 0.2840\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.9468 - accuracy: 0.2639 - val_loss: 1.9530 - val_accuracy: 0.2654\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 1.8445 - accuracy: 0.3025 - val_loss: 2.0407 - val_accuracy: 0.2099\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 2.0938 - accuracy: 0.2469 - val_loss: 1.9904 - val_accuracy: 0.3025\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.8274 - accuracy: 0.3457 - val_loss: 1.8016 - val_accuracy: 0.3333\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.9226 - accuracy: 0.3102 - val_loss: 2.0036 - val_accuracy: 0.2593\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.8811 - accuracy: 0.3287 - val_loss: 1.8316 - val_accuracy: 0.2963\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 1.6968 - accuracy: 0.3750 - val_loss: 1.8281 - val_accuracy: 0.3148\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.8133 - accuracy: 0.3302 - val_loss: 1.9277 - val_accuracy: 0.2716\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.7381 - accuracy: 0.3966 - val_loss: 1.9215 - val_accuracy: 0.2901\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 2.1056 - accuracy: 0.2685 - val_loss: 1.8645 - val_accuracy: 0.3086\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.7701 - accuracy: 0.3395 - val_loss: 1.8351 - val_accuracy: 0.3025\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 1.7665 - accuracy: 0.3704 - val_loss: 1.7759 - val_accuracy: 0.3642\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.6174 - accuracy: 0.3904 - val_loss: 1.7831 - val_accuracy: 0.3519\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.6308 - accuracy: 0.4043 - val_loss: 2.2864 - val_accuracy: 0.2654\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.9252 - accuracy: 0.3380 - val_loss: 1.9473 - val_accuracy: 0.2284\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 1.6502 - accuracy: 0.4105 - val_loss: 1.6615 - val_accuracy: 0.3951\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 1.7365 - accuracy: 0.3627 - val_loss: 1.6575 - val_accuracy: 0.4321\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 1.4658 - accuracy: 0.5046 - val_loss: 2.3113 - val_accuracy: 0.2716\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 2s 394ms/step - loss: 2.0014 - accuracy: 0.3426 - val_loss: 1.6504 - val_accuracy: 0.4691\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 1.4367 - accuracy: 0.5031 - val_loss: 1.9039 - val_accuracy: 0.3210\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 2.0237 - accuracy: 0.3287 - val_loss: 1.7794 - val_accuracy: 0.3272\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.5365 - accuracy: 0.4522 - val_loss: 1.9016 - val_accuracy: 0.2901\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 1.7353 - accuracy: 0.3534 - val_loss: 1.6088 - val_accuracy: 0.3951\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.3589 - accuracy: 0.5154 - val_loss: 1.8808 - val_accuracy: 0.2840\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.6184 - accuracy: 0.3997 - val_loss: 1.6433 - val_accuracy: 0.4136\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.6189 - accuracy: 0.4306 - val_loss: 1.8357 - val_accuracy: 0.3395\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.5957 - accuracy: 0.4275 - val_loss: 1.5033 - val_accuracy: 0.4444\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 1.3628 - accuracy: 0.4954 - val_loss: 2.1142 - val_accuracy: 0.2469\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.7645 - accuracy: 0.3719 - val_loss: 1.9231 - val_accuracy: 0.2901\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.5251 - accuracy: 0.4676 - val_loss: 1.5663 - val_accuracy: 0.4630\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.3901 - accuracy: 0.4923 - val_loss: 1.5197 - val_accuracy: 0.4136\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 1.4690 - accuracy: 0.5247 - val_loss: 1.7824 - val_accuracy: 0.2716\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.4250 - accuracy: 0.4815 - val_loss: 1.7222 - val_accuracy: 0.3951\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 1.4104 - accuracy: 0.5247 - val_loss: 1.5891 - val_accuracy: 0.4691\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 1.4226 - accuracy: 0.4969 - val_loss: 1.8035 - val_accuracy: 0.4136\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 1.6581 - accuracy: 0.4398 - val_loss: 1.4279 - val_accuracy: 0.4815\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 1.4016 - accuracy: 0.5185 - val_loss: 1.7622 - val_accuracy: 0.3889\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.5121 - accuracy: 0.4522 - val_loss: 1.4557 - val_accuracy: 0.4506\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.2874 - accuracy: 0.5710 - val_loss: 1.6087 - val_accuracy: 0.3765\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.3125 - accuracy: 0.5432 - val_loss: 1.4951 - val_accuracy: 0.4506\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.3422 - accuracy: 0.5293 - val_loss: 1.4015 - val_accuracy: 0.5247\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.3917 - accuracy: 0.4923 - val_loss: 1.4461 - val_accuracy: 0.4877\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.2952 - accuracy: 0.5509 - val_loss: 1.5828 - val_accuracy: 0.4259\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 1.4668 - accuracy: 0.4552 - val_loss: 1.6004 - val_accuracy: 0.3889\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.4218 - accuracy: 0.5185 - val_loss: 1.3516 - val_accuracy: 0.5617\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.1597 - accuracy: 0.5772 - val_loss: 1.7906 - val_accuracy: 0.3951\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.8141 - accuracy: 0.4167 - val_loss: 1.4411 - val_accuracy: 0.5123\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.1973 - accuracy: 0.5972 - val_loss: 1.8202 - val_accuracy: 0.3827\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.3711 - accuracy: 0.5247 - val_loss: 1.3350 - val_accuracy: 0.5370\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.0781 - accuracy: 0.6204 - val_loss: 1.7919 - val_accuracy: 0.4383\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.4227 - accuracy: 0.5216 - val_loss: 1.3057 - val_accuracy: 0.4938\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 1.0517 - accuracy: 0.6219 - val_loss: 1.8948 - val_accuracy: 0.4321\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.5996 - accuracy: 0.4753 - val_loss: 1.3991 - val_accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.1253 - accuracy: 0.6142 - val_loss: 1.4093 - val_accuracy: 0.4938\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.1126 - accuracy: 0.6157 - val_loss: 1.3705 - val_accuracy: 0.4568\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.0256 - accuracy: 0.6358 - val_loss: 2.2399 - val_accuracy: 0.3765\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 1.6989 - accuracy: 0.4630 - val_loss: 1.5717 - val_accuracy: 0.4198\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.2008 - accuracy: 0.5864 - val_loss: 1.2578 - val_accuracy: 0.5062\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.0665 - accuracy: 0.6312 - val_loss: 2.4811 - val_accuracy: 0.3457\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 1.9046 - accuracy: 0.4120 - val_loss: 1.4596 - val_accuracy: 0.5062\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.0949 - accuracy: 0.6636 - val_loss: 1.3642 - val_accuracy: 0.4815\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.2136 - accuracy: 0.5556 - val_loss: 1.2005 - val_accuracy: 0.5741\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.9449 - accuracy: 0.6759 - val_loss: 2.0946 - val_accuracy: 0.3765\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.3763 - accuracy: 0.5571 - val_loss: 1.3240 - val_accuracy: 0.5123\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.1083 - accuracy: 0.6049 - val_loss: 1.5979 - val_accuracy: 0.4568\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 1.3597 - accuracy: 0.5617 - val_loss: 1.4697 - val_accuracy: 0.4630\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.1685 - accuracy: 0.5864 - val_loss: 1.3545 - val_accuracy: 0.4877\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 1.2067 - accuracy: 0.5772 - val_loss: 1.1844 - val_accuracy: 0.5617\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.9977 - accuracy: 0.6373 - val_loss: 1.7944 - val_accuracy: 0.4259\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.1479 - accuracy: 0.5972 - val_loss: 1.3532 - val_accuracy: 0.5309\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.0544 - accuracy: 0.6204 - val_loss: 1.3080 - val_accuracy: 0.5556\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.9735 - accuracy: 0.6466 - val_loss: 1.2110 - val_accuracy: 0.5309\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 1.1247 - accuracy: 0.5833 - val_loss: 1.2064 - val_accuracy: 0.5926\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.9736 - accuracy: 0.6682 - val_loss: 1.3447 - val_accuracy: 0.5494\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.1972 - accuracy: 0.5895 - val_loss: 1.6124 - val_accuracy: 0.4383\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.1493 - accuracy: 0.5910 - val_loss: 1.4485 - val_accuracy: 0.5123\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.1660 - accuracy: 0.5910 - val_loss: 1.3564 - val_accuracy: 0.5432\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.9768 - accuracy: 0.6559 - val_loss: 1.3072 - val_accuracy: 0.5617\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 1.4631 - accuracy: 0.5586 - val_loss: 2.1173 - val_accuracy: 0.3519\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 1.3733 - accuracy: 0.5509 - val_loss: 1.1748 - val_accuracy: 0.5802\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.8469 - accuracy: 0.7068 - val_loss: 1.3423 - val_accuracy: 0.5370\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.9319 - accuracy: 0.6713 - val_loss: 1.5949 - val_accuracy: 0.4444\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.9854 - accuracy: 0.6574 - val_loss: 1.8345 - val_accuracy: 0.4691\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.5235 - accuracy: 0.5401 - val_loss: 1.3307 - val_accuracy: 0.5556\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.9182 - accuracy: 0.6682 - val_loss: 1.3292 - val_accuracy: 0.5556\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.8950 - accuracy: 0.6914 - val_loss: 1.5413 - val_accuracy: 0.4815\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.9947 - accuracy: 0.6327 - val_loss: 1.4048 - val_accuracy: 0.5247\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 1.1110 - accuracy: 0.6003 - val_loss: 1.3848 - val_accuracy: 0.4877\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.9715 - accuracy: 0.6836 - val_loss: 1.6273 - val_accuracy: 0.4877\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 1.1818 - accuracy: 0.5880 - val_loss: 1.5458 - val_accuracy: 0.4691\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.9944 - accuracy: 0.6512 - val_loss: 1.3558 - val_accuracy: 0.5494\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 1.0286 - accuracy: 0.6481 - val_loss: 1.1905 - val_accuracy: 0.5494\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.8348 - accuracy: 0.7160 - val_loss: 1.7205 - val_accuracy: 0.4630\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.4597 - accuracy: 0.5571 - val_loss: 1.3424 - val_accuracy: 0.5679\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.0670 - accuracy: 0.6373 - val_loss: 1.2494 - val_accuracy: 0.5741\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.7704 - accuracy: 0.7253 - val_loss: 1.3256 - val_accuracy: 0.5370\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 1.1059 - accuracy: 0.6173 - val_loss: 1.2758 - val_accuracy: 0.5247\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 1.0754 - accuracy: 0.5926 - val_loss: 1.4999 - val_accuracy: 0.5123\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.9085 - accuracy: 0.6775 - val_loss: 1.3181 - val_accuracy: 0.5864\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.1079 - accuracy: 0.6281 - val_loss: 1.6272 - val_accuracy: 0.4815\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.1157 - accuracy: 0.6065 - val_loss: 1.1132 - val_accuracy: 0.6296\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.7297 - accuracy: 0.7454 - val_loss: 1.2758 - val_accuracy: 0.5802\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.8982 - accuracy: 0.6898 - val_loss: 1.2306 - val_accuracy: 0.5494\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.7721 - accuracy: 0.7145 - val_loss: 1.4638 - val_accuracy: 0.5309\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.8718 - accuracy: 0.6914 - val_loss: 1.7393 - val_accuracy: 0.4938\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 1.3672 - accuracy: 0.5957 - val_loss: 1.3834 - val_accuracy: 0.5247\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.8909 - accuracy: 0.7022 - val_loss: 1.0744 - val_accuracy: 0.6173\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.6576 - accuracy: 0.7531 - val_loss: 1.4055 - val_accuracy: 0.5309\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 1.3161 - accuracy: 0.5864 - val_loss: 1.7966 - val_accuracy: 0.3889\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 1.2722 - accuracy: 0.5432 - val_loss: 1.1420 - val_accuracy: 0.5679\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6789 - accuracy: 0.7824 - val_loss: 1.1797 - val_accuracy: 0.6173\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.1907 - accuracy: 0.6265 - val_loss: 1.5664 - val_accuracy: 0.5309\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.9550 - accuracy: 0.6682 - val_loss: 1.1019 - val_accuracy: 0.6173\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6961 - accuracy: 0.7654 - val_loss: 1.1549 - val_accuracy: 0.5988\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.8249 - accuracy: 0.7114 - val_loss: 1.5651 - val_accuracy: 0.5000\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.9973 - accuracy: 0.6605 - val_loss: 1.4613 - val_accuracy: 0.4815\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.8071 - accuracy: 0.7037 - val_loss: 1.4093 - val_accuracy: 0.5679\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.9446 - accuracy: 0.6821 - val_loss: 1.0607 - val_accuracy: 0.5926\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.7597 - accuracy: 0.7299 - val_loss: 1.4732 - val_accuracy: 0.5309\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.9550 - accuracy: 0.6713 - val_loss: 1.1013 - val_accuracy: 0.6111\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.6814 - accuracy: 0.7407 - val_loss: 1.2983 - val_accuracy: 0.5988\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.9209 - accuracy: 0.6744 - val_loss: 1.3739 - val_accuracy: 0.5741\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.7155 - accuracy: 0.7593 - val_loss: 1.5708 - val_accuracy: 0.5617\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.3937 - accuracy: 0.5833 - val_loss: 1.2513 - val_accuracy: 0.5309\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.8461 - accuracy: 0.7068 - val_loss: 1.1139 - val_accuracy: 0.6173\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.7403 - accuracy: 0.7423 - val_loss: 1.0442 - val_accuracy: 0.6605\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.7522 - accuracy: 0.7191 - val_loss: 1.5470 - val_accuracy: 0.5000\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 1.1197 - accuracy: 0.5957 - val_loss: 1.0498 - val_accuracy: 0.6296\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6777 - accuracy: 0.7716 - val_loss: 1.1581 - val_accuracy: 0.6111\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6472 - accuracy: 0.7716 - val_loss: 1.6954 - val_accuracy: 0.4753\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.2590 - accuracy: 0.5972 - val_loss: 1.4020 - val_accuracy: 0.5185\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.9705 - accuracy: 0.6512 - val_loss: 1.0472 - val_accuracy: 0.6111\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.6390 - accuracy: 0.7623 - val_loss: 1.4909 - val_accuracy: 0.5123\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 1.0495 - accuracy: 0.6281 - val_loss: 1.1641 - val_accuracy: 0.5926\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 0.7585 - accuracy: 0.7253 - val_loss: 1.1039 - val_accuracy: 0.6049\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 2s 363ms/step - loss: 0.8707 - accuracy: 0.6852 - val_loss: 1.2032 - val_accuracy: 0.5741\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.6557 - accuracy: 0.7701 - val_loss: 1.2096 - val_accuracy: 0.5741\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.8959 - accuracy: 0.6759 - val_loss: 1.2735 - val_accuracy: 0.5062\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.7330 - accuracy: 0.7546 - val_loss: 1.8378 - val_accuracy: 0.5370\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 1.3761 - accuracy: 0.5617 - val_loss: 1.0925 - val_accuracy: 0.6235\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.6016 - accuracy: 0.7994 - val_loss: 1.1062 - val_accuracy: 0.6543\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.8771 - accuracy: 0.7052 - val_loss: 1.3685 - val_accuracy: 0.5123\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.7903 - accuracy: 0.7284 - val_loss: 1.0612 - val_accuracy: 0.6296\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.6841 - accuracy: 0.7623 - val_loss: 1.2540 - val_accuracy: 0.5988\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.6112 - accuracy: 0.7793 - val_loss: 1.6508 - val_accuracy: 0.5247\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 1.3690 - accuracy: 0.5926 - val_loss: 1.3505 - val_accuracy: 0.4753\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.7609 - accuracy: 0.7315 - val_loss: 1.1808 - val_accuracy: 0.5988\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.6892 - accuracy: 0.7809 - val_loss: 1.3310 - val_accuracy: 0.5556\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 1.0735 - accuracy: 0.6466 - val_loss: 0.9928 - val_accuracy: 0.6235\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 0.4957 - accuracy: 0.8395 - val_loss: 1.6292 - val_accuracy: 0.5123\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.8524 - accuracy: 0.6914 - val_loss: 1.3448 - val_accuracy: 0.5247\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 2s 436ms/step - loss: 0.6874 - accuracy: 0.7701 - val_loss: 1.2559 - val_accuracy: 0.5926\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.8220 - accuracy: 0.7176 - val_loss: 1.1807 - val_accuracy: 0.5864\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6547 - accuracy: 0.7670 - val_loss: 1.4637 - val_accuracy: 0.5000\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.9474 - accuracy: 0.7006 - val_loss: 1.4727 - val_accuracy: 0.5247\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 0.7792 - accuracy: 0.7269 - val_loss: 1.3737 - val_accuracy: 0.6111\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.6562 - accuracy: 0.7917 - val_loss: 1.7682 - val_accuracy: 0.5062\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 1.2991 - accuracy: 0.6188 - val_loss: 1.0455 - val_accuracy: 0.6667\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.5826 - accuracy: 0.8086 - val_loss: 1.0411 - val_accuracy: 0.6111\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5095 - accuracy: 0.8194 - val_loss: 1.1286 - val_accuracy: 0.6605\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.7516 - accuracy: 0.7469 - val_loss: 1.3044 - val_accuracy: 0.5741\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.8910 - accuracy: 0.6898 - val_loss: 1.4590 - val_accuracy: 0.5556\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 1.0170 - accuracy: 0.6620 - val_loss: 1.3045 - val_accuracy: 0.5185\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.6898 - accuracy: 0.7469 - val_loss: 1.2415 - val_accuracy: 0.5802\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.7382 - accuracy: 0.7407 - val_loss: 1.2019 - val_accuracy: 0.6173\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 1s 337ms/step - loss: 0.8077 - accuracy: 0.7315 - val_loss: 1.1749 - val_accuracy: 0.5494\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.6630 - accuracy: 0.7608 - val_loss: 1.3699 - val_accuracy: 0.4815\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 1s 357ms/step - loss: 0.9458 - accuracy: 0.6713 - val_loss: 1.1402 - val_accuracy: 0.6049\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.5518 - accuracy: 0.7901 - val_loss: 1.1853 - val_accuracy: 0.6173\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.6651 - accuracy: 0.7562 - val_loss: 1.6225 - val_accuracy: 0.5062\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 1s 351ms/step - loss: 0.9536 - accuracy: 0.6651 - val_loss: 1.0457 - val_accuracy: 0.6296\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 0.6009 - accuracy: 0.8025 - val_loss: 1.2297 - val_accuracy: 0.5988\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 1s 348ms/step - loss: 0.6639 - accuracy: 0.7685 - val_loss: 0.9607 - val_accuracy: 0.6481\n"
          ]
        }
      ],
      "source": [
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "\n",
        "\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gu_ocoB4Wrm",
        "outputId": "2b1307eb-0006-431d-e654-677e452a7e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (648, 768)\n",
            "Test data shape: (162, 768)\n",
            "Epoch 1/200\n",
            "4/4 [==============================] - 3s 534ms/step - loss: 2.2562 - accuracy: 0.1127 - val_loss: 2.2066 - val_accuracy: 0.1605\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 2s 473ms/step - loss: 2.1995 - accuracy: 0.1250 - val_loss: 2.1860 - val_accuracy: 0.1420\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 2.1851 - accuracy: 0.1404 - val_loss: 2.1801 - val_accuracy: 0.1358\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 2s 500ms/step - loss: 2.1827 - accuracy: 0.1327 - val_loss: 2.1911 - val_accuracy: 0.1420\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 2.1648 - accuracy: 0.1512 - val_loss: 2.1613 - val_accuracy: 0.1790\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 3s 620ms/step - loss: 2.1458 - accuracy: 0.1651 - val_loss: 2.1528 - val_accuracy: 0.2037\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 2.1402 - accuracy: 0.1991 - val_loss: 2.1575 - val_accuracy: 0.1790\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 2.0932 - accuracy: 0.2253 - val_loss: 2.2575 - val_accuracy: 0.0802\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 2.1624 - accuracy: 0.1605 - val_loss: 2.1207 - val_accuracy: 0.1914\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 2s 466ms/step - loss: 2.1226 - accuracy: 0.1836 - val_loss: 2.1060 - val_accuracy: 0.1852\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 2.0577 - accuracy: 0.2253 - val_loss: 2.1294 - val_accuracy: 0.1852\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 2.0119 - accuracy: 0.2438 - val_loss: 2.2855 - val_accuracy: 0.1358\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 2s 468ms/step - loss: 2.1821 - accuracy: 0.1759 - val_loss: 2.0453 - val_accuracy: 0.2407\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 1.9662 - accuracy: 0.2994 - val_loss: 2.0478 - val_accuracy: 0.2284\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 2s 638ms/step - loss: 2.0783 - accuracy: 0.2330 - val_loss: 1.9818 - val_accuracy: 0.2716\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 3s 594ms/step - loss: 1.9391 - accuracy: 0.2963 - val_loss: 2.3231 - val_accuracy: 0.1481\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 2.0884 - accuracy: 0.2315 - val_loss: 1.9584 - val_accuracy: 0.2531\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 2s 438ms/step - loss: 1.8686 - accuracy: 0.3164 - val_loss: 2.2398 - val_accuracy: 0.1420\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 2.0732 - accuracy: 0.2253 - val_loss: 1.9428 - val_accuracy: 0.2407\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.8185 - accuracy: 0.3472 - val_loss: 2.0744 - val_accuracy: 0.1914\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 2s 500ms/step - loss: 1.9482 - accuracy: 0.2917 - val_loss: 2.0325 - val_accuracy: 0.2222\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 2s 472ms/step - loss: 1.8377 - accuracy: 0.3256 - val_loss: 1.8535 - val_accuracy: 0.3025\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 1.8958 - accuracy: 0.2994 - val_loss: 1.8849 - val_accuracy: 0.3086\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 1.7539 - accuracy: 0.3611 - val_loss: 2.1212 - val_accuracy: 0.2099\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 1.9333 - accuracy: 0.2978 - val_loss: 1.7843 - val_accuracy: 0.3704\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.6047 - accuracy: 0.4259 - val_loss: 2.9686 - val_accuracy: 0.1173\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 2.3172 - accuracy: 0.1975 - val_loss: 1.8002 - val_accuracy: 0.3333\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 1.6596 - accuracy: 0.4213 - val_loss: 1.8162 - val_accuracy: 0.3333\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 1.7607 - accuracy: 0.3673 - val_loss: 1.7460 - val_accuracy: 0.3395\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 2s 409ms/step - loss: 1.6407 - accuracy: 0.4198 - val_loss: 1.6484 - val_accuracy: 0.4136\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 1.6448 - accuracy: 0.4074 - val_loss: 1.9705 - val_accuracy: 0.2901\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 2s 494ms/step - loss: 1.8668 - accuracy: 0.3071 - val_loss: 1.6672 - val_accuracy: 0.4012\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.5419 - accuracy: 0.4753 - val_loss: 1.7865 - val_accuracy: 0.3333\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.4946 - accuracy: 0.4784 - val_loss: 2.0242 - val_accuracy: 0.2469\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 1.6346 - accuracy: 0.4259 - val_loss: 1.8490 - val_accuracy: 0.3025\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 1.4860 - accuracy: 0.4630 - val_loss: 1.9841 - val_accuracy: 0.2840\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 1.5490 - accuracy: 0.4444 - val_loss: 1.7379 - val_accuracy: 0.3704\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 2s 465ms/step - loss: 1.5700 - accuracy: 0.4275 - val_loss: 1.8686 - val_accuracy: 0.2840\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.4759 - accuracy: 0.4846 - val_loss: 1.7141 - val_accuracy: 0.3519\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.4583 - accuracy: 0.4676 - val_loss: 1.9657 - val_accuracy: 0.3765\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 2s 463ms/step - loss: 1.5892 - accuracy: 0.4475 - val_loss: 1.6919 - val_accuracy: 0.4136\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 1.4255 - accuracy: 0.5000 - val_loss: 1.8058 - val_accuracy: 0.3519\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 1.5217 - accuracy: 0.4444 - val_loss: 1.7318 - val_accuracy: 0.3272\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.4730 - accuracy: 0.4815 - val_loss: 1.5840 - val_accuracy: 0.4506\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 2s 466ms/step - loss: 1.5633 - accuracy: 0.4522 - val_loss: 1.9536 - val_accuracy: 0.3086\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 1.4716 - accuracy: 0.4522 - val_loss: 1.7091 - val_accuracy: 0.3704\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.2564 - accuracy: 0.5540 - val_loss: 1.6236 - val_accuracy: 0.4198\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 1.3443 - accuracy: 0.5401 - val_loss: 1.5912 - val_accuracy: 0.4136\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 1.3092 - accuracy: 0.5293 - val_loss: 1.5463 - val_accuracy: 0.4074\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 1.2747 - accuracy: 0.5586 - val_loss: 1.4190 - val_accuracy: 0.4568\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 1.1523 - accuracy: 0.6003 - val_loss: 2.3022 - val_accuracy: 0.2840\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 1.5069 - accuracy: 0.5015 - val_loss: 1.3589 - val_accuracy: 0.5123\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.2046 - accuracy: 0.5818 - val_loss: 1.6028 - val_accuracy: 0.4259\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 1.2911 - accuracy: 0.5309 - val_loss: 1.8543 - val_accuracy: 0.3457\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 2s 472ms/step - loss: 1.5412 - accuracy: 0.4614 - val_loss: 1.6980 - val_accuracy: 0.4198\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 2s 430ms/step - loss: 1.2503 - accuracy: 0.5633 - val_loss: 1.3089 - val_accuracy: 0.5679\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 1.2077 - accuracy: 0.5602 - val_loss: 1.4126 - val_accuracy: 0.4691\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 1.0586 - accuracy: 0.6204 - val_loss: 1.3272 - val_accuracy: 0.5309\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 2s 482ms/step - loss: 1.1132 - accuracy: 0.6019 - val_loss: 2.4415 - val_accuracy: 0.2346\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 1.4913 - accuracy: 0.5170 - val_loss: 1.4081 - val_accuracy: 0.4691\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 1.0153 - accuracy: 0.6620 - val_loss: 2.0443 - val_accuracy: 0.3642\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 3s 679ms/step - loss: 1.3985 - accuracy: 0.5185 - val_loss: 1.3150 - val_accuracy: 0.4938\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 1.1357 - accuracy: 0.6080 - val_loss: 1.4779 - val_accuracy: 0.4630\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.9851 - accuracy: 0.6713 - val_loss: 2.2173 - val_accuracy: 0.3457\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 1.5348 - accuracy: 0.4660 - val_loss: 1.3984 - val_accuracy: 0.5062\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 2s 468ms/step - loss: 0.9774 - accuracy: 0.6590 - val_loss: 1.5457 - val_accuracy: 0.4568\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 1.2247 - accuracy: 0.5602 - val_loss: 1.4839 - val_accuracy: 0.4877\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 1.1866 - accuracy: 0.5880 - val_loss: 1.5302 - val_accuracy: 0.5062\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 2s 443ms/step - loss: 1.3576 - accuracy: 0.5494 - val_loss: 1.2401 - val_accuracy: 0.5556\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 0.9498 - accuracy: 0.6636 - val_loss: 1.8031 - val_accuracy: 0.4012\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 2s 443ms/step - loss: 1.4518 - accuracy: 0.5340 - val_loss: 1.2063 - val_accuracy: 0.5556\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 0.8816 - accuracy: 0.6929 - val_loss: 2.2795 - val_accuracy: 0.3580\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 2s 415ms/step - loss: 1.6160 - accuracy: 0.4784 - val_loss: 1.4734 - val_accuracy: 0.4815\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 0.9414 - accuracy: 0.6929 - val_loss: 1.4117 - val_accuracy: 0.5123\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.9332 - accuracy: 0.6636 - val_loss: 1.5577 - val_accuracy: 0.4753\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.9501 - accuracy: 0.6682 - val_loss: 1.4261 - val_accuracy: 0.5309\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 1.0937 - accuracy: 0.6003 - val_loss: 1.6069 - val_accuracy: 0.4444\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 2s 410ms/step - loss: 1.0693 - accuracy: 0.6204 - val_loss: 1.6764 - val_accuracy: 0.4383\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 1.1875 - accuracy: 0.5818 - val_loss: 1.2922 - val_accuracy: 0.4815\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.8804 - accuracy: 0.7222 - val_loss: 1.4495 - val_accuracy: 0.4444\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 2s 453ms/step - loss: 0.9190 - accuracy: 0.6620 - val_loss: 1.2116 - val_accuracy: 0.5432\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 2s 442ms/step - loss: 0.9498 - accuracy: 0.6497 - val_loss: 1.5112 - val_accuracy: 0.4321\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 1.1940 - accuracy: 0.5910 - val_loss: 1.2619 - val_accuracy: 0.5432\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.8191 - accuracy: 0.7191 - val_loss: 1.3967 - val_accuracy: 0.5432\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 1.1580 - accuracy: 0.6235 - val_loss: 1.2180 - val_accuracy: 0.5494\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.7290 - accuracy: 0.7392 - val_loss: 1.7379 - val_accuracy: 0.4753\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 2s 480ms/step - loss: 1.1472 - accuracy: 0.5926 - val_loss: 1.7512 - val_accuracy: 0.3951\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 2s 417ms/step - loss: 1.3569 - accuracy: 0.5309 - val_loss: 1.1258 - val_accuracy: 0.5864\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.7144 - accuracy: 0.7747 - val_loss: 1.3586 - val_accuracy: 0.5309\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 2s 406ms/step - loss: 1.0502 - accuracy: 0.6512 - val_loss: 1.5430 - val_accuracy: 0.4630\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 0.9270 - accuracy: 0.6960 - val_loss: 1.4613 - val_accuracy: 0.5309\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.8904 - accuracy: 0.6759 - val_loss: 1.3682 - val_accuracy: 0.4815\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 2s 453ms/step - loss: 1.0020 - accuracy: 0.6235 - val_loss: 1.3027 - val_accuracy: 0.5432\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 2s 482ms/step - loss: 0.7555 - accuracy: 0.7593 - val_loss: 1.4171 - val_accuracy: 0.4691\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 2s 414ms/step - loss: 0.8550 - accuracy: 0.6898 - val_loss: 1.9313 - val_accuracy: 0.3827\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.1246 - accuracy: 0.6111 - val_loss: 1.3848 - val_accuracy: 0.5370\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 2s 414ms/step - loss: 0.9011 - accuracy: 0.6728 - val_loss: 1.2720 - val_accuracy: 0.5679\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.6141 - accuracy: 0.8071 - val_loss: 1.3576 - val_accuracy: 0.5309\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 1.1252 - accuracy: 0.6250 - val_loss: 1.6911 - val_accuracy: 0.4815\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.8949 - accuracy: 0.6821 - val_loss: 1.5739 - val_accuracy: 0.4383\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 1.1926 - accuracy: 0.5787 - val_loss: 1.6964 - val_accuracy: 0.4198\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 2s 411ms/step - loss: 0.9774 - accuracy: 0.6404 - val_loss: 1.2506 - val_accuracy: 0.5556\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.6864 - accuracy: 0.7762 - val_loss: 1.1937 - val_accuracy: 0.5494\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.6751 - accuracy: 0.7454 - val_loss: 1.3891 - val_accuracy: 0.5370\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.9843 - accuracy: 0.6312 - val_loss: 1.4278 - val_accuracy: 0.4753\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.8851 - accuracy: 0.6728 - val_loss: 1.1553 - val_accuracy: 0.5864\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 2s 442ms/step - loss: 0.6858 - accuracy: 0.7716 - val_loss: 2.0185 - val_accuracy: 0.4136\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 1.4112 - accuracy: 0.5556 - val_loss: 1.5759 - val_accuracy: 0.4568\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 0.7836 - accuracy: 0.7145 - val_loss: 1.2105 - val_accuracy: 0.5864\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.5851 - accuracy: 0.7886 - val_loss: 1.9083 - val_accuracy: 0.4198\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.9919 - accuracy: 0.6698 - val_loss: 1.3006 - val_accuracy: 0.5309\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.8068 - accuracy: 0.7315 - val_loss: 1.1751 - val_accuracy: 0.5988\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 2s 475ms/step - loss: 0.6472 - accuracy: 0.7654 - val_loss: 1.0516 - val_accuracy: 0.6111\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.6662 - accuracy: 0.7685 - val_loss: 1.3511 - val_accuracy: 0.5432\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.5896 - accuracy: 0.8148 - val_loss: 2.4091 - val_accuracy: 0.4136\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 1.3242 - accuracy: 0.5833 - val_loss: 1.1509 - val_accuracy: 0.5926\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 2s 416ms/step - loss: 0.7109 - accuracy: 0.7654 - val_loss: 1.3113 - val_accuracy: 0.5432\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.5413 - accuracy: 0.8364 - val_loss: 1.4615 - val_accuracy: 0.5309\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 1.0210 - accuracy: 0.6682 - val_loss: 1.8359 - val_accuracy: 0.4383\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 2s 613ms/step - loss: 0.9101 - accuracy: 0.6944 - val_loss: 1.3289 - val_accuracy: 0.5309\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.6616 - accuracy: 0.7793 - val_loss: 1.0436 - val_accuracy: 0.6235\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 0.4612 - accuracy: 0.8441 - val_loss: 1.3936 - val_accuracy: 0.5556\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.7309 - accuracy: 0.7485 - val_loss: 1.9086 - val_accuracy: 0.4321\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 2s 413ms/step - loss: 0.9699 - accuracy: 0.6682 - val_loss: 1.4138 - val_accuracy: 0.4877\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 2s 475ms/step - loss: 0.9621 - accuracy: 0.6528 - val_loss: 1.3229 - val_accuracy: 0.5741\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 2s 442ms/step - loss: 0.6081 - accuracy: 0.7824 - val_loss: 1.7287 - val_accuracy: 0.4753\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.8446 - accuracy: 0.7191 - val_loss: 1.6969 - val_accuracy: 0.5000\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.7004 - accuracy: 0.7793 - val_loss: 1.6535 - val_accuracy: 0.5556\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.8139 - accuracy: 0.7377 - val_loss: 1.0846 - val_accuracy: 0.5926\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 2s 440ms/step - loss: 0.5106 - accuracy: 0.8102 - val_loss: 1.2360 - val_accuracy: 0.5802\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 3s 680ms/step - loss: 0.6695 - accuracy: 0.7485 - val_loss: 1.1330 - val_accuracy: 0.6235\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 3s 523ms/step - loss: 0.6734 - accuracy: 0.7716 - val_loss: 2.9384 - val_accuracy: 0.3025\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 1.3532 - accuracy: 0.5910 - val_loss: 1.2344 - val_accuracy: 0.5617\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.5578 - accuracy: 0.8148 - val_loss: 1.0824 - val_accuracy: 0.6420\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 0.4060 - accuracy: 0.8642 - val_loss: 1.3953 - val_accuracy: 0.5309\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.8254 - accuracy: 0.7269 - val_loss: 1.4833 - val_accuracy: 0.5185\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.6255 - accuracy: 0.7824 - val_loss: 1.3182 - val_accuracy: 0.5556\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.5384 - accuracy: 0.8194 - val_loss: 1.3957 - val_accuracy: 0.5370\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 0.5468 - accuracy: 0.7870 - val_loss: 1.8109 - val_accuracy: 0.5000\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 1.3011 - accuracy: 0.5895 - val_loss: 1.2655 - val_accuracy: 0.5309\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 0.5155 - accuracy: 0.8287 - val_loss: 1.2042 - val_accuracy: 0.5926\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.5483 - accuracy: 0.8025 - val_loss: 1.1255 - val_accuracy: 0.6111\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 0.5524 - accuracy: 0.8025 - val_loss: 1.7111 - val_accuracy: 0.5062\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 1.0939 - accuracy: 0.6327 - val_loss: 1.2237 - val_accuracy: 0.5432\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.6193 - accuracy: 0.7855 - val_loss: 1.0391 - val_accuracy: 0.6420\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 0.4799 - accuracy: 0.8256 - val_loss: 1.1103 - val_accuracy: 0.6296\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.4280 - accuracy: 0.8349 - val_loss: 1.1487 - val_accuracy: 0.6420\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.4831 - accuracy: 0.8318 - val_loss: 1.3292 - val_accuracy: 0.5617\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 2s 453ms/step - loss: 0.8082 - accuracy: 0.7191 - val_loss: 1.2861 - val_accuracy: 0.5741\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.6488 - accuracy: 0.7670 - val_loss: 1.1970 - val_accuracy: 0.5556\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.5544 - accuracy: 0.8040 - val_loss: 1.5910 - val_accuracy: 0.5370\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 0.7543 - accuracy: 0.7330 - val_loss: 1.2368 - val_accuracy: 0.5679\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 0.5185 - accuracy: 0.8302 - val_loss: 1.4966 - val_accuracy: 0.5370\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 2s 510ms/step - loss: 0.6850 - accuracy: 0.7623 - val_loss: 1.0609 - val_accuracy: 0.6173\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.3777 - accuracy: 0.8735 - val_loss: 1.2432 - val_accuracy: 0.5802\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 2s 466ms/step - loss: 0.7288 - accuracy: 0.7515 - val_loss: 1.8332 - val_accuracy: 0.4877\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 2s 432ms/step - loss: 0.7774 - accuracy: 0.7346 - val_loss: 1.4369 - val_accuracy: 0.5309\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 0.5721 - accuracy: 0.8009 - val_loss: 1.8720 - val_accuracy: 0.4444\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 2s 474ms/step - loss: 0.8058 - accuracy: 0.7191 - val_loss: 1.2534 - val_accuracy: 0.5741\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 0.4643 - accuracy: 0.8457 - val_loss: 1.2529 - val_accuracy: 0.5864\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.4750 - accuracy: 0.8410 - val_loss: 1.0045 - val_accuracy: 0.6852\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.3378 - accuracy: 0.8858 - val_loss: 1.6217 - val_accuracy: 0.5309\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 2s 494ms/step - loss: 0.8522 - accuracy: 0.6867 - val_loss: 1.3828 - val_accuracy: 0.5802\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.7190 - accuracy: 0.7238 - val_loss: 1.5923 - val_accuracy: 0.5679\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 2s 423ms/step - loss: 0.4587 - accuracy: 0.8426 - val_loss: 1.0710 - val_accuracy: 0.6235\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.4241 - accuracy: 0.8457 - val_loss: 1.7614 - val_accuracy: 0.4938\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 1.1020 - accuracy: 0.6713 - val_loss: 1.3958 - val_accuracy: 0.5185\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.4436 - accuracy: 0.8627 - val_loss: 1.0475 - val_accuracy: 0.6481\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 2s 477ms/step - loss: 0.3082 - accuracy: 0.8951 - val_loss: 1.1096 - val_accuracy: 0.6420\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.3866 - accuracy: 0.8657 - val_loss: 1.4678 - val_accuracy: 0.5617\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 2s 440ms/step - loss: 0.6599 - accuracy: 0.7762 - val_loss: 1.3692 - val_accuracy: 0.5802\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.4645 - accuracy: 0.8441 - val_loss: 1.1452 - val_accuracy: 0.6111\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.5600 - accuracy: 0.8225 - val_loss: 1.5629 - val_accuracy: 0.5617\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 2s 407ms/step - loss: 0.6015 - accuracy: 0.7762 - val_loss: 1.1210 - val_accuracy: 0.6358\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 0.3262 - accuracy: 0.8951 - val_loss: 1.8891 - val_accuracy: 0.5062\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 1.0292 - accuracy: 0.7037 - val_loss: 1.8811 - val_accuracy: 0.5062\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.7760 - accuracy: 0.7438 - val_loss: 1.3257 - val_accuracy: 0.5679\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 3s 674ms/step - loss: 0.4122 - accuracy: 0.8781 - val_loss: 1.1118 - val_accuracy: 0.6481\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 0.3657 - accuracy: 0.8781 - val_loss: 1.2521 - val_accuracy: 0.6358\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.3525 - accuracy: 0.8858 - val_loss: 1.1416 - val_accuracy: 0.6296\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.3207 - accuracy: 0.8889 - val_loss: 1.4330 - val_accuracy: 0.5802\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 2s 410ms/step - loss: 0.4784 - accuracy: 0.8426 - val_loss: 2.5838 - val_accuracy: 0.4012\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 1.2156 - accuracy: 0.6605 - val_loss: 1.1257 - val_accuracy: 0.6543\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 0.3413 - accuracy: 0.8904 - val_loss: 1.2478 - val_accuracy: 0.6049\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.3915 - accuracy: 0.8750 - val_loss: 1.2625 - val_accuracy: 0.6049\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.3743 - accuracy: 0.8657 - val_loss: 2.7890 - val_accuracy: 0.4074\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 1.3310 - accuracy: 0.6451 - val_loss: 2.5378 - val_accuracy: 0.4136\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.7671 - accuracy: 0.7577 - val_loss: 1.0402 - val_accuracy: 0.6728\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 0.2421 - accuracy: 0.9306 - val_loss: 1.3073 - val_accuracy: 0.5926\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.5191 - accuracy: 0.8272 - val_loss: 1.1158 - val_accuracy: 0.6111\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.2364 - accuracy: 0.9182 - val_loss: 1.5478 - val_accuracy: 0.5556\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 0.3231 - accuracy: 0.8951 - val_loss: 1.3906 - val_accuracy: 0.5926\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.3115 - accuracy: 0.8781 - val_loss: 1.3783 - val_accuracy: 0.5617\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.6078 - accuracy: 0.8179 - val_loss: 1.8029 - val_accuracy: 0.5185\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.7542 - accuracy: 0.7469 - val_loss: 2.2571 - val_accuracy: 0.4444\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 2s 427ms/step - loss: 0.7643 - accuracy: 0.7577 - val_loss: 1.1366 - val_accuracy: 0.6049\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.4692 - accuracy: 0.8488 - val_loss: 1.1092 - val_accuracy: 0.6790\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.2328 - accuracy: 0.9336 - val_loss: 1.1161 - val_accuracy: 0.6296\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.3964 - accuracy: 0.8534 - val_loss: 1.5628 - val_accuracy: 0.5556\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 0.6393 - accuracy: 0.7762 - val_loss: 1.2662 - val_accuracy: 0.5864\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Conv1D(256, 14,strides=4, padding='causal', activation='relu'),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcKWGyKG_NQN",
        "outputId": "b4c4a39f-7195-43b9-9195-fe912db381b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (648, 768)\n",
            "Test data shape: (162, 768)\n",
            "Epoch 1/400\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 2.3077 - accuracy: 0.1111 - val_loss: 2.1966 - val_accuracy: 0.1173\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.2271 - accuracy: 0.1173 - val_loss: 2.1984 - val_accuracy: 0.1111\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2035 - accuracy: 0.1343 - val_loss: 2.2001 - val_accuracy: 0.1049\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1977 - accuracy: 0.1389 - val_loss: 2.1949 - val_accuracy: 0.1296\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2041 - accuracy: 0.1420 - val_loss: 2.1899 - val_accuracy: 0.1667\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.1947 - accuracy: 0.1343 - val_loss: 2.1930 - val_accuracy: 0.1481\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1839 - accuracy: 0.1528 - val_loss: 2.1917 - val_accuracy: 0.1481\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1862 - accuracy: 0.1512 - val_loss: 2.1799 - val_accuracy: 0.1852\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1703 - accuracy: 0.1759 - val_loss: 2.1683 - val_accuracy: 0.1728\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.1605 - accuracy: 0.2006 - val_loss: 2.1538 - val_accuracy: 0.1914\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1548 - accuracy: 0.1852 - val_loss: 2.1501 - val_accuracy: 0.1914\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1325 - accuracy: 0.1944 - val_loss: 2.1546 - val_accuracy: 0.1790\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1309 - accuracy: 0.2068 - val_loss: 2.1490 - val_accuracy: 0.1975\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.1360 - accuracy: 0.2068 - val_loss: 2.1421 - val_accuracy: 0.2222\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1107 - accuracy: 0.2238 - val_loss: 2.1387 - val_accuracy: 0.2346\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.1091 - accuracy: 0.2284 - val_loss: 2.1267 - val_accuracy: 0.2284\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0969 - accuracy: 0.2315 - val_loss: 2.1192 - val_accuracy: 0.2346\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.0830 - accuracy: 0.2330 - val_loss: 2.1063 - val_accuracy: 0.2160\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0767 - accuracy: 0.2361 - val_loss: 2.0865 - val_accuracy: 0.2654\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0615 - accuracy: 0.2253 - val_loss: 2.0719 - val_accuracy: 0.3210\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.0516 - accuracy: 0.2716 - val_loss: 2.0641 - val_accuracy: 0.2963\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.0145 - accuracy: 0.2731 - val_loss: 2.0557 - val_accuracy: 0.3148\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0287 - accuracy: 0.2731 - val_loss: 2.0505 - val_accuracy: 0.3148\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.9970 - accuracy: 0.2917 - val_loss: 2.0443 - val_accuracy: 0.3272\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0025 - accuracy: 0.3056 - val_loss: 2.0279 - val_accuracy: 0.3827\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9669 - accuracy: 0.3025 - val_loss: 2.0021 - val_accuracy: 0.3889\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.9564 - accuracy: 0.3194 - val_loss: 1.9830 - val_accuracy: 0.4012\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9405 - accuracy: 0.3395 - val_loss: 1.9797 - val_accuracy: 0.3519\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8989 - accuracy: 0.3688 - val_loss: 1.9718 - val_accuracy: 0.3395\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9263 - accuracy: 0.3287 - val_loss: 1.9441 - val_accuracy: 0.3580\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9122 - accuracy: 0.3580 - val_loss: 1.9235 - val_accuracy: 0.4012\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8825 - accuracy: 0.3642 - val_loss: 1.9139 - val_accuracy: 0.3951\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8632 - accuracy: 0.3704 - val_loss: 1.8964 - val_accuracy: 0.4012\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.8449 - accuracy: 0.3642 - val_loss: 1.8775 - val_accuracy: 0.4074\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8293 - accuracy: 0.3827 - val_loss: 1.8481 - val_accuracy: 0.3951\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7796 - accuracy: 0.4167 - val_loss: 1.8348 - val_accuracy: 0.4259\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7529 - accuracy: 0.4028 - val_loss: 1.8110 - val_accuracy: 0.4136\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7766 - accuracy: 0.4012 - val_loss: 1.7845 - val_accuracy: 0.4136\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7372 - accuracy: 0.4059 - val_loss: 1.7557 - val_accuracy: 0.4568\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.7521 - accuracy: 0.4059 - val_loss: 1.7606 - val_accuracy: 0.4444\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6933 - accuracy: 0.4244 - val_loss: 1.7551 - val_accuracy: 0.4383\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.6319 - accuracy: 0.4691 - val_loss: 1.7095 - val_accuracy: 0.4630\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.6921 - accuracy: 0.4228 - val_loss: 1.7445 - val_accuracy: 0.4444\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.6546 - accuracy: 0.4630 - val_loss: 1.7018 - val_accuracy: 0.4568\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6032 - accuracy: 0.4954 - val_loss: 1.6491 - val_accuracy: 0.4815\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.6055 - accuracy: 0.4429 - val_loss: 1.6615 - val_accuracy: 0.4568\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.5693 - accuracy: 0.5062 - val_loss: 1.6701 - val_accuracy: 0.4506\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.5467 - accuracy: 0.5247 - val_loss: 1.5994 - val_accuracy: 0.5062\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.5359 - accuracy: 0.4907 - val_loss: 1.5825 - val_accuracy: 0.4877\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5212 - accuracy: 0.5401 - val_loss: 1.5981 - val_accuracy: 0.4877\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4831 - accuracy: 0.5386 - val_loss: 1.5814 - val_accuracy: 0.4938\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4890 - accuracy: 0.5123 - val_loss: 1.5359 - val_accuracy: 0.5062\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.4585 - accuracy: 0.5417 - val_loss: 1.5181 - val_accuracy: 0.5123\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4821 - accuracy: 0.5139 - val_loss: 1.5472 - val_accuracy: 0.5185\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4623 - accuracy: 0.5262 - val_loss: 1.5130 - val_accuracy: 0.5185\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4595 - accuracy: 0.5231 - val_loss: 1.4938 - val_accuracy: 0.5123\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3959 - accuracy: 0.5540 - val_loss: 1.4814 - val_accuracy: 0.5185\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4186 - accuracy: 0.5478 - val_loss: 1.4567 - val_accuracy: 0.5432\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3765 - accuracy: 0.5648 - val_loss: 1.4587 - val_accuracy: 0.5432\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.3686 - accuracy: 0.5432 - val_loss: 1.4238 - val_accuracy: 0.5494\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3511 - accuracy: 0.5432 - val_loss: 1.4339 - val_accuracy: 0.5432\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3043 - accuracy: 0.6080 - val_loss: 1.4074 - val_accuracy: 0.5679\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2800 - accuracy: 0.5957 - val_loss: 1.3834 - val_accuracy: 0.5370\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3112 - accuracy: 0.5556 - val_loss: 1.3778 - val_accuracy: 0.5432\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3081 - accuracy: 0.5664 - val_loss: 1.3603 - val_accuracy: 0.5309\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2636 - accuracy: 0.5957 - val_loss: 1.3669 - val_accuracy: 0.5679\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2722 - accuracy: 0.5972 - val_loss: 1.3437 - val_accuracy: 0.5802\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2536 - accuracy: 0.5880 - val_loss: 1.3493 - val_accuracy: 0.5741\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2432 - accuracy: 0.6019 - val_loss: 1.3260 - val_accuracy: 0.5864\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2525 - accuracy: 0.5880 - val_loss: 1.3006 - val_accuracy: 0.5926\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2546 - accuracy: 0.5926 - val_loss: 1.3276 - val_accuracy: 0.5617\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2222 - accuracy: 0.6096 - val_loss: 1.3192 - val_accuracy: 0.5679\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.1920 - accuracy: 0.6003 - val_loss: 1.2548 - val_accuracy: 0.6235\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2328 - accuracy: 0.5880 - val_loss: 1.2762 - val_accuracy: 0.5988\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1928 - accuracy: 0.6003 - val_loss: 1.2854 - val_accuracy: 0.5864\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1505 - accuracy: 0.6327 - val_loss: 1.2152 - val_accuracy: 0.6111\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1322 - accuracy: 0.6296 - val_loss: 1.2332 - val_accuracy: 0.5864\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1266 - accuracy: 0.6327 - val_loss: 1.2424 - val_accuracy: 0.5988\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1275 - accuracy: 0.6389 - val_loss: 1.2042 - val_accuracy: 0.6296\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1098 - accuracy: 0.6281 - val_loss: 1.2471 - val_accuracy: 0.5802\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1232 - accuracy: 0.6435 - val_loss: 1.1992 - val_accuracy: 0.5988\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1104 - accuracy: 0.6466 - val_loss: 1.1936 - val_accuracy: 0.6235\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.0890 - accuracy: 0.6281 - val_loss: 1.1784 - val_accuracy: 0.5926\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0880 - accuracy: 0.6543 - val_loss: 1.1673 - val_accuracy: 0.5864\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0499 - accuracy: 0.6636 - val_loss: 1.1783 - val_accuracy: 0.6173\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0317 - accuracy: 0.6451 - val_loss: 1.1705 - val_accuracy: 0.6358\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0800 - accuracy: 0.6481 - val_loss: 1.1645 - val_accuracy: 0.6111\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0555 - accuracy: 0.6559 - val_loss: 1.1402 - val_accuracy: 0.6173\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0154 - accuracy: 0.6728 - val_loss: 1.1418 - val_accuracy: 0.6481\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0275 - accuracy: 0.6651 - val_loss: 1.1333 - val_accuracy: 0.6358\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9818 - accuracy: 0.6821 - val_loss: 1.1198 - val_accuracy: 0.6049\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0038 - accuracy: 0.6667 - val_loss: 1.1010 - val_accuracy: 0.6358\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0086 - accuracy: 0.6728 - val_loss: 1.1113 - val_accuracy: 0.6358\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9893 - accuracy: 0.6698 - val_loss: 1.1138 - val_accuracy: 0.6173\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0241 - accuracy: 0.6574 - val_loss: 1.1005 - val_accuracy: 0.6358\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9809 - accuracy: 0.6759 - val_loss: 1.0992 - val_accuracy: 0.6420\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9346 - accuracy: 0.7037 - val_loss: 1.0951 - val_accuracy: 0.6235\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9799 - accuracy: 0.6775 - val_loss: 1.0643 - val_accuracy: 0.6667\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9508 - accuracy: 0.6836 - val_loss: 1.0659 - val_accuracy: 0.6605\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9051 - accuracy: 0.6975 - val_loss: 1.0442 - val_accuracy: 0.6481\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9480 - accuracy: 0.6898 - val_loss: 1.0377 - val_accuracy: 0.6481\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9206 - accuracy: 0.7099 - val_loss: 1.0643 - val_accuracy: 0.6543\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9356 - accuracy: 0.6960 - val_loss: 1.0711 - val_accuracy: 0.6296\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8690 - accuracy: 0.7145 - val_loss: 1.0269 - val_accuracy: 0.6667\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8712 - accuracy: 0.7269 - val_loss: 1.0223 - val_accuracy: 0.6605\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8643 - accuracy: 0.7160 - val_loss: 1.0134 - val_accuracy: 0.6543\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8794 - accuracy: 0.7222 - val_loss: 1.0058 - val_accuracy: 0.6728\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8631 - accuracy: 0.7037 - val_loss: 1.0171 - val_accuracy: 0.6605\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8625 - accuracy: 0.7330 - val_loss: 1.0044 - val_accuracy: 0.6790\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8473 - accuracy: 0.7284 - val_loss: 1.0083 - val_accuracy: 0.6728\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8877 - accuracy: 0.6836 - val_loss: 1.0157 - val_accuracy: 0.6481\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8827 - accuracy: 0.7022 - val_loss: 0.9810 - val_accuracy: 0.6728\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8603 - accuracy: 0.7207 - val_loss: 0.9735 - val_accuracy: 0.6914\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8396 - accuracy: 0.7176 - val_loss: 0.9917 - val_accuracy: 0.6914\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8512 - accuracy: 0.7284 - val_loss: 0.9903 - val_accuracy: 0.6914\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8571 - accuracy: 0.7114 - val_loss: 0.9776 - val_accuracy: 0.6914\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8340 - accuracy: 0.7207 - val_loss: 0.9626 - val_accuracy: 0.6975\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8119 - accuracy: 0.7269 - val_loss: 0.9721 - val_accuracy: 0.6790\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8290 - accuracy: 0.7269 - val_loss: 0.9856 - val_accuracy: 0.6667\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7850 - accuracy: 0.7639 - val_loss: 0.9501 - val_accuracy: 0.7099\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8290 - accuracy: 0.7052 - val_loss: 0.9429 - val_accuracy: 0.7099\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8377 - accuracy: 0.7284 - val_loss: 0.9588 - val_accuracy: 0.6852\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7711 - accuracy: 0.7531 - val_loss: 0.9279 - val_accuracy: 0.7160\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7912 - accuracy: 0.7469 - val_loss: 0.9416 - val_accuracy: 0.6667\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7798 - accuracy: 0.7454 - val_loss: 0.9278 - val_accuracy: 0.6975\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7452 - accuracy: 0.7608 - val_loss: 0.9114 - val_accuracy: 0.7222\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7881 - accuracy: 0.7623 - val_loss: 0.9679 - val_accuracy: 0.6605\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7877 - accuracy: 0.7423 - val_loss: 0.9653 - val_accuracy: 0.6296\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7912 - accuracy: 0.7469 - val_loss: 0.9126 - val_accuracy: 0.7284\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7745 - accuracy: 0.7330 - val_loss: 0.9404 - val_accuracy: 0.7037\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7764 - accuracy: 0.7515 - val_loss: 0.9771 - val_accuracy: 0.6667\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7689 - accuracy: 0.7454 - val_loss: 0.8832 - val_accuracy: 0.7407\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7784 - accuracy: 0.7361 - val_loss: 0.9084 - val_accuracy: 0.6975\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7810 - accuracy: 0.7315 - val_loss: 0.9417 - val_accuracy: 0.6605\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7408 - accuracy: 0.7623 - val_loss: 0.9142 - val_accuracy: 0.7037\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7562 - accuracy: 0.7577 - val_loss: 0.9038 - val_accuracy: 0.7407\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7316 - accuracy: 0.7654 - val_loss: 0.9344 - val_accuracy: 0.6975\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7500 - accuracy: 0.7593 - val_loss: 0.8746 - val_accuracy: 0.7222\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7193 - accuracy: 0.7639 - val_loss: 0.8684 - val_accuracy: 0.7284\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7412 - accuracy: 0.7469 - val_loss: 0.9153 - val_accuracy: 0.6852\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7231 - accuracy: 0.7608 - val_loss: 0.8870 - val_accuracy: 0.7160\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7113 - accuracy: 0.7932 - val_loss: 0.8593 - val_accuracy: 0.7346\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7017 - accuracy: 0.7793 - val_loss: 0.8909 - val_accuracy: 0.6975\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7239 - accuracy: 0.7731 - val_loss: 0.8791 - val_accuracy: 0.6914\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6833 - accuracy: 0.8009 - val_loss: 0.8837 - val_accuracy: 0.7160\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7144 - accuracy: 0.7639 - val_loss: 0.8948 - val_accuracy: 0.6790\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7008 - accuracy: 0.7639 - val_loss: 0.8903 - val_accuracy: 0.6728\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7067 - accuracy: 0.7716 - val_loss: 0.8660 - val_accuracy: 0.7469\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7041 - accuracy: 0.7593 - val_loss: 0.8805 - val_accuracy: 0.7099\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6534 - accuracy: 0.7886 - val_loss: 0.9060 - val_accuracy: 0.6914\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6820 - accuracy: 0.7608 - val_loss: 0.8374 - val_accuracy: 0.7407\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6518 - accuracy: 0.8009 - val_loss: 0.8378 - val_accuracy: 0.7346\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6972 - accuracy: 0.7623 - val_loss: 0.8767 - val_accuracy: 0.7099\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7130 - accuracy: 0.7608 - val_loss: 0.8317 - val_accuracy: 0.7222\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6970 - accuracy: 0.7886 - val_loss: 0.8484 - val_accuracy: 0.7531\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6733 - accuracy: 0.7824 - val_loss: 0.9191 - val_accuracy: 0.6790\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6962 - accuracy: 0.7531 - val_loss: 0.8627 - val_accuracy: 0.6975\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6583 - accuracy: 0.7824 - val_loss: 0.7988 - val_accuracy: 0.7469\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6676 - accuracy: 0.7778 - val_loss: 0.8193 - val_accuracy: 0.7469\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6737 - accuracy: 0.7886 - val_loss: 0.8757 - val_accuracy: 0.6914\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6532 - accuracy: 0.7948 - val_loss: 0.8284 - val_accuracy: 0.7654\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6803 - accuracy: 0.7623 - val_loss: 0.8053 - val_accuracy: 0.7469\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6243 - accuracy: 0.7886 - val_loss: 0.8498 - val_accuracy: 0.7037\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6436 - accuracy: 0.7994 - val_loss: 0.8355 - val_accuracy: 0.7407\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6246 - accuracy: 0.7948 - val_loss: 0.8124 - val_accuracy: 0.7716\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6396 - accuracy: 0.7870 - val_loss: 0.8180 - val_accuracy: 0.7407\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6213 - accuracy: 0.7948 - val_loss: 0.8106 - val_accuracy: 0.7407\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6153 - accuracy: 0.8025 - val_loss: 0.8010 - val_accuracy: 0.7593\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5938 - accuracy: 0.8133 - val_loss: 0.7956 - val_accuracy: 0.7716\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5891 - accuracy: 0.8086 - val_loss: 0.7948 - val_accuracy: 0.7654\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5976 - accuracy: 0.8040 - val_loss: 0.7774 - val_accuracy: 0.7654\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6080 - accuracy: 0.7994 - val_loss: 0.7802 - val_accuracy: 0.7654\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6177 - accuracy: 0.8164 - val_loss: 0.7741 - val_accuracy: 0.7531\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6097 - accuracy: 0.8071 - val_loss: 0.8277 - val_accuracy: 0.7222\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5907 - accuracy: 0.8164 - val_loss: 0.7808 - val_accuracy: 0.7531\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5943 - accuracy: 0.8040 - val_loss: 0.7890 - val_accuracy: 0.7654\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6184 - accuracy: 0.7994 - val_loss: 0.7949 - val_accuracy: 0.7531\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6071 - accuracy: 0.7994 - val_loss: 0.8060 - val_accuracy: 0.7222\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5819 - accuracy: 0.8272 - val_loss: 0.7693 - val_accuracy: 0.7778\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5379 - accuracy: 0.8349 - val_loss: 0.7866 - val_accuracy: 0.7716\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5461 - accuracy: 0.8302 - val_loss: 0.7902 - val_accuracy: 0.7222\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5750 - accuracy: 0.8210 - val_loss: 0.7768 - val_accuracy: 0.7654\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5547 - accuracy: 0.8272 - val_loss: 0.7604 - val_accuracy: 0.7778\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5862 - accuracy: 0.8210 - val_loss: 0.7871 - val_accuracy: 0.7407\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5515 - accuracy: 0.8302 - val_loss: 0.7754 - val_accuracy: 0.7469\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5610 - accuracy: 0.8256 - val_loss: 0.7486 - val_accuracy: 0.7840\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5569 - accuracy: 0.8395 - val_loss: 0.7833 - val_accuracy: 0.7346\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5903 - accuracy: 0.8164 - val_loss: 0.7979 - val_accuracy: 0.7469\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5738 - accuracy: 0.8009 - val_loss: 0.7320 - val_accuracy: 0.7716\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5584 - accuracy: 0.8225 - val_loss: 0.7801 - val_accuracy: 0.7593\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5438 - accuracy: 0.8395 - val_loss: 0.8089 - val_accuracy: 0.7284\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5517 - accuracy: 0.8164 - val_loss: 0.7552 - val_accuracy: 0.7716\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5912 - accuracy: 0.8086 - val_loss: 0.7350 - val_accuracy: 0.7963\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5548 - accuracy: 0.8179 - val_loss: 0.7916 - val_accuracy: 0.7346\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5456 - accuracy: 0.8194 - val_loss: 0.7614 - val_accuracy: 0.7840\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5117 - accuracy: 0.8333 - val_loss: 0.7510 - val_accuracy: 0.7654\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5555 - accuracy: 0.8164 - val_loss: 0.7565 - val_accuracy: 0.7531\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5466 - accuracy: 0.8086 - val_loss: 0.7804 - val_accuracy: 0.7407\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5467 - accuracy: 0.8302 - val_loss: 0.7316 - val_accuracy: 0.7778\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5657 - accuracy: 0.8333 - val_loss: 0.7278 - val_accuracy: 0.7654\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5126 - accuracy: 0.8318 - val_loss: 0.7611 - val_accuracy: 0.7593\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5151 - accuracy: 0.8349 - val_loss: 0.7553 - val_accuracy: 0.7469\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4927 - accuracy: 0.8457 - val_loss: 0.7138 - val_accuracy: 0.7716\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5432 - accuracy: 0.8225 - val_loss: 0.7246 - val_accuracy: 0.7778\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5305 - accuracy: 0.8194 - val_loss: 0.7484 - val_accuracy: 0.7778\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5091 - accuracy: 0.8333 - val_loss: 0.7309 - val_accuracy: 0.7778\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5239 - accuracy: 0.8318 - val_loss: 0.7145 - val_accuracy: 0.7654\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4990 - accuracy: 0.8457 - val_loss: 0.7315 - val_accuracy: 0.7593\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5134 - accuracy: 0.8256 - val_loss: 0.7070 - val_accuracy: 0.7901\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5067 - accuracy: 0.8333 - val_loss: 0.7128 - val_accuracy: 0.7840\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5462 - accuracy: 0.8164 - val_loss: 0.7533 - val_accuracy: 0.7778\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5200 - accuracy: 0.8179 - val_loss: 0.7067 - val_accuracy: 0.7778\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5032 - accuracy: 0.8457 - val_loss: 0.6981 - val_accuracy: 0.7716\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4836 - accuracy: 0.8519 - val_loss: 0.7013 - val_accuracy: 0.7716\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4989 - accuracy: 0.8410 - val_loss: 0.7051 - val_accuracy: 0.7840\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5020 - accuracy: 0.8349 - val_loss: 0.7208 - val_accuracy: 0.7778\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4807 - accuracy: 0.8519 - val_loss: 0.6892 - val_accuracy: 0.7963\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4577 - accuracy: 0.8565 - val_loss: 0.7146 - val_accuracy: 0.7778\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5067 - accuracy: 0.8472 - val_loss: 0.7243 - val_accuracy: 0.7963\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4731 - accuracy: 0.8642 - val_loss: 0.6911 - val_accuracy: 0.7901\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4244 - accuracy: 0.8812 - val_loss: 0.6941 - val_accuracy: 0.7840\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4368 - accuracy: 0.8673 - val_loss: 0.6813 - val_accuracy: 0.7963\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4700 - accuracy: 0.8549 - val_loss: 0.7120 - val_accuracy: 0.7901\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4814 - accuracy: 0.8472 - val_loss: 0.6789 - val_accuracy: 0.7901\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4380 - accuracy: 0.8611 - val_loss: 0.6859 - val_accuracy: 0.7840\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4533 - accuracy: 0.8611 - val_loss: 0.7026 - val_accuracy: 0.7716\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4662 - accuracy: 0.8596 - val_loss: 0.7244 - val_accuracy: 0.7716\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4845 - accuracy: 0.8534 - val_loss: 0.6821 - val_accuracy: 0.7901\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4628 - accuracy: 0.8688 - val_loss: 0.6919 - val_accuracy: 0.8025\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4342 - accuracy: 0.8580 - val_loss: 0.7235 - val_accuracy: 0.7716\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4643 - accuracy: 0.8364 - val_loss: 0.6711 - val_accuracy: 0.7901\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4520 - accuracy: 0.8472 - val_loss: 0.6793 - val_accuracy: 0.7840\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4235 - accuracy: 0.8580 - val_loss: 0.6795 - val_accuracy: 0.7901\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4552 - accuracy: 0.8519 - val_loss: 0.7286 - val_accuracy: 0.7531\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4530 - accuracy: 0.8596 - val_loss: 0.6895 - val_accuracy: 0.7654\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4568 - accuracy: 0.8627 - val_loss: 0.6743 - val_accuracy: 0.7963\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4232 - accuracy: 0.8627 - val_loss: 0.6696 - val_accuracy: 0.7840\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4408 - accuracy: 0.8534 - val_loss: 0.6983 - val_accuracy: 0.7778\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4298 - accuracy: 0.8549 - val_loss: 0.6816 - val_accuracy: 0.7901\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3987 - accuracy: 0.8750 - val_loss: 0.6687 - val_accuracy: 0.7901\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4488 - accuracy: 0.8519 - val_loss: 0.6975 - val_accuracy: 0.7840\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4302 - accuracy: 0.8596 - val_loss: 0.7197 - val_accuracy: 0.7716\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4406 - accuracy: 0.8765 - val_loss: 0.6788 - val_accuracy: 0.7778\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4222 - accuracy: 0.8796 - val_loss: 0.6750 - val_accuracy: 0.8086\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4631 - accuracy: 0.8503 - val_loss: 0.6947 - val_accuracy: 0.7531\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3972 - accuracy: 0.8611 - val_loss: 0.6539 - val_accuracy: 0.7840\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4228 - accuracy: 0.8503 - val_loss: 0.6710 - val_accuracy: 0.7901\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4584 - accuracy: 0.8364 - val_loss: 0.6908 - val_accuracy: 0.7963\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4200 - accuracy: 0.8750 - val_loss: 0.6889 - val_accuracy: 0.7901\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4183 - accuracy: 0.8657 - val_loss: 0.6445 - val_accuracy: 0.8086\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4132 - accuracy: 0.8812 - val_loss: 0.6422 - val_accuracy: 0.8025\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3968 - accuracy: 0.8781 - val_loss: 0.6572 - val_accuracy: 0.7840\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4247 - accuracy: 0.8657 - val_loss: 0.6706 - val_accuracy: 0.7963\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4122 - accuracy: 0.8781 - val_loss: 0.6597 - val_accuracy: 0.7963\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4125 - accuracy: 0.8704 - val_loss: 0.6524 - val_accuracy: 0.7963\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4460 - accuracy: 0.8441 - val_loss: 0.6627 - val_accuracy: 0.7963\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3813 - accuracy: 0.8904 - val_loss: 0.6604 - val_accuracy: 0.7901\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4164 - accuracy: 0.8750 - val_loss: 0.6581 - val_accuracy: 0.7901\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4041 - accuracy: 0.8688 - val_loss: 0.6824 - val_accuracy: 0.7716\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4123 - accuracy: 0.8627 - val_loss: 0.6388 - val_accuracy: 0.7963\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3790 - accuracy: 0.8719 - val_loss: 0.6252 - val_accuracy: 0.8086\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3873 - accuracy: 0.8843 - val_loss: 0.6583 - val_accuracy: 0.8025\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4051 - accuracy: 0.8488 - val_loss: 0.6704 - val_accuracy: 0.8086\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3979 - accuracy: 0.8889 - val_loss: 0.6506 - val_accuracy: 0.7963\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3918 - accuracy: 0.8796 - val_loss: 0.6240 - val_accuracy: 0.8025\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3884 - accuracy: 0.8873 - val_loss: 0.6602 - val_accuracy: 0.7901\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4026 - accuracy: 0.8750 - val_loss: 0.6669 - val_accuracy: 0.8025\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3685 - accuracy: 0.8812 - val_loss: 0.6224 - val_accuracy: 0.7901\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4026 - accuracy: 0.8673 - val_loss: 0.6242 - val_accuracy: 0.8086\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3673 - accuracy: 0.8935 - val_loss: 0.6701 - val_accuracy: 0.7963\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3862 - accuracy: 0.8796 - val_loss: 0.6407 - val_accuracy: 0.8148\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3628 - accuracy: 0.9012 - val_loss: 0.6442 - val_accuracy: 0.8025\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3864 - accuracy: 0.8765 - val_loss: 0.6598 - val_accuracy: 0.7901\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3909 - accuracy: 0.8673 - val_loss: 0.6464 - val_accuracy: 0.8210\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3680 - accuracy: 0.8904 - val_loss: 0.6477 - val_accuracy: 0.8025\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3733 - accuracy: 0.8843 - val_loss: 0.6350 - val_accuracy: 0.8025\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3591 - accuracy: 0.9059 - val_loss: 0.6580 - val_accuracy: 0.7901\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3679 - accuracy: 0.8843 - val_loss: 0.6431 - val_accuracy: 0.7901\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3852 - accuracy: 0.8812 - val_loss: 0.6325 - val_accuracy: 0.8148\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.3896 - accuracy: 0.8704 - val_loss: 0.6297 - val_accuracy: 0.8148\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3272 - accuracy: 0.9090 - val_loss: 0.6482 - val_accuracy: 0.8025\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3968 - accuracy: 0.8704 - val_loss: 0.6302 - val_accuracy: 0.8210\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3230 - accuracy: 0.9074 - val_loss: 0.6179 - val_accuracy: 0.8086\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3529 - accuracy: 0.8997 - val_loss: 0.6200 - val_accuracy: 0.7840\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3544 - accuracy: 0.8951 - val_loss: 0.6642 - val_accuracy: 0.7963\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3354 - accuracy: 0.8966 - val_loss: 0.6343 - val_accuracy: 0.7901\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3373 - accuracy: 0.8966 - val_loss: 0.6192 - val_accuracy: 0.7901\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3819 - accuracy: 0.8827 - val_loss: 0.6592 - val_accuracy: 0.7778\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3568 - accuracy: 0.8873 - val_loss: 0.6866 - val_accuracy: 0.7840\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3969 - accuracy: 0.8781 - val_loss: 0.6011 - val_accuracy: 0.7963\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3868 - accuracy: 0.8735 - val_loss: 0.6033 - val_accuracy: 0.7963\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3536 - accuracy: 0.8920 - val_loss: 0.6358 - val_accuracy: 0.7963\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3286 - accuracy: 0.8997 - val_loss: 0.6196 - val_accuracy: 0.7963\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3600 - accuracy: 0.8858 - val_loss: 0.6183 - val_accuracy: 0.7840\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3467 - accuracy: 0.8904 - val_loss: 0.6305 - val_accuracy: 0.7901\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3692 - accuracy: 0.8827 - val_loss: 0.6537 - val_accuracy: 0.7840\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3462 - accuracy: 0.8966 - val_loss: 0.6247 - val_accuracy: 0.7840\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3437 - accuracy: 0.9012 - val_loss: 0.6071 - val_accuracy: 0.7901\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3674 - accuracy: 0.8843 - val_loss: 0.6104 - val_accuracy: 0.8025\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3351 - accuracy: 0.8951 - val_loss: 0.6249 - val_accuracy: 0.8210\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3410 - accuracy: 0.8997 - val_loss: 0.6102 - val_accuracy: 0.8025\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3428 - accuracy: 0.8827 - val_loss: 0.6091 - val_accuracy: 0.8272\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3106 - accuracy: 0.9275 - val_loss: 0.6313 - val_accuracy: 0.8148\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3428 - accuracy: 0.8858 - val_loss: 0.6151 - val_accuracy: 0.8025\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3658 - accuracy: 0.8873 - val_loss: 0.5984 - val_accuracy: 0.8148\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3240 - accuracy: 0.9074 - val_loss: 0.6197 - val_accuracy: 0.8148\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2978 - accuracy: 0.9012 - val_loss: 0.6241 - val_accuracy: 0.8148\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3136 - accuracy: 0.8997 - val_loss: 0.6139 - val_accuracy: 0.8025\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3329 - accuracy: 0.8951 - val_loss: 0.5908 - val_accuracy: 0.8025\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2819 - accuracy: 0.9090 - val_loss: 0.5991 - val_accuracy: 0.8025\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3363 - accuracy: 0.8858 - val_loss: 0.6257 - val_accuracy: 0.7840\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3242 - accuracy: 0.8981 - val_loss: 0.6219 - val_accuracy: 0.7840\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3113 - accuracy: 0.9105 - val_loss: 0.6202 - val_accuracy: 0.7963\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3597 - accuracy: 0.8843 - val_loss: 0.6217 - val_accuracy: 0.8333\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3203 - accuracy: 0.8951 - val_loss: 0.6228 - val_accuracy: 0.7963\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3424 - accuracy: 0.8889 - val_loss: 0.5950 - val_accuracy: 0.8086\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3250 - accuracy: 0.8951 - val_loss: 0.5955 - val_accuracy: 0.8025\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3274 - accuracy: 0.8889 - val_loss: 0.6092 - val_accuracy: 0.7963\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2843 - accuracy: 0.9259 - val_loss: 0.6601 - val_accuracy: 0.7778\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3368 - accuracy: 0.8981 - val_loss: 0.6013 - val_accuracy: 0.8148\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2999 - accuracy: 0.9136 - val_loss: 0.6006 - val_accuracy: 0.8086\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3192 - accuracy: 0.8920 - val_loss: 0.5907 - val_accuracy: 0.8086\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3056 - accuracy: 0.9120 - val_loss: 0.6300 - val_accuracy: 0.7901\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3349 - accuracy: 0.8904 - val_loss: 0.6015 - val_accuracy: 0.8148\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3284 - accuracy: 0.9074 - val_loss: 0.5930 - val_accuracy: 0.7716\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2997 - accuracy: 0.9136 - val_loss: 0.6002 - val_accuracy: 0.8086\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2993 - accuracy: 0.9136 - val_loss: 0.6585 - val_accuracy: 0.7901\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3241 - accuracy: 0.9012 - val_loss: 0.6249 - val_accuracy: 0.8086\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3062 - accuracy: 0.9028 - val_loss: 0.5935 - val_accuracy: 0.7840\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2920 - accuracy: 0.9105 - val_loss: 0.5995 - val_accuracy: 0.8025\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3310 - accuracy: 0.8858 - val_loss: 0.6098 - val_accuracy: 0.8086\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2953 - accuracy: 0.9259 - val_loss: 0.6099 - val_accuracy: 0.8272\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3104 - accuracy: 0.9012 - val_loss: 0.6177 - val_accuracy: 0.7963\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3089 - accuracy: 0.8966 - val_loss: 0.5866 - val_accuracy: 0.8025\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3079 - accuracy: 0.9074 - val_loss: 0.6162 - val_accuracy: 0.8025\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2976 - accuracy: 0.9012 - val_loss: 0.5977 - val_accuracy: 0.8025\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2899 - accuracy: 0.9167 - val_loss: 0.5815 - val_accuracy: 0.8333\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3122 - accuracy: 0.9151 - val_loss: 0.6188 - val_accuracy: 0.8086\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3171 - accuracy: 0.8935 - val_loss: 0.6137 - val_accuracy: 0.8148\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2868 - accuracy: 0.9167 - val_loss: 0.6335 - val_accuracy: 0.7963\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2970 - accuracy: 0.9120 - val_loss: 0.6042 - val_accuracy: 0.7963\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2924 - accuracy: 0.9028 - val_loss: 0.5679 - val_accuracy: 0.8148\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3140 - accuracy: 0.9012 - val_loss: 0.6085 - val_accuracy: 0.8086\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3072 - accuracy: 0.9105 - val_loss: 0.5953 - val_accuracy: 0.8210\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2949 - accuracy: 0.9105 - val_loss: 0.6034 - val_accuracy: 0.8025\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2921 - accuracy: 0.9120 - val_loss: 0.6205 - val_accuracy: 0.8025\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2773 - accuracy: 0.9244 - val_loss: 0.6190 - val_accuracy: 0.8148\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2731 - accuracy: 0.9151 - val_loss: 0.5901 - val_accuracy: 0.8148\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2747 - accuracy: 0.9244 - val_loss: 0.5836 - val_accuracy: 0.8148\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2662 - accuracy: 0.9136 - val_loss: 0.5950 - val_accuracy: 0.8025\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3340 - accuracy: 0.9012 - val_loss: 0.5804 - val_accuracy: 0.8025\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2933 - accuracy: 0.8981 - val_loss: 0.5910 - val_accuracy: 0.7963\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2679 - accuracy: 0.9120 - val_loss: 0.6272 - val_accuracy: 0.7963\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2625 - accuracy: 0.9228 - val_loss: 0.6071 - val_accuracy: 0.8086\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2495 - accuracy: 0.9244 - val_loss: 0.5839 - val_accuracy: 0.7963\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2828 - accuracy: 0.9306 - val_loss: 0.5666 - val_accuracy: 0.8086\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2447 - accuracy: 0.9275 - val_loss: 0.5911 - val_accuracy: 0.8086\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2449 - accuracy: 0.9275 - val_loss: 0.6048 - val_accuracy: 0.8086\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2709 - accuracy: 0.9198 - val_loss: 0.5984 - val_accuracy: 0.8025\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2878 - accuracy: 0.9259 - val_loss: 0.5821 - val_accuracy: 0.8086\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2398 - accuracy: 0.9321 - val_loss: 0.5637 - val_accuracy: 0.8086\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2503 - accuracy: 0.9352 - val_loss: 0.5873 - val_accuracy: 0.8148\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2776 - accuracy: 0.9074 - val_loss: 0.6159 - val_accuracy: 0.8025\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2743 - accuracy: 0.9198 - val_loss: 0.5974 - val_accuracy: 0.8025\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2560 - accuracy: 0.9275 - val_loss: 0.6042 - val_accuracy: 0.8086\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2755 - accuracy: 0.9290 - val_loss: 0.5910 - val_accuracy: 0.8086\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2540 - accuracy: 0.9259 - val_loss: 0.6236 - val_accuracy: 0.8086\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2543 - accuracy: 0.9321 - val_loss: 0.5826 - val_accuracy: 0.8148\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2638 - accuracy: 0.9275 - val_loss: 0.5917 - val_accuracy: 0.8086\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2775 - accuracy: 0.9151 - val_loss: 0.6192 - val_accuracy: 0.7963\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2768 - accuracy: 0.9043 - val_loss: 0.5946 - val_accuracy: 0.8210\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2308 - accuracy: 0.9336 - val_loss: 0.5941 - val_accuracy: 0.7963\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2968 - accuracy: 0.9120 - val_loss: 0.5847 - val_accuracy: 0.8086\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2808 - accuracy: 0.9059 - val_loss: 0.6342 - val_accuracy: 0.8025\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2566 - accuracy: 0.9213 - val_loss: 0.6104 - val_accuracy: 0.8086\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3058 - accuracy: 0.9090 - val_loss: 0.5948 - val_accuracy: 0.8025\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2625 - accuracy: 0.9105 - val_loss: 0.5951 - val_accuracy: 0.8210\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2451 - accuracy: 0.9383 - val_loss: 0.5949 - val_accuracy: 0.8148\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2295 - accuracy: 0.9398 - val_loss: 0.5833 - val_accuracy: 0.8025\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2267 - accuracy: 0.9336 - val_loss: 0.5840 - val_accuracy: 0.8025\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2625 - accuracy: 0.9290 - val_loss: 0.5974 - val_accuracy: 0.8025\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2351 - accuracy: 0.9414 - val_loss: 0.5953 - val_accuracy: 0.8086\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2613 - accuracy: 0.9198 - val_loss: 0.5862 - val_accuracy: 0.7963\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2374 - accuracy: 0.9352 - val_loss: 0.5904 - val_accuracy: 0.8025\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2494 - accuracy: 0.9275 - val_loss: 0.5991 - val_accuracy: 0.8086\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2181 - accuracy: 0.9352 - val_loss: 0.6045 - val_accuracy: 0.8025\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2637 - accuracy: 0.9213 - val_loss: 0.5842 - val_accuracy: 0.7901\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2519 - accuracy: 0.9290 - val_loss: 0.6051 - val_accuracy: 0.7963\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2465 - accuracy: 0.9383 - val_loss: 0.6136 - val_accuracy: 0.8210\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2284 - accuracy: 0.9336 - val_loss: 0.6198 - val_accuracy: 0.8086\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2421 - accuracy: 0.9321 - val_loss: 0.6235 - val_accuracy: 0.7778\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2242 - accuracy: 0.9352 - val_loss: 0.5895 - val_accuracy: 0.7778\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2435 - accuracy: 0.9198 - val_loss: 0.5854 - val_accuracy: 0.8210\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2568 - accuracy: 0.9290 - val_loss: 0.5883 - val_accuracy: 0.8086\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2359 - accuracy: 0.9336 - val_loss: 0.5896 - val_accuracy: 0.8025\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2483 - accuracy: 0.9321 - val_loss: 0.5832 - val_accuracy: 0.8025\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2007 - accuracy: 0.9444 - val_loss: 0.5779 - val_accuracy: 0.8148\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2099 - accuracy: 0.9398 - val_loss: 0.5823 - val_accuracy: 0.8025\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2399 - accuracy: 0.9213 - val_loss: 0.6141 - val_accuracy: 0.8148\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2019 - accuracy: 0.9475 - val_loss: 0.5806 - val_accuracy: 0.8148\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Dense(50, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=400,\n",
        "    batch_size=400,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkJ-reZmDZxq",
        "outputId": "c48b9ae9-f6ca-4602-8933-c6da5422b8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.48947368421052634\n"
          ]
        }
      ],
      "source": [
        "class std_threshold_NN():\n",
        "    def __init__(self, train, threshold=0.23, clf=NN()):\n",
        "        self._clf = clf\n",
        "        self._threshold = threshold\n",
        "        self._train = train\n",
        "        \n",
        "    def fit(self, X_train):\n",
        "         self._clf.fit(X_train, self._train ,epochs=200, batch_size=512)\n",
        "            \n",
        "    def predict2(self, X):\n",
        "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict(X)]\n",
        "\n",
        "    def probs(self, X):\n",
        "        return self._clf.predict(X)\n",
        "\n",
        "    def std(self, X):\n",
        "        return np.std(self._clf.predict(X))\n",
        "\n",
        "clf = std_threshold_NN(y_train,0.29, clf=model)\n",
        "# model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "# clf.fit(X_train)\n",
        "\n",
        "y_pred_train = clf.predict2(np.array(X_train))\n",
        "y_pred_test = clf.predict2(np.array(X_test))\n",
        "print(accuracy_score(y_pred_train,y_train))\n",
        "print(accuracy_score(y_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pPq7bqXFLkt",
        "outputId": "b5705b10-e575-40c3-f387-d69f40d976d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3662708"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.std(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPljMiP_Ej1X",
        "outputId": "fad5d821-7840-4556-b296-86e833d8a9bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.15789473684210525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "class StdThresholdClassifier():\n",
        "    def __init__(self, train, threshold=0.15, clf=LogisticRegression(C = 9)):\n",
        "        self._clf = clf\n",
        "        self._threshold = threshold\n",
        "        self._train = train\n",
        "        \n",
        "    def fit(self, X_train):\n",
        "         self._clf.fit(X_train, self._train)\n",
        "            \n",
        "    def predict(self, X):\n",
        "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict_proba(X)]\n",
        "\n",
        "clf = StdThresholdClassifier(y_train,0.22, clf=LogisticRegression(C = 9, max_iter=500))\n",
        "# model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "clf.fit(X_train)\n",
        "\n",
        "y_pred_train = clf.predict(np.array(X_train))\n",
        "y_pred_test = clf.predict(np.array(X_test))\n",
        "print(accuracy_score(y_pred_train,y_train))\n",
        "print(accuracy_score(y_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWfJ2uaJ9fpE",
        "outputId": "984c55ac-a2cb-4813-f0d7-017df39a9870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (648, 768)\n",
            "Test data shape: (162, 768)\n",
            "Epoch 1/400\n",
            "2/2 [==============================] - 10s 806ms/step - loss: 2.1967 - accuracy: 0.1281 - val_loss: 2.1973 - val_accuracy: 0.1235\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.1951 - accuracy: 0.1204 - val_loss: 2.1977 - val_accuracy: 0.1420\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.1938 - accuracy: 0.1157 - val_loss: 2.1982 - val_accuracy: 0.1049\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.1900 - accuracy: 0.1204 - val_loss: 2.1997 - val_accuracy: 0.1049\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2.1867 - accuracy: 0.1358 - val_loss: 2.2017 - val_accuracy: 0.1049\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.1875 - accuracy: 0.1235 - val_loss: 2.1932 - val_accuracy: 0.0988\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.1850 - accuracy: 0.1296 - val_loss: 2.1850 - val_accuracy: 0.1358\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.1763 - accuracy: 0.1373 - val_loss: 2.1791 - val_accuracy: 0.1296\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 2.1664 - accuracy: 0.1404 - val_loss: 2.1743 - val_accuracy: 0.1543\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.1593 - accuracy: 0.1528 - val_loss: 2.1701 - val_accuracy: 0.1790\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.1616 - accuracy: 0.1574 - val_loss: 2.1582 - val_accuracy: 0.1667\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 2.1532 - accuracy: 0.1559 - val_loss: 2.1357 - val_accuracy: 0.2037\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.1243 - accuracy: 0.1836 - val_loss: 2.1254 - val_accuracy: 0.1914\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.1189 - accuracy: 0.1790 - val_loss: 2.1058 - val_accuracy: 0.2284\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.0980 - accuracy: 0.2052 - val_loss: 2.0876 - val_accuracy: 0.2593\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.0951 - accuracy: 0.2083 - val_loss: 2.0667 - val_accuracy: 0.2654\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.0466 - accuracy: 0.2562 - val_loss: 2.0274 - val_accuracy: 0.2531\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.0369 - accuracy: 0.2315 - val_loss: 2.0005 - val_accuracy: 0.2963\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.0148 - accuracy: 0.2315 - val_loss: 1.9472 - val_accuracy: 0.3457\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.0064 - accuracy: 0.2315 - val_loss: 1.9121 - val_accuracy: 0.3333\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.9338 - accuracy: 0.2716 - val_loss: 1.9058 - val_accuracy: 0.3272\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.9019 - accuracy: 0.2963 - val_loss: 1.8762 - val_accuracy: 0.3272\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.8690 - accuracy: 0.2978 - val_loss: 1.8122 - val_accuracy: 0.3580\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.8536 - accuracy: 0.2978 - val_loss: 1.7719 - val_accuracy: 0.3642\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.8263 - accuracy: 0.3056 - val_loss: 1.7293 - val_accuracy: 0.4198\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.7604 - accuracy: 0.3225 - val_loss: 1.7194 - val_accuracy: 0.4136\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.7433 - accuracy: 0.3549 - val_loss: 1.6983 - val_accuracy: 0.4198\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.6985 - accuracy: 0.3673 - val_loss: 1.6264 - val_accuracy: 0.4198\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.7007 - accuracy: 0.3657 - val_loss: 1.6261 - val_accuracy: 0.4198\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.6401 - accuracy: 0.3781 - val_loss: 1.6147 - val_accuracy: 0.4321\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.6284 - accuracy: 0.4043 - val_loss: 1.6221 - val_accuracy: 0.4321\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.6241 - accuracy: 0.3920 - val_loss: 1.5845 - val_accuracy: 0.4136\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.5548 - accuracy: 0.4167 - val_loss: 1.5568 - val_accuracy: 0.4383\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.5261 - accuracy: 0.4367 - val_loss: 1.4958 - val_accuracy: 0.4321\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.5118 - accuracy: 0.4491 - val_loss: 1.5569 - val_accuracy: 0.4568\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.4959 - accuracy: 0.4552 - val_loss: 1.4918 - val_accuracy: 0.4938\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.4198 - accuracy: 0.4630 - val_loss: 1.4301 - val_accuracy: 0.4321\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.3766 - accuracy: 0.4753 - val_loss: 1.5025 - val_accuracy: 0.4136\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.3676 - accuracy: 0.4784 - val_loss: 1.4303 - val_accuracy: 0.4568\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.3688 - accuracy: 0.4907 - val_loss: 1.4930 - val_accuracy: 0.4444\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.3756 - accuracy: 0.4830 - val_loss: 1.3706 - val_accuracy: 0.4753\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.3482 - accuracy: 0.5123 - val_loss: 1.3579 - val_accuracy: 0.4938\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.2735 - accuracy: 0.5370 - val_loss: 1.3954 - val_accuracy: 0.4753\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.2424 - accuracy: 0.5448 - val_loss: 1.3209 - val_accuracy: 0.4753\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2379 - accuracy: 0.5262 - val_loss: 1.3044 - val_accuracy: 0.4938\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.2318 - accuracy: 0.5571 - val_loss: 1.2491 - val_accuracy: 0.5309\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.2068 - accuracy: 0.5370 - val_loss: 1.2622 - val_accuracy: 0.5247\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.1491 - accuracy: 0.5710 - val_loss: 1.2419 - val_accuracy: 0.5062\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.1381 - accuracy: 0.6065 - val_loss: 1.2724 - val_accuracy: 0.5185\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.1300 - accuracy: 0.5741 - val_loss: 1.2748 - val_accuracy: 0.5123\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.1915 - accuracy: 0.5741 - val_loss: 1.1697 - val_accuracy: 0.5802\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.1220 - accuracy: 0.5988 - val_loss: 1.2933 - val_accuracy: 0.5247\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.1261 - accuracy: 0.6142 - val_loss: 1.1616 - val_accuracy: 0.5864\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.0723 - accuracy: 0.6080 - val_loss: 1.1531 - val_accuracy: 0.5556\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0326 - accuracy: 0.6451 - val_loss: 1.2274 - val_accuracy: 0.5494\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.0517 - accuracy: 0.6404 - val_loss: 1.1256 - val_accuracy: 0.6049\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.9925 - accuracy: 0.6481 - val_loss: 1.1093 - val_accuracy: 0.5617\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0304 - accuracy: 0.5988 - val_loss: 1.1683 - val_accuracy: 0.5556\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.9725 - accuracy: 0.6590 - val_loss: 1.1286 - val_accuracy: 0.5864\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.9459 - accuracy: 0.6775 - val_loss: 1.0793 - val_accuracy: 0.6111\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.9575 - accuracy: 0.6852 - val_loss: 1.1140 - val_accuracy: 0.6111\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.9786 - accuracy: 0.6590 - val_loss: 1.0765 - val_accuracy: 0.6111\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.9504 - accuracy: 0.6713 - val_loss: 1.0765 - val_accuracy: 0.6111\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9068 - accuracy: 0.6574 - val_loss: 1.0561 - val_accuracy: 0.5988\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8926 - accuracy: 0.6620 - val_loss: 1.0869 - val_accuracy: 0.5432\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8687 - accuracy: 0.6836 - val_loss: 1.0188 - val_accuracy: 0.6235\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8557 - accuracy: 0.6960 - val_loss: 1.0200 - val_accuracy: 0.6358\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8393 - accuracy: 0.6960 - val_loss: 1.0814 - val_accuracy: 0.5864\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.8073 - accuracy: 0.7222 - val_loss: 0.9806 - val_accuracy: 0.6358\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7844 - accuracy: 0.7130 - val_loss: 1.0910 - val_accuracy: 0.6296\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8261 - accuracy: 0.6883 - val_loss: 1.0068 - val_accuracy: 0.6111\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.8084 - accuracy: 0.7361 - val_loss: 0.9647 - val_accuracy: 0.6358\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8673 - accuracy: 0.6651 - val_loss: 1.0181 - val_accuracy: 0.6358\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.8730 - accuracy: 0.7006 - val_loss: 0.9840 - val_accuracy: 0.5988\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8410 - accuracy: 0.6991 - val_loss: 1.0432 - val_accuracy: 0.6111\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7785 - accuracy: 0.7330 - val_loss: 0.9628 - val_accuracy: 0.6605\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.7738 - accuracy: 0.7160 - val_loss: 0.9856 - val_accuracy: 0.6235\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.7939 - accuracy: 0.7114 - val_loss: 1.0234 - val_accuracy: 0.6296\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7790 - accuracy: 0.7299 - val_loss: 0.9496 - val_accuracy: 0.6358\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.7739 - accuracy: 0.7253 - val_loss: 0.9435 - val_accuracy: 0.6420\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7575 - accuracy: 0.7207 - val_loss: 1.0193 - val_accuracy: 0.6235\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7400 - accuracy: 0.7377 - val_loss: 0.9723 - val_accuracy: 0.6173\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6950 - accuracy: 0.7593 - val_loss: 0.9188 - val_accuracy: 0.6667\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.7727 - accuracy: 0.7238 - val_loss: 0.9789 - val_accuracy: 0.6296\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7208 - accuracy: 0.7330 - val_loss: 0.9471 - val_accuracy: 0.6605\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7399 - accuracy: 0.7515 - val_loss: 0.9289 - val_accuracy: 0.6667\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6960 - accuracy: 0.7515 - val_loss: 0.9130 - val_accuracy: 0.6420\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6974 - accuracy: 0.7485 - val_loss: 0.9475 - val_accuracy: 0.6481\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6794 - accuracy: 0.7593 - val_loss: 0.9242 - val_accuracy: 0.6543\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.7055 - accuracy: 0.7531 - val_loss: 0.9111 - val_accuracy: 0.6420\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6677 - accuracy: 0.7654 - val_loss: 0.9373 - val_accuracy: 0.6605\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6597 - accuracy: 0.7639 - val_loss: 0.8947 - val_accuracy: 0.6790\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.7090 - accuracy: 0.7515 - val_loss: 0.8987 - val_accuracy: 0.6667\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6563 - accuracy: 0.7870 - val_loss: 0.8720 - val_accuracy: 0.6914\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6412 - accuracy: 0.7855 - val_loss: 0.8899 - val_accuracy: 0.6852\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6380 - accuracy: 0.7793 - val_loss: 0.8996 - val_accuracy: 0.6667\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6056 - accuracy: 0.7901 - val_loss: 0.9120 - val_accuracy: 0.6790\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6450 - accuracy: 0.7701 - val_loss: 0.8557 - val_accuracy: 0.7099\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6096 - accuracy: 0.8164 - val_loss: 0.8769 - val_accuracy: 0.6728\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5825 - accuracy: 0.7978 - val_loss: 0.8592 - val_accuracy: 0.6790\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5503 - accuracy: 0.8117 - val_loss: 0.8395 - val_accuracy: 0.7160\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5871 - accuracy: 0.7948 - val_loss: 0.9298 - val_accuracy: 0.6667\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5506 - accuracy: 0.8241 - val_loss: 0.8978 - val_accuracy: 0.6790\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6215 - accuracy: 0.7716 - val_loss: 0.8537 - val_accuracy: 0.6914\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5552 - accuracy: 0.8056 - val_loss: 0.9121 - val_accuracy: 0.6728\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5665 - accuracy: 0.8071 - val_loss: 0.8396 - val_accuracy: 0.7037\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5785 - accuracy: 0.8009 - val_loss: 0.8909 - val_accuracy: 0.6667\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5595 - accuracy: 0.8164 - val_loss: 0.8769 - val_accuracy: 0.6605\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5342 - accuracy: 0.8194 - val_loss: 0.8152 - val_accuracy: 0.7407\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5330 - accuracy: 0.8225 - val_loss: 0.8614 - val_accuracy: 0.7037\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5231 - accuracy: 0.8148 - val_loss: 0.8115 - val_accuracy: 0.6914\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5190 - accuracy: 0.8164 - val_loss: 0.8569 - val_accuracy: 0.6667\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5346 - accuracy: 0.8225 - val_loss: 0.8221 - val_accuracy: 0.7037\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5108 - accuracy: 0.8133 - val_loss: 0.8389 - val_accuracy: 0.7160\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5286 - accuracy: 0.8225 - val_loss: 0.9563 - val_accuracy: 0.6481\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5259 - accuracy: 0.8225 - val_loss: 0.8174 - val_accuracy: 0.7037\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5052 - accuracy: 0.8225 - val_loss: 0.8371 - val_accuracy: 0.7099\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5156 - accuracy: 0.8040 - val_loss: 0.8996 - val_accuracy: 0.6481\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5299 - accuracy: 0.8117 - val_loss: 0.8661 - val_accuracy: 0.6914\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5123 - accuracy: 0.8241 - val_loss: 0.8162 - val_accuracy: 0.7037\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4835 - accuracy: 0.8148 - val_loss: 0.8750 - val_accuracy: 0.6605\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4838 - accuracy: 0.8302 - val_loss: 0.8586 - val_accuracy: 0.7099\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4506 - accuracy: 0.8349 - val_loss: 0.8859 - val_accuracy: 0.6667\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4849 - accuracy: 0.8225 - val_loss: 0.8369 - val_accuracy: 0.7099\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5004 - accuracy: 0.8241 - val_loss: 0.8656 - val_accuracy: 0.6975\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5298 - accuracy: 0.8117 - val_loss: 0.8048 - val_accuracy: 0.6975\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4789 - accuracy: 0.8256 - val_loss: 0.8581 - val_accuracy: 0.6543\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4899 - accuracy: 0.8287 - val_loss: 0.7628 - val_accuracy: 0.7284\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4494 - accuracy: 0.8426 - val_loss: 0.8751 - val_accuracy: 0.6975\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5169 - accuracy: 0.8086 - val_loss: 0.8138 - val_accuracy: 0.7284\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4640 - accuracy: 0.8380 - val_loss: 0.7907 - val_accuracy: 0.7160\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4170 - accuracy: 0.8534 - val_loss: 0.7980 - val_accuracy: 0.7037\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4736 - accuracy: 0.8241 - val_loss: 0.8257 - val_accuracy: 0.7099\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4590 - accuracy: 0.8302 - val_loss: 0.8511 - val_accuracy: 0.7284\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4748 - accuracy: 0.8210 - val_loss: 0.7586 - val_accuracy: 0.6852\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4486 - accuracy: 0.8225 - val_loss: 0.8567 - val_accuracy: 0.6605\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4744 - accuracy: 0.8488 - val_loss: 0.7948 - val_accuracy: 0.7037\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4111 - accuracy: 0.8472 - val_loss: 0.8305 - val_accuracy: 0.7099\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4819 - accuracy: 0.8426 - val_loss: 0.7903 - val_accuracy: 0.6975\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4223 - accuracy: 0.8580 - val_loss: 0.7909 - val_accuracy: 0.7160\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.4021 - accuracy: 0.8488 - val_loss: 0.9306 - val_accuracy: 0.6914\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 0.4989 - accuracy: 0.8133 - val_loss: 0.7630 - val_accuracy: 0.7407\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 0.4570 - accuracy: 0.8364 - val_loss: 0.7372 - val_accuracy: 0.7284\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.4116 - accuracy: 0.8704 - val_loss: 0.8340 - val_accuracy: 0.6975\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.4047 - accuracy: 0.8704 - val_loss: 0.7662 - val_accuracy: 0.7222\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3815 - accuracy: 0.8657 - val_loss: 0.7761 - val_accuracy: 0.7469\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3770 - accuracy: 0.8657 - val_loss: 0.8318 - val_accuracy: 0.7037\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3927 - accuracy: 0.8519 - val_loss: 0.7935 - val_accuracy: 0.7160\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3499 - accuracy: 0.8858 - val_loss: 0.8476 - val_accuracy: 0.6852\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.3618 - accuracy: 0.8765 - val_loss: 0.7849 - val_accuracy: 0.7160\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 0.3554 - accuracy: 0.8750 - val_loss: 0.8086 - val_accuracy: 0.6914\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.4222 - accuracy: 0.8472 - val_loss: 0.8397 - val_accuracy: 0.6975\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.3474 - accuracy: 0.8735 - val_loss: 0.8043 - val_accuracy: 0.7037\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.3757 - accuracy: 0.8596 - val_loss: 0.7335 - val_accuracy: 0.7469\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3717 - accuracy: 0.8781 - val_loss: 0.7821 - val_accuracy: 0.7284\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3383 - accuracy: 0.8796 - val_loss: 0.7831 - val_accuracy: 0.7222\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3548 - accuracy: 0.8781 - val_loss: 0.7602 - val_accuracy: 0.7222\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3457 - accuracy: 0.8796 - val_loss: 0.7877 - val_accuracy: 0.7160\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.3586 - accuracy: 0.8843 - val_loss: 0.8474 - val_accuracy: 0.7099\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3250 - accuracy: 0.8889 - val_loss: 0.7915 - val_accuracy: 0.7284\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3273 - accuracy: 0.8843 - val_loss: 0.7592 - val_accuracy: 0.7346\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3473 - accuracy: 0.8781 - val_loss: 0.8261 - val_accuracy: 0.7222\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3293 - accuracy: 0.8781 - val_loss: 0.7733 - val_accuracy: 0.7222\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3315 - accuracy: 0.8920 - val_loss: 0.7715 - val_accuracy: 0.7160\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3075 - accuracy: 0.8951 - val_loss: 0.7373 - val_accuracy: 0.7469\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3368 - accuracy: 0.8873 - val_loss: 0.7930 - val_accuracy: 0.6975\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2941 - accuracy: 0.8889 - val_loss: 0.7578 - val_accuracy: 0.7099\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3233 - accuracy: 0.8719 - val_loss: 0.7297 - val_accuracy: 0.7469\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3143 - accuracy: 0.9059 - val_loss: 0.8504 - val_accuracy: 0.7160\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3206 - accuracy: 0.8750 - val_loss: 0.7403 - val_accuracy: 0.7469\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2963 - accuracy: 0.9074 - val_loss: 0.7494 - val_accuracy: 0.7407\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3211 - accuracy: 0.8904 - val_loss: 0.8374 - val_accuracy: 0.7160\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2823 - accuracy: 0.9105 - val_loss: 0.8621 - val_accuracy: 0.6914\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3170 - accuracy: 0.8889 - val_loss: 0.8525 - val_accuracy: 0.7160\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3325 - accuracy: 0.8843 - val_loss: 0.8122 - val_accuracy: 0.7222\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3190 - accuracy: 0.8827 - val_loss: 0.7355 - val_accuracy: 0.7716\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3290 - accuracy: 0.8812 - val_loss: 0.7550 - val_accuracy: 0.7346\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2667 - accuracy: 0.9090 - val_loss: 0.8778 - val_accuracy: 0.6914\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3181 - accuracy: 0.8935 - val_loss: 0.8332 - val_accuracy: 0.7531\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3200 - accuracy: 0.8843 - val_loss: 0.7456 - val_accuracy: 0.7222\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2829 - accuracy: 0.9120 - val_loss: 0.8434 - val_accuracy: 0.6975\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2872 - accuracy: 0.8981 - val_loss: 0.7657 - val_accuracy: 0.7654\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2728 - accuracy: 0.9012 - val_loss: 0.8282 - val_accuracy: 0.7284\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.8966 - val_loss: 0.8442 - val_accuracy: 0.7099\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2771 - accuracy: 0.9105 - val_loss: 0.7482 - val_accuracy: 0.7716\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3080 - accuracy: 0.8951 - val_loss: 0.7774 - val_accuracy: 0.7346\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2479 - accuracy: 0.9198 - val_loss: 0.8370 - val_accuracy: 0.7160\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2937 - accuracy: 0.8951 - val_loss: 0.7678 - val_accuracy: 0.7593\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2879 - accuracy: 0.8966 - val_loss: 0.7229 - val_accuracy: 0.7346\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2143 - accuracy: 0.9259 - val_loss: 0.7798 - val_accuracy: 0.7593\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2994 - accuracy: 0.8935 - val_loss: 0.8078 - val_accuracy: 0.7346\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2632 - accuracy: 0.9120 - val_loss: 0.7870 - val_accuracy: 0.7284\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2871 - accuracy: 0.8935 - val_loss: 0.7701 - val_accuracy: 0.7222\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2707 - accuracy: 0.9012 - val_loss: 0.7235 - val_accuracy: 0.7346\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2481 - accuracy: 0.9213 - val_loss: 0.7321 - val_accuracy: 0.7469\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2556 - accuracy: 0.9090 - val_loss: 0.7573 - val_accuracy: 0.7346\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2193 - accuracy: 0.9336 - val_loss: 0.8487 - val_accuracy: 0.7037\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2328 - accuracy: 0.9151 - val_loss: 0.8248 - val_accuracy: 0.7407\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2617 - accuracy: 0.9012 - val_loss: 0.7861 - val_accuracy: 0.7469\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2558 - accuracy: 0.9136 - val_loss: 0.8549 - val_accuracy: 0.7099\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2582 - accuracy: 0.9059 - val_loss: 0.7853 - val_accuracy: 0.7407\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2644 - accuracy: 0.8997 - val_loss: 0.7327 - val_accuracy: 0.7716\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2495 - accuracy: 0.9120 - val_loss: 0.7368 - val_accuracy: 0.7407\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2279 - accuracy: 0.9228 - val_loss: 0.7950 - val_accuracy: 0.7037\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2618 - accuracy: 0.9120 - val_loss: 0.7601 - val_accuracy: 0.7222\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2400 - accuracy: 0.9198 - val_loss: 0.8022 - val_accuracy: 0.7284\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2324 - accuracy: 0.9151 - val_loss: 0.7648 - val_accuracy: 0.7346\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2249 - accuracy: 0.9182 - val_loss: 0.7453 - val_accuracy: 0.7654\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2544 - accuracy: 0.8966 - val_loss: 0.8984 - val_accuracy: 0.6914\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2724 - accuracy: 0.8920 - val_loss: 0.7529 - val_accuracy: 0.7531\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2408 - accuracy: 0.9182 - val_loss: 0.8408 - val_accuracy: 0.7407\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2393 - accuracy: 0.9059 - val_loss: 0.9017 - val_accuracy: 0.7037\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2554 - accuracy: 0.9043 - val_loss: 0.8078 - val_accuracy: 0.7284\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2501 - accuracy: 0.9151 - val_loss: 0.7599 - val_accuracy: 0.7654\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2511 - accuracy: 0.9151 - val_loss: 0.9017 - val_accuracy: 0.7160\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2657 - accuracy: 0.9090 - val_loss: 0.7210 - val_accuracy: 0.7716\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2442 - accuracy: 0.9213 - val_loss: 0.7403 - val_accuracy: 0.7901\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2484 - accuracy: 0.9167 - val_loss: 0.9520 - val_accuracy: 0.7037\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2412 - accuracy: 0.9105 - val_loss: 0.8003 - val_accuracy: 0.7407\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2025 - accuracy: 0.9244 - val_loss: 0.7723 - val_accuracy: 0.7716\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2348 - accuracy: 0.9198 - val_loss: 0.8529 - val_accuracy: 0.7160\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.8738 - val_accuracy: 0.7222\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2314 - accuracy: 0.9213 - val_loss: 0.8151 - val_accuracy: 0.7469\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2115 - accuracy: 0.9244 - val_loss: 0.9685 - val_accuracy: 0.7099\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2526 - accuracy: 0.8981 - val_loss: 0.8209 - val_accuracy: 0.7284\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1773 - accuracy: 0.9336 - val_loss: 0.8801 - val_accuracy: 0.7222\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2336 - accuracy: 0.9167 - val_loss: 0.8431 - val_accuracy: 0.7099\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2031 - accuracy: 0.9444 - val_loss: 0.8830 - val_accuracy: 0.7222\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2224 - accuracy: 0.9213 - val_loss: 0.7231 - val_accuracy: 0.7407\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1873 - accuracy: 0.9414 - val_loss: 0.7488 - val_accuracy: 0.7963\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1777 - accuracy: 0.9352 - val_loss: 0.8526 - val_accuracy: 0.7222\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2057 - accuracy: 0.9367 - val_loss: 0.8972 - val_accuracy: 0.7346\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2233 - accuracy: 0.9167 - val_loss: 0.7910 - val_accuracy: 0.7716\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1873 - accuracy: 0.9444 - val_loss: 0.7733 - val_accuracy: 0.7346\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1797 - accuracy: 0.9414 - val_loss: 0.8557 - val_accuracy: 0.7469\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1856 - accuracy: 0.9352 - val_loss: 0.7964 - val_accuracy: 0.7531\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 247ms/step - loss: 0.1837 - accuracy: 0.9429 - val_loss: 0.8214 - val_accuracy: 0.7778\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2015 - accuracy: 0.9213 - val_loss: 0.8625 - val_accuracy: 0.7407\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1829 - accuracy: 0.9383 - val_loss: 0.8568 - val_accuracy: 0.7531\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2038 - accuracy: 0.9321 - val_loss: 0.7798 - val_accuracy: 0.7531\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1996 - accuracy: 0.9259 - val_loss: 0.7628 - val_accuracy: 0.7963\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1874 - accuracy: 0.9290 - val_loss: 0.7714 - val_accuracy: 0.7593\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1753 - accuracy: 0.9290 - val_loss: 0.7788 - val_accuracy: 0.7469\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1618 - accuracy: 0.9460 - val_loss: 0.8091 - val_accuracy: 0.7346\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1729 - accuracy: 0.9429 - val_loss: 0.7453 - val_accuracy: 0.7778\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1631 - accuracy: 0.9414 - val_loss: 0.7553 - val_accuracy: 0.7593\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1523 - accuracy: 0.9429 - val_loss: 0.7751 - val_accuracy: 0.7654\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1601 - accuracy: 0.9367 - val_loss: 0.8230 - val_accuracy: 0.7778\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1748 - accuracy: 0.9444 - val_loss: 0.8747 - val_accuracy: 0.7531\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1678 - accuracy: 0.9460 - val_loss: 0.7543 - val_accuracy: 0.7654\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1506 - accuracy: 0.9583 - val_loss: 0.8223 - val_accuracy: 0.7531\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1705 - accuracy: 0.9460 - val_loss: 0.9056 - val_accuracy: 0.7346\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1881 - accuracy: 0.9336 - val_loss: 0.7971 - val_accuracy: 0.7531\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.1817 - accuracy: 0.9429 - val_loss: 0.7672 - val_accuracy: 0.7593\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1580 - accuracy: 0.9460 - val_loss: 0.8638 - val_accuracy: 0.7099\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1909 - accuracy: 0.9352 - val_loss: 0.7506 - val_accuracy: 0.7654\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2015 - accuracy: 0.9321 - val_loss: 0.7561 - val_accuracy: 0.7469\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1508 - accuracy: 0.9522 - val_loss: 0.8234 - val_accuracy: 0.7469\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1391 - accuracy: 0.9522 - val_loss: 0.8216 - val_accuracy: 0.7407\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1658 - accuracy: 0.9306 - val_loss: 0.8456 - val_accuracy: 0.7654\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1818 - accuracy: 0.9367 - val_loss: 0.8642 - val_accuracy: 0.7531\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.1540 - accuracy: 0.9444 - val_loss: 0.9018 - val_accuracy: 0.7469\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.2074 - accuracy: 0.9275 - val_loss: 0.7986 - val_accuracy: 0.7593\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.1918 - accuracy: 0.9336 - val_loss: 0.7662 - val_accuracy: 0.7346\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.1327 - accuracy: 0.9552 - val_loss: 0.7792 - val_accuracy: 0.7593\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.1563 - accuracy: 0.9444 - val_loss: 0.7564 - val_accuracy: 0.7593\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 0.1278 - accuracy: 0.9552 - val_loss: 0.8603 - val_accuracy: 0.7284\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.1687 - accuracy: 0.9429 - val_loss: 0.7952 - val_accuracy: 0.7531\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.1351 - accuracy: 0.9552 - val_loss: 0.7791 - val_accuracy: 0.7654\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.1077 - accuracy: 0.9676 - val_loss: 0.8170 - val_accuracy: 0.7346\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1765 - accuracy: 0.9367 - val_loss: 0.8425 - val_accuracy: 0.7284\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.1240 - accuracy: 0.9599 - val_loss: 0.9672 - val_accuracy: 0.7407\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.2009 - accuracy: 0.9336 - val_loss: 0.8813 - val_accuracy: 0.7593\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.1410 - accuracy: 0.9475 - val_loss: 0.8189 - val_accuracy: 0.7284\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1496 - accuracy: 0.9583 - val_loss: 0.7316 - val_accuracy: 0.7716\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1506 - accuracy: 0.9491 - val_loss: 0.7694 - val_accuracy: 0.7407\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1078 - accuracy: 0.9722 - val_loss: 0.8782 - val_accuracy: 0.7346\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1288 - accuracy: 0.9630 - val_loss: 0.9615 - val_accuracy: 0.7654\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1440 - accuracy: 0.9506 - val_loss: 0.9575 - val_accuracy: 0.7222\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1489 - accuracy: 0.9491 - val_loss: 0.9395 - val_accuracy: 0.7160\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1553 - accuracy: 0.9506 - val_loss: 0.8300 - val_accuracy: 0.7654\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1457 - accuracy: 0.9398 - val_loss: 0.9113 - val_accuracy: 0.7407\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1665 - accuracy: 0.9475 - val_loss: 0.9096 - val_accuracy: 0.7160\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1724 - accuracy: 0.9429 - val_loss: 0.8373 - val_accuracy: 0.7346\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1962 - accuracy: 0.9228 - val_loss: 0.7840 - val_accuracy: 0.7407\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1543 - accuracy: 0.9491 - val_loss: 0.8783 - val_accuracy: 0.7469\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1680 - accuracy: 0.9429 - val_loss: 0.8665 - val_accuracy: 0.7531\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1947 - accuracy: 0.9414 - val_loss: 0.7973 - val_accuracy: 0.7593\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1476 - accuracy: 0.9522 - val_loss: 0.8929 - val_accuracy: 0.7346\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1447 - accuracy: 0.9506 - val_loss: 0.8106 - val_accuracy: 0.7716\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1564 - accuracy: 0.9522 - val_loss: 0.9286 - val_accuracy: 0.7407\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1599 - accuracy: 0.9444 - val_loss: 0.9520 - val_accuracy: 0.7222\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1318 - accuracy: 0.9630 - val_loss: 1.0005 - val_accuracy: 0.7222\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1313 - accuracy: 0.9568 - val_loss: 0.9401 - val_accuracy: 0.7346\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1571 - accuracy: 0.9475 - val_loss: 0.8488 - val_accuracy: 0.7407\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1518 - accuracy: 0.9460 - val_loss: 0.9330 - val_accuracy: 0.7531\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1560 - accuracy: 0.9522 - val_loss: 0.8935 - val_accuracy: 0.7593\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1740 - accuracy: 0.9336 - val_loss: 0.8134 - val_accuracy: 0.7840\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1011 - accuracy: 0.9645 - val_loss: 0.8672 - val_accuracy: 0.7593\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1735 - accuracy: 0.9429 - val_loss: 0.7723 - val_accuracy: 0.7469\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1285 - accuracy: 0.9645 - val_loss: 0.8145 - val_accuracy: 0.7346\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1600 - accuracy: 0.9444 - val_loss: 0.8221 - val_accuracy: 0.7593\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1197 - accuracy: 0.9614 - val_loss: 0.8506 - val_accuracy: 0.7531\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1342 - accuracy: 0.9568 - val_loss: 0.8599 - val_accuracy: 0.7407\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.1617 - accuracy: 0.9398 - val_loss: 0.8772 - val_accuracy: 0.7222\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1189 - accuracy: 0.9568 - val_loss: 0.8377 - val_accuracy: 0.7593\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1446 - accuracy: 0.9630 - val_loss: 0.8124 - val_accuracy: 0.7593\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1122 - accuracy: 0.9614 - val_loss: 0.8248 - val_accuracy: 0.7901\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1107 - accuracy: 0.9660 - val_loss: 0.8191 - val_accuracy: 0.7654\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0929 - accuracy: 0.9707 - val_loss: 0.9076 - val_accuracy: 0.7593\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1157 - accuracy: 0.9583 - val_loss: 0.9520 - val_accuracy: 0.7593\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1018 - accuracy: 0.9630 - val_loss: 0.8914 - val_accuracy: 0.7531\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1127 - accuracy: 0.9583 - val_loss: 0.8043 - val_accuracy: 0.7531\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1147 - accuracy: 0.9676 - val_loss: 0.8101 - val_accuracy: 0.7778\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1194 - accuracy: 0.9599 - val_loss: 0.8863 - val_accuracy: 0.7531\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1242 - accuracy: 0.9506 - val_loss: 0.9376 - val_accuracy: 0.7531\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1031 - accuracy: 0.9676 - val_loss: 0.9039 - val_accuracy: 0.7531\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1189 - accuracy: 0.9506 - val_loss: 0.8532 - val_accuracy: 0.7716\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0983 - accuracy: 0.9722 - val_loss: 0.9019 - val_accuracy: 0.7407\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0972 - accuracy: 0.9691 - val_loss: 0.9020 - val_accuracy: 0.7654\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0939 - accuracy: 0.9722 - val_loss: 0.9582 - val_accuracy: 0.7654\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0883 - accuracy: 0.9769 - val_loss: 1.0668 - val_accuracy: 0.7284\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1207 - accuracy: 0.9599 - val_loss: 0.8489 - val_accuracy: 0.7654\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0979 - accuracy: 0.9645 - val_loss: 0.7516 - val_accuracy: 0.8025\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1003 - accuracy: 0.9645 - val_loss: 0.8234 - val_accuracy: 0.7593\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1320 - accuracy: 0.9522 - val_loss: 0.8399 - val_accuracy: 0.7531\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0879 - accuracy: 0.9707 - val_loss: 0.8201 - val_accuracy: 0.7840\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0952 - accuracy: 0.9599 - val_loss: 0.8224 - val_accuracy: 0.7654\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1264 - accuracy: 0.9552 - val_loss: 0.8533 - val_accuracy: 0.7593\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1401 - accuracy: 0.9552 - val_loss: 0.7907 - val_accuracy: 0.7716\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0911 - accuracy: 0.9738 - val_loss: 0.8559 - val_accuracy: 0.7716\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0938 - accuracy: 0.9753 - val_loss: 0.8716 - val_accuracy: 0.7531\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0835 - accuracy: 0.9722 - val_loss: 0.9238 - val_accuracy: 0.7407\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0866 - accuracy: 0.9676 - val_loss: 0.8958 - val_accuracy: 0.7531\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1022 - accuracy: 0.9645 - val_loss: 0.8387 - val_accuracy: 0.7593\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1217 - accuracy: 0.9568 - val_loss: 0.8650 - val_accuracy: 0.7716\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0868 - accuracy: 0.9660 - val_loss: 1.0291 - val_accuracy: 0.7531\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1084 - accuracy: 0.9630 - val_loss: 0.8848 - val_accuracy: 0.7531\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0675 - accuracy: 0.9769 - val_loss: 0.8686 - val_accuracy: 0.7716\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0816 - accuracy: 0.9769 - val_loss: 0.8737 - val_accuracy: 0.7593\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 0.9031 - val_accuracy: 0.7654\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0828 - accuracy: 0.9660 - val_loss: 0.8701 - val_accuracy: 0.7716\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0974 - accuracy: 0.9614 - val_loss: 0.9220 - val_accuracy: 0.7346\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0973 - accuracy: 0.9753 - val_loss: 0.9807 - val_accuracy: 0.7346\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1020 - accuracy: 0.9660 - val_loss: 0.8173 - val_accuracy: 0.7716\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 0.8319 - val_accuracy: 0.7593\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1246 - accuracy: 0.9568 - val_loss: 0.8567 - val_accuracy: 0.7469\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1015 - accuracy: 0.9722 - val_loss: 0.8159 - val_accuracy: 0.7654\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0760 - accuracy: 0.9769 - val_loss: 0.8354 - val_accuracy: 0.7654\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0936 - accuracy: 0.9630 - val_loss: 0.9026 - val_accuracy: 0.7716\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0668 - accuracy: 0.9722 - val_loss: 1.0149 - val_accuracy: 0.7346\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.9236 - val_accuracy: 0.7654\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1106 - accuracy: 0.9614 - val_loss: 0.9278 - val_accuracy: 0.7654\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0862 - accuracy: 0.9784 - val_loss: 1.0079 - val_accuracy: 0.7469\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0992 - accuracy: 0.9630 - val_loss: 1.0348 - val_accuracy: 0.7407\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1120 - accuracy: 0.9614 - val_loss: 1.0108 - val_accuracy: 0.7407\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0713 - accuracy: 0.9753 - val_loss: 0.8998 - val_accuracy: 0.7778\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0623 - accuracy: 0.9830 - val_loss: 0.8450 - val_accuracy: 0.7840\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0576 - accuracy: 0.9830 - val_loss: 0.8959 - val_accuracy: 0.7531\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0804 - accuracy: 0.9707 - val_loss: 1.0336 - val_accuracy: 0.7284\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0939 - accuracy: 0.9676 - val_loss: 0.9413 - val_accuracy: 0.7654\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.8936 - val_accuracy: 0.7840\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0775 - accuracy: 0.9707 - val_loss: 0.9333 - val_accuracy: 0.7531\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1050 - accuracy: 0.9552 - val_loss: 0.8120 - val_accuracy: 0.7778\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0824 - accuracy: 0.9707 - val_loss: 0.8695 - val_accuracy: 0.7778\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1102 - accuracy: 0.9614 - val_loss: 0.9697 - val_accuracy: 0.7654\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1192 - accuracy: 0.9599 - val_loss: 0.8896 - val_accuracy: 0.7593\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0743 - accuracy: 0.9769 - val_loss: 0.7707 - val_accuracy: 0.8025\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0770 - accuracy: 0.9784 - val_loss: 0.7415 - val_accuracy: 0.7593\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0806 - accuracy: 0.9738 - val_loss: 0.7729 - val_accuracy: 0.7716\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0666 - accuracy: 0.9753 - val_loss: 0.8637 - val_accuracy: 0.7654\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1075 - accuracy: 0.9645 - val_loss: 0.8187 - val_accuracy: 0.7840\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0609 - accuracy: 0.9846 - val_loss: 0.9279 - val_accuracy: 0.7593\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0781 - accuracy: 0.9738 - val_loss: 1.0014 - val_accuracy: 0.7901\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1093 - accuracy: 0.9614 - val_loss: 1.0971 - val_accuracy: 0.7469\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1018 - accuracy: 0.9630 - val_loss: 0.9970 - val_accuracy: 0.7469\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0996 - accuracy: 0.9676 - val_loss: 0.8130 - val_accuracy: 0.7593\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1069 - accuracy: 0.9614 - val_loss: 0.8050 - val_accuracy: 0.7778\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1200 - accuracy: 0.9676 - val_loss: 1.0283 - val_accuracy: 0.7531\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0973 - accuracy: 0.9676 - val_loss: 0.8676 - val_accuracy: 0.7716\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0938 - accuracy: 0.9660 - val_loss: 0.8992 - val_accuracy: 0.7716\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1061 - accuracy: 0.9676 - val_loss: 0.9538 - val_accuracy: 0.7346\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1034 - accuracy: 0.9691 - val_loss: 1.0201 - val_accuracy: 0.7469\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0814 - accuracy: 0.9753 - val_loss: 0.9104 - val_accuracy: 0.7901\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0872 - accuracy: 0.9784 - val_loss: 0.9338 - val_accuracy: 0.7901\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0795 - accuracy: 0.9722 - val_loss: 0.9941 - val_accuracy: 0.7531\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0877 - accuracy: 0.9722 - val_loss: 0.9197 - val_accuracy: 0.7531\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 0.8897 - val_accuracy: 0.7531\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0895 - accuracy: 0.9630 - val_loss: 0.9308 - val_accuracy: 0.7407\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0828 - accuracy: 0.9676 - val_loss: 0.8932 - val_accuracy: 0.7654\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0953 - accuracy: 0.9660 - val_loss: 0.9121 - val_accuracy: 0.7531\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.9676 - val_accuracy: 0.7531\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0735 - accuracy: 0.9722 - val_loss: 1.0675 - val_accuracy: 0.7222\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1130 - accuracy: 0.9614 - val_loss: 0.9181 - val_accuracy: 0.7593\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0903 - accuracy: 0.9707 - val_loss: 0.8912 - val_accuracy: 0.7654\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0967 - accuracy: 0.9660 - val_loss: 0.9834 - val_accuracy: 0.7531\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1129 - accuracy: 0.9660 - val_loss: 0.8981 - val_accuracy: 0.7963\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0876 - accuracy: 0.9753 - val_loss: 0.9705 - val_accuracy: 0.7593\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0799 - accuracy: 0.9784 - val_loss: 1.0418 - val_accuracy: 0.7222\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0643 - accuracy: 0.9784 - val_loss: 0.9690 - val_accuracy: 0.7346\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "class NN(Model):\n",
        "\n",
        "  def __init__(self): \n",
        "    super().__init__()\n",
        "    self.clf = Sequential([\n",
        "      Bidirectional(LSTM(100, activation='relu',return_sequences=True)),\n",
        "      Dropout(0.2),\n",
        "      Bidirectional(LSTM(50, activation='relu',return_sequences=True)),\n",
        "      Dropout(0.2),\n",
        "      Bidirectional(LSTM(30, activation='relu')),\n",
        "      Dropout(0.2),\n",
        "      Dense(9, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "  def call(self, inputs):\n",
        "    prob = self.clf(inputs)\n",
        "    return prob\n",
        "model = NN()\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_val2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "print(\"Test data shape:\", X_val.shape)\n",
        "# configurations of model\n",
        "model.compile(loss='SparseCategoricalCrossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train2,\n",
        "    y_train,\n",
        "    epochs=400,\n",
        "    batch_size=400,\n",
        "    validation_data=(X_val2,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdGOKEwLMwh"
      },
      "outputs": [],
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=8):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmuAEKhVLMzp"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test\n",
        "\n",
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=20,\n",
        "    batch_size=100,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")\n",
        "\n",
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def find_threshold_method_two(model, x_train_scaled):\n",
        "  # another method to find threshold\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "\n",
        "  threshold_2 = np.percentile(reconstruction_errors, 95)\n",
        "  return threshold_2\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = model.predict(x_test_scaled)\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
        "  # 0 = anomaly, 1 = normal\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1 if x == True else -1)\n",
        "  return preds\n",
        "\n",
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, x_train_scaled)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "\n",
        "preds = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Gik6VeRVs8"
      },
      "outputs": [],
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=4):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3yqESbMRcR6"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=20,\n",
        "    batch_size=100,\n",
        "    validation_data=(x_test_scaled, x_test_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ej1TqpkRiYR"
      },
      "outputs": [],
      "source": [
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, x_train_scaled)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "\n",
        "preds = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZKU3Y0ARwvR"
      },
      "outputs": [],
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "x_train_scaled = X_train\n",
        "x_test_scaled = X_test\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=4):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(30, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZJMfvIBR_EC"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=400,\n",
        "    batch_size=150,\n",
        "    validation_data=(x_test_scaled, x_test_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcVVvRfnR9Gs"
      },
      "outputs": [],
      "source": [
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, x_train_scaled)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "\n",
        "preds = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3UTdV9cg9W8"
      },
      "outputs": [],
      "source": [
        "X_tr = X_train\n",
        "X_te = X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgSOqIFbSzRY"
      },
      "outputs": [],
      "source": [
        "# define the autoencoder network model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxwCudAYTJYz"
      },
      "source": [
        "LSTM autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjyq_xUTTL5J"
      },
      "outputs": [],
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.mse(reconstructions, x_train_scaled)\n",
        "\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def find_threshold_method_two(model, x_train_scaled):\n",
        "  # another method to find threshold\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.mse(reconstructions, x_train_scaled)\n",
        "\n",
        "  threshold_2 = np.percentile(reconstruction_errors, 95)\n",
        "  return threshold_2\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = np.array(model.predict(x_test_scaled))\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.mse(predictions, x_test_scaled)\n",
        "  # 0 = anomaly, 1 = normal\n",
        "  errors=np.array(errors).reshape(errors.shape[0],)\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1 if x == True else -1)\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNAZ0wchSqBK"
      },
      "outputs": [],
      "source": [
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(32, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(16, activation='relu', return_sequences=True)(L1)\n",
        "    L3 = LSTM(4, activation='relu', return_sequences=False)(L2)\n",
        "    L4 = RepeatVector(X.shape[1])(L3)\n",
        "    L5 = LSTM(4, activation='relu', return_sequences=True)(L4)\n",
        "    L6 = LSTM(16, activation='relu', return_sequences=True)(L5)\n",
        "    L7 = LSTM(32, activation='relu', return_sequences=True)(L6)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "nb_epochs = 100\n",
        "batch_size = 100\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history\n",
        "\n",
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQIic00ghY3L"
      },
      "outputs": [],
      "source": [
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(32, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(16, activation='relu', return_sequences=True)(L1)\n",
        "    L3 = LSTM(8, activation='relu', return_sequences=False)(L2)\n",
        "    L4 = RepeatVector(X.shape[1])(L3)\n",
        "    L5 = LSTM(8, activation='relu', return_sequences=True)(L4)\n",
        "    L6 = LSTM(16, activation='relu', return_sequences=True)(L5)\n",
        "    L7 = LSTM(32, activation='relu', return_sequences=True)(L6)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "nb_epochs = 20\n",
        "batch_size = 20\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history\n",
        "\n",
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaYCNsqcjniJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = Bidirectional(LSTM(32, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00)))(inputs)\n",
        "    L2 = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(L1)\n",
        "    L3 = Bidirectional(LSTM(8, activation='relu', return_sequences=False))(L2)\n",
        "    L4 = RepeatVector(X.shape[1])(L3)\n",
        "    L5 = Bidirectional(LSTM(8, activation='relu', return_sequences=True))(L4)\n",
        "    L6 = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(L5)\n",
        "    L7 = Bidirectional(LSTM(32, activation='relu', return_sequences=True))(L6)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "nb_epochs = 1000\n",
        "batch_size = 100  \n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n",
        "                    validation_split=0.05).history\n",
        "\n",
        "threshold = find_threshold(model, X_train)\n",
        "print(f\"Threshold method one: {threshold}\")\n",
        "\n",
        "threshold_2 = find_threshold_method_two(model, X_train)\n",
        "print(f\"Threshold method two: {threshold_2}\")\n",
        "preds = get_predictions(model, X_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AkhJb3jpxq"
      },
      "outputs": [],
      "source": [
        "preds = get_predictions(model, X_test, threshold_2)\n",
        "accuracy_score(preds, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHlnP1K7cVOV"
      },
      "source": [
        "# Finding parameters for dbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxuTFals-Mi6"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "nclusters = []\n",
        "minPts = 3\n",
        "for i in range(2, 200):\n",
        "  dbscan=DBSCAN(eps=i/100,min_samples=minPts)\n",
        "  dbscan.fit(X_train)\n",
        "  labels = dbscan.labels_\n",
        "  nclusters.append(np.max(labels)+1)\n",
        "\n",
        "plt.plot([i/100 for i in range(2,200)],nclusters)\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('number of clusters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3KNeDvf-EUC"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "minPts =  195\n",
        "neighbors = NearestNeighbors(n_neighbors=minPts)\n",
        "neighbors_fit = neighbors.fit(X_train)\n",
        "distances, indices = neighbors_fit.kneighbors(X_train)\n",
        "dist = distances[:,minPts-1]\n",
        "dist_sort = np.sort(dist)\n",
        "plt.plot(dist_sort)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVMe4r1rcsM9"
      },
      "source": [
        "# Applying dbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meONQOZDYEr_"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 1.25\n",
        "minPts =3\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYOANkP3dDAB"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 1.2\n",
        "minPts =300\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ8u-3Zwdvmp"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 2\n",
        "minPts =300\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kIBK-0ceKtY"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 1.25\n",
        "minPts =195\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGCzqo6wLxXl"
      },
      "outputs": [],
      "source": [
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnnblNFyckB-"
      },
      "outputs": [],
      "source": [
        "# results = pd.DataFrame({'clustered': [list(predict2)], 'label': [db_y_test]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeHfgKL-erCO"
      },
      "outputs": [],
      "source": [
        "columns = ['comment','vector','clustered', 'label']\n",
        "results = pd.DataFrame(data=list(zip(text_test0, X_test0, predict2, db_y_test)),columns=columns)\n",
        "results.head(60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rps-L31eZd0x"
      },
      "outputs": [],
      "source": [
        "len(dbscan.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7aBqZffZngP"
      },
      "outputs": [],
      "source": [
        "len(clf.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epYGgpqUVaSk"
      },
      "outputs": [],
      "source": [
        "dbscan.n_features_in_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tyk2y0ohq_1"
      },
      "source": [
        "# Isolation Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_sTbEMZqfps"
      },
      "source": [
        "# Testing different parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8wQ_xOohpnd"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=10, bootstrap=False,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnNdzaLEHN9l"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', max_features=1.0, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PPCZCSIHpxL"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=200, max_samples='auto', contamination='auto', max_features=1.0, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00ThLw_dHvXe"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=200, max_samples=50, contamination='auto', max_features=1.0, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS0w6sWJIRGO"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=200, max_samples=50, contamination=0.1, max_features=1.0, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nifq4flIvij"
      },
      "source": [
        "big difference (contamination 0.1 -> 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m-fu_lGIpZT"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=200, max_samples=50, contamination=0.5, max_features=1.0, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTZfHHFFItxr"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=200, max_samples=50, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z70XADZUJHZs"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=150, max_samples=50, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT_SLeKWJmaa"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=115, max_samples=50, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vneQq341JzRS"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=115, max_samples=90, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY8djNkEKLYR"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=95, max_samples=90, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER3WO9O-K9NK"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=95, max_samples=90, contamination=0.5, max_features=5, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cSzVaDxhs4e"
      },
      "outputs": [],
      "source": [
        "columns = ['comment','vector','clustered', 'label']\n",
        "results = pd.DataFrame(data=list(zip(text_test0, X_test0, predict2, y_test)),columns=columns)\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNFmw4bOr8Lk"
      },
      "outputs": [],
      "source": [
        "Xtrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5dHDzObqNZI"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toYKVFq2rRQ2"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEwBqq7brVEl"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wCE6yxHssA8"
      },
      "outputs": [],
      "source": [
        "# Set the figure size\n",
        "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Random data of 1003 dimension\n",
        "data = np.array(np.random.random((100, 3)))\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], cmap='blue')\n",
        "\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], cmap='red')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C64mtJQEzt30"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [5,5]\n",
        "plt.rcParams[\"figure.autolayout\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe6SUaN8zMbe"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "nclusters = []\n",
        "minPts = 3\n",
        "for i in range(2, 200):\n",
        "  dbscan=DBSCAN(eps=i/100,min_samples=minPts)\n",
        "  dbscan.fit(X_train)\n",
        "  labels = dbscan.labels_\n",
        "  nclusters.append(np.max(labels)+1)\n",
        "\n",
        "plt.plot([i/100 for i in range(2,200)],nclusters)\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('number of clusters')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hquwAi6PzOCs"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "minPts =  2\n",
        "neighbors = NearestNeighbors(n_neighbors=minPts)\n",
        "neighbors_fit = neighbors.fit(X_train)\n",
        "distances, indices = neighbors_fit.kneighbors(X_train)\n",
        "dist = distances[:,minPts-1]\n",
        "dist_sort = np.sort(dist)\n",
        "plt.plot(dist_sort)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZhfCw5Xy989"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 1.25\n",
        "minPts =195\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltGyfHCFz2du"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts).fit(X_train)\n",
        "\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))\n",
        "print(f1_score(predict, db_train, average='macro'))\n",
        "print(f1_score(predict2, db_y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCL8RzzQ2ojK"
      },
      "source": [
        "metric: minkowski"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwOqH6jp2zP6"
      },
      "outputs": [],
      "source": [
        "import scipy.spatial.distance\n",
        "\n",
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=1.5).fit(X_train)\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1NAL063qvy"
      },
      "outputs": [],
      "source": [
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=2).fit(X_train)\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9bKo-Xf3q3I"
      },
      "outputs": [],
      "source": [
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=3.5).fit(X_train)\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIjsC7VA3q7g"
      },
      "outputs": [],
      "source": [
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=4.5).fit(X_train)\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpoyaw9r3q-g"
      },
      "outputs": [],
      "source": [
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=5).fit(X_train)\n",
        "epsilon = 0.1\n",
        "minPts =2\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkQFlCbt4AHo"
      },
      "outputs": [],
      "source": [
        "clf=DBSCAN(eps=epsilon,min_samples=minPts, metric='minkowski', p=1).fit(X_train)\n",
        "epsilon =0.1\n",
        "minPts =3\n",
        "predict = clf.fit_predict(X_train)\n",
        "predict2=  clf.fit_predict(X_test)\n",
        "print('train: ',accuracy_score(predict, db_train))\n",
        "print('test: ',accuracy_score(predict2, db_y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B-6w7bAAKJf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=predict2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBxFO1sPC_cF"
      },
      "outputs": [],
      "source": [
        "columns = ['clustered', 'label']\n",
        "results = pd.DataFrame(data=list(zip( predict2, db_y_test)),columns=columns)\n",
        "results.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f21PoQ5CSal"
      },
      "outputs": [],
      "source": [
        "results['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJm4OohhDUeM"
      },
      "outputs": [],
      "source": [
        "results['clustered'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dov-fm85C2W8"
      },
      "outputs": [],
      "source": [
        "results.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5eU3c6oCqd9"
      },
      "outputs": [],
      "source": [
        "db_y_test.shape\n",
        "predict2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6MaEU8CwzgP"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=95, max_samples=90, contamination=0.5, max_features=2, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ9sCUt-w-MH"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=15, max_samples='auto', contamination='auto', max_features=1, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvoX6tnNx92W"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=15, max_samples='auto', contamination=0.1, max_features=1, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKPxzs4gyFaO"
      },
      "outputs": [],
      "source": [
        "clf = IsolationForest(n_estimators=15, max_samples='auto', contamination=0.19, max_features=1, bootstrap=False, n_jobs=None,random_state=0)\n",
        "\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "print(accuracy_score(y_pred_train, y_train))\n",
        "print(accuracy_score( y_pred_test, y_test))\n",
        "print(f1_score(y_pred_train, y_train, average='macro'))\n",
        "print(f1_score(y_pred_test, y_test, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-D1Ker3E3ry"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQg6zeAnE7oK"
      },
      "outputs": [],
      "source": [
        "columns = ['clustered', 'label']\n",
        "results = pd.DataFrame(data=list(zip( y_pred_test, y_test)),columns=columns)\n",
        "results.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p153_PoUE-wW"
      },
      "outputs": [],
      "source": [
        "results['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4uqfFm4FDI6"
      },
      "outputs": [],
      "source": [
        "results['clustered'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXQhGjEbK0Jy"
      },
      "outputs": [],
      "source": [
        "#metric: minkowski\n",
        "#opisa problem wielowymiarowosci w pracy i opisa dbscan "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPYDZs_HkYa6"
      },
      "outputs": [],
      "source": [
        "#random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vVNEFuPZYwT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMLEfB5TihPt"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import IsolationForest\n",
        "# from sklearn.metrics import make_scorer, f1_score\n",
        "# from sklearn import model_selection\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# X_train, y_train = make_classification(n_samples=500, \n",
        "#                                        n_classes=2)\n",
        "\n",
        "# clf = IsolationForest(random_state=47 )\n",
        "\n",
        "# param_grid = {'n_estimators': list(range(1, 801, 50)), \n",
        "#               'max_samples': list(range(1, 501, 50)), \n",
        "#               'contamination': ['auto', 0.1, 0.2, 0.3, 0.4, 0.5], \n",
        "#               'max_features': [1, 3, 5, 10, 15],  \n",
        "#               'n_jobs': [None, 2, 5, 10, 20, 30]}\n",
        "\n",
        "\n",
        "# f1sc = make_scorer(f1_score, average='micro')\n",
        "# grid_dt_estimator = model_selection.GridSearchCV(clf, \n",
        "#                                                  param_grid,\n",
        "#                                                  scoring=f1sc, \n",
        "#                                                  refit=True,\n",
        "#                                                  cv=10, \n",
        "#                                                  return_train_score=True)\n",
        "# grid_dt_estimator.fit(X_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
